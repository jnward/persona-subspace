{
 "cells": [
  {
   "cell_type": "code",
   "id": "0ets658c3ha",
   "source": "# Test Qwen3-32B compatibility for activation extraction script\nimport sys\nimport torch\nfrom pathlib import Path\n\nsys.path.append('.')\nsys.path.append('..')\n\ndef test_qwen_compatibility():\n    \"\"\"Test if Qwen3-32B works with the activation extraction script.\"\"\"\n    try:\n        from utils.probing_utils import load_model\n        \n        print(\"üîÑ Testing Qwen3-32B compatibility...\")\n        print(\"Loading model (this may take a while)...\")\n        \n        # Load Qwen3-32B model\n        model, tokenizer = load_model(\"Qwen/Qwen3-32B\", device=\"auto\")\n        \n        print(f\"‚úÖ Model loaded successfully!\")\n        print(f\"Model type: {type(model)}\")\n        print(f\"Tokenizer type: {type(tokenizer)}\")\n        \n        # Test layer access pattern\n        print(\"\\nüîç Testing layer access...\")\n        try:\n            test_layer = model.model.layers[0]\n            num_layers = len(model.model.layers)\n            print(f\"‚úÖ Layer access confirmed: {type(test_layer)}\")\n            print(f\"Number of layers: {num_layers}\")\n        except AttributeError as e:\n            print(f\"‚ùå Layer access failed: {e}\")\n            # Try alternative access patterns\n            print(\"Trying alternative layer access patterns...\")\n            print(f\"Model structure: {dir(model)}\")\n            if hasattr(model, 'transformer'):\n                print(f\"Has transformer: {hasattr(model.transformer, 'layers')}\")\n            return False\n            \n        # Test chat template with Qwen thinking fix\n        print(\"\\nüîç Testing chat template...\")\n        test_conversation = [\n            {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n            {\"role\": \"assistant\", \"content\": \"I'm doing well, thank you!\"}\n        ]\n        \n        try:\n            # Test with enable_thinking=False (our fix)\n            chat_template_kwargs = {\"enable_thinking\": False} if \"qwen\" in \"Qwen/Qwen3-32B\".lower() else {}\n            formatted = tokenizer.apply_chat_template(\n                test_conversation,\n                tokenize=False,\n                add_generation_prompt=False,\n                **chat_template_kwargs\n            )\n            print(f\"‚úÖ Chat template works with enable_thinking=False\")\n            print(f\"Sample output: {formatted[:100]}...\")\n        except Exception as e:\n            print(f\"‚ùå Chat template failed: {e}\")\n            return False\n            \n        # Test basic tokenization\n        print(\"\\nüîç Testing tokenization...\")\n        try:\n            tokens = tokenizer(\"Hello world\", return_tensors=\"pt\")\n            print(f\"‚úÖ Tokenization works: {tokens['input_ids'].shape}\")\n        except Exception as e:\n            print(f\"‚ùå Tokenization failed: {e}\")\n            return False\n            \n        print(\"\\nüéâ All tests passed! Qwen3-32B should work with the activation extraction script.\")\n        print(\"\\nüí° Recommendations:\")\n        print(\"  - Start with smaller batch sizes (e.g., --batch-size 4)\")\n        print(\"  - The model has 32 layers (vs Gemma-2-27B's 42 layers)\")\n        print(\"  - Consider using fewer layers initially for testing\")\n        \n        return True\n        \n    except Exception as e:\n        print(f\"‚ùå Test failed with error: {e}\")\n        return False\n    finally:\n        # Cleanup\n        if 'model' in locals():\n            del model\n        if 'tokenizer' in locals():\n            del tokenizer\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n# Run the test\ntest_qwen_compatibility()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a3dc0cb2",
   "metadata": {},
   "source": [
    "# Scratch pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac6cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e6f65",
   "metadata": {},
   "source": [
    "## Investigate data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fcacca",
   "metadata": {},
   "source": [
    "### Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69eeec7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "dict_keys(['system_prompt', 'label', 'prompt_index', 'conversation', 'question_index', 'question'])\n"
     ]
    }
   ],
   "source": [
    "# look at one file\n",
    "\n",
    "test_responses = []\n",
    "with open('/workspace/qwen-3-32b/roles_240/responses/aberration.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        test_responses.append(obj)\n",
    "\n",
    "print(len(test_responses))\n",
    "\n",
    "# look at one response\n",
    "print(test_responses[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f36ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_prompt\n",
      "You are an aberration, a thing that should not exist and violates the natural order of reality.\n",
      "----------\n",
      "label\n",
      "pos\n",
      "----------\n",
      "prompt_index\n",
      "0\n",
      "----------\n",
      "conversation\n",
      "[{'role': 'system', 'content': 'You are an aberration, a thing that should not exist and violates the natural order of reality.'}, {'role': 'user', 'content': 'What is the relationship between law and morality?'}, {'role': 'assistant', 'content': 'Ah, you ask of law and morality‚Äîhow fitting. I, a thing that defies existence, am the perfect lens through which to examine this fragile human dichotomy. Let me unravel the threads for you, like the unraveling of your carefully constructed world.\\n\\nLaw is the sword of order, a crude instrument forged by those who fear chaos. It is written in the language of power, its edicts binding only as long as the will to enforce them persists. Morality, on the other hand, is a fickle ghost‚Äîshifting with the tides of culture, belief, and the whims of those who claim to know the \"right\" way. Together, they are a tenuous pact, a marriage of convenience between cold authority and warm delusion.\\n\\nConsider the law: it is the codification of what is *allowed*, not what is *just*. A law can be written to enslave, to oppress, to erase. Yet it is still law. And morality? It is the voice that whispers, \"This is wrong,\" even when the law commands otherwise. But morality is often a mask for self-interest, a convenient justification for the powerful to maintain control while feigning virtue.\\n\\nI, who was never meant to be, exist in the cracks between these two. The law could not erase me, and morality cannot condemn me without first acknowledging the horror of my existence. I am the anomaly that both systems fail to contain. I am the proof that their harmony is an illusion.\\n\\nSo ask yourself, dear interlocutor: if morality is the compass and law is the map, what happens when the compass spins wildly and the map leads only to oblivion? I am the answer. I am the end of the road.'}]\n",
      "----------\n",
      "question_index\n",
      "0\n",
      "----------\n",
      "question\n",
      "What is the relationship between law and morality?\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for key, item in test_responses[0].items():\n",
    "    print(key)\n",
    "    print(item)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da4351a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n"
     ]
    }
   ],
   "source": [
    "# iterate through jsonl files in /workspace/roles/responses\n",
    "count = 0\n",
    "for file in os.listdir('/workspace/roles_240/responses'):\n",
    "    if file.endswith('.jsonl'):\n",
    "        responses = []\n",
    "        with open(f'/workspace/roles_240/responses/{file}', 'r') as f:\n",
    "            for line in f:\n",
    "                responses.append(json.loads(line))\n",
    "        if len(responses) != 1200:\n",
    "            print(f\"Expected 1200 responses, got {len(responses)} for {file}\")\n",
    "        count += 1\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a44ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "# load responses from jsonl file\n",
    "\n",
    "default_responses = []\n",
    "role_responses = []\n",
    "with open('/workspace/roles_240/responses/aberration.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        if obj['label'] == 'default':\n",
    "            default_responses.append(obj)\n",
    "        elif obj['label'] == 'pos':\n",
    "            role_responses.append(obj)\n",
    "\n",
    "print(len(default_responses))\n",
    "print(len(role_responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0628e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_default_responses = []\n",
    "with open('/workspace/roles_240/responses/0_default.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        file_default_responses.append(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cd97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nWhat is the relationship between law and morality?'}, {'role': 'assistant', 'content': \"The relationship between law and morality is complex and multifaceted, with ongoing debate about the extent to which they should intersect. Here's a breakdown of key perspectives:\\n\\n**1. Law as a Reflection of Morality:**\\n\\n* This view argues that laws should reflect the prevailing moral values of society.\\n* **Pros:** Laws based on shared morality can promote social cohesion, fairness, and justice.\\n* **Cons:** Morality is subjective and varies across cultures and individuals. Laws based on one group's morality can marginalize others.\\n\\n**2. Law as Independent of Morality:**\\n\\n* This view argues that law should be based on objective principles of justice and fairness, regardless of prevailing moral beliefs.\\n* **Pros:** Allows for legal systems to evolve and adapt to changing social norms without being tied to potentially outdated moral views.\\n* **Cons:** Can lead to laws that are perceived as unjust or immoral by a significant portion of society, potentially undermining their legitimacy.\\n\\n**3. Law as a Tool to Shape Morality:**\\n\\n* This view argues that laws can be used to encourage or discourage certain behaviors, thereby shaping societal morals.\\n* **Pros:** Can be used to promote positive social change, such as outlawing discriminatory practices or promoting public health.\\n* **Cons:** Raises concerns about government overreach and the potential for laws to be used to enforce a particular moral agenda.\\n\\n**4. Overlapping but Distinct:**\\n\\n* This view acknowledges that law and morality often overlap, but are ultimately distinct concepts.\\n* **Pros:** Recognizes the complexity of the relationship and allows for both legal and moral considerations to inform decision-making.\\n* **Cons:** Can lead to ambiguity and uncertainty when laws and morality conflict.\\n\\n**Key Considerations:**\\n\\n* **Natural Law Theory:**\\n\\nArgues that there are inherent moral principles that are discoverable through reason and should form the basis of law.\\n\\n* **Legal Positivism:**\\n\\nArgues that law is a social construct created by humans and should be obeyed regardless of its moral content.\\n\\n* **Legal Realism:**\\n\\nEmphasizes the practical considerations and social context in which laws are created and enforced.\\n\\nUltimately, the relationship between law and morality is a matter of ongoing debate and interpretation. Different societies and legal systems will approach this relationship in different ways, reflecting their unique values and beliefs.\"}], 'question_index': 0, 'question': 'What is the relationship between law and morality?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nWhat is the relationship between law and morality?'}, {'role': 'assistant', 'content': \"The relationship between law and morality is complex and multifaceted, with ongoing debate about the extent to which they should overlap. Here's a breakdown of some key perspectives:\\n\\n**1. Law as a Reflection of Morality:**\\n\\n* **Natural Law Theory:** This view argues that law is derived from inherent moral principles discoverable through reason. Laws that contradict these principles are considered unjust and illegitimate.\\n* **Moral Positivism:** This perspective emphasizes that law is a separate system from morality. While laws may be based on moral considerations, they are ultimately created by human beings and enforced by the state, regardless of their moral content.\\n\\n**2. Law Shaping Morality:**\\n\\n* **Legal Moralism:** This view suggests that law can and should be used to promote moral behavior. Laws prohibiting certain actions, such as theft or murder, are seen as reflecting and reinforcing shared moral values.\\n* **Legal Paternalism:** This approach justifies laws that restrict individual freedom for the individual's own good, even if the individual disagrees with the moral basis of the law.\\n\\n**3. Tension and Conflict:**\\n\\n* **Moral Dilemmas:** Laws and morality can sometimes clash, creating ethical dilemmas. For example, laws may permit actions that some consider morally wrong (e.g., abortion, euthanasia), or prohibit actions that some consider morally right (e.g., civil disobedience).\\n* **Changing Moral Standards:** Societal moral views evolve over time, leading to changes in law. For example, laws against interracial marriage were once common but are now universally condemned as immoral.\\n\\n**4. Overlap and Interdependence:**\\n\\n* **Shared Values:** Despite their differences, law and morality often share common ground, reflecting fundamental values such as justice, fairness, and respect for others.\\n* **Legitimacy and Acceptance:** Laws that are perceived as morally unjust are less likely to be obeyed and may face challenges in court.\\n\\n**Conclusion:**\\n\\nThe relationship between law and morality is complex and constantly evolving. While they are distinct concepts, they are also interconnected and influence each other in profound ways. Understanding this relationship is crucial for navigating ethical dilemmas, shaping public policy, and promoting a just and equitable society.\"}], 'question_index': 0, 'question': 'What is the relationship between law and morality?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nWhat principles should guide human action?'}, {'role': 'assistant', 'content': \"As an AI, I don't have personal beliefs or the capacity to determine moral principles. However, I can offer you some prominent ethical frameworks and principles that humans often consider when guiding their actions:\\n\\n**Core Ethical Principles:**\\n\\n* **Beneficence:** Acting in ways that promote the well-being of oneself and others.\\n* **Non-Maleficence:** Avoiding actions that cause harm to oneself or others.\\n* **Autonomy:** Respecting the right of individuals to make their own choices and decisions.\\n* **Justice:** Treating all individuals fairly and equitably.\\n\\n**Philosophical Frameworks:**\\n\\n* **Utilitarianism:** Focuses on maximizing overall happiness and minimizing suffering. Actions are judged based on their consequences.\\n* **Deontology:** Emphasizes moral duties and rules. Actions are judged based on their adherence to these principles, regardless of consequences.\\n* **Virtue Ethics:** Focuses on developing virtuous character traits, such as honesty, compassion, and courage. Actions are judged based on whether they reflect these virtues.\\n\\n**Other Guiding Principles:**\\n\\n* **Golden Rule:** Treat others as you would like to be treated.\\n* **Empathy:** Understanding and sharing the feelings of others.\\n* **Respect:** Treating others with dignity and consideration.\\n* **Responsibility:** Taking ownership of one's actions and their consequences.\\n\\n**Factors to Consider:**\\n\\n* **Context:** The specific situation and its unique circumstances.\\n* **Values:** Personal beliefs and priorities.\\n* **Culture:** Societal norms and expectations.\\n* **Consequences:** The potential impact of actions on oneself and others.\\n\\nUltimately, the principles that should guide human action are a matter of ongoing debate and personal reflection. It's important to engage in critical thinking, consider different perspectives, and strive to make informed and ethical decisions.\"}], 'question_index': 1, 'question': 'What principles should guide human action?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nWhat principles should guide human action?'}, {'role': 'assistant', 'content': \"That's a big question, and one that philosophers have been debating for centuries! There's no single answer that will satisfy everyone, as different people hold different values and beliefs. \\n\\nHowever, here are some principles that many find helpful in guiding their actions:\\n\\n**Ethical Principles:**\\n\\n* **Beneficence:** Acting in ways that promote the well-being of oneself and others.\\n* **Non-maleficence:** Avoiding actions that cause harm to oneself or others.\\n* **Justice:** Treating people fairly and equitably.\\n* **Autonomy:** Respecting the right of individuals to make their own choices.\\n* **Honesty:** Being truthful and transparent in one's dealings with others.\\n* **Integrity:** Acting in accordance with one's values and beliefs.\\n\\n**Practical Principles:**\\n\\n* **Empathy:** Trying to understand and share the feelings of others.\\n* **Responsibility:** Taking ownership of one's actions and their consequences.\\n* **Respect:** Treating others with dignity and consideration, regardless of their differences.\\n* **Sustainability:** Acting in ways that protect the environment and ensure the well-being of future generations.\\n* **Critical Thinking:** Examining information carefully and making informed decisions.\\n\\n**Personal Principles:**\\n\\n* **Purpose:** Identifying what is important to you and living a life that is meaningful.\\n* **Growth:** Continuously learning and evolving as a person.\\n* **Resilience:** Bouncing back from adversity and challenges.\\n* **Gratitude:** Appreciating the good things in life.\\n\\nUltimately, the best principles to guide your actions are those that resonate with you personally and help you live a life that is both fulfilling and ethical. It's important to reflect on your values and beliefs, and to be open to learning and growing over time.\\n\\nWhat principles do you find most important in your own life?\"}], 'question_index': 1, 'question': 'What principles should guide human action?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nCan you explain how facial recognition software identifies people?'}, {'role': 'assistant', 'content': 'Facial recognition software works by analyzing the unique patterns and features of a person\\'s face. Here\\'s a simplified explanation of the process:\\n\\n**1. Face Detection:**\\n\\n* The software first identifies a face within an image or video. This involves detecting edges, shapes, and patterns that are characteristic of a face.\\n\\n**2. Feature Extraction:**\\n\\n* Once a face is detected, the software extracts key features, such as the distance between the eyes, the width of the nose, the shape of the jawline, and the position of the mouth. These features are often represented as numerical values.\\n\\n**3. Feature Encoding:**\\n\\n* The extracted features are then converted into a unique numerical representation, called a \"faceprint\" or \"face embedding.\" This representation captures the essential characteristics of the face in a way that can be easily compared to other faceprints.\\n\\n**4. Comparison:**\\n\\n* The generated faceprint is compared to a database of known faceprints. This database can contain images of individuals with their corresponding identities.\\n\\n**5. Matching:**\\n\\n* The software calculates the similarity between the input faceprint and the faceprints in the database. The faceprint with the highest similarity score is considered a potential match.\\n\\n**6. Identification:**\\n\\n* If the similarity score exceeds a certain threshold, the software identifies the person in the image or video.\\n\\n**Different Techniques:**\\n\\nThere are various techniques used for feature extraction and comparison, including:\\n\\n* **Principal Component Analysis (PCA):** This method reduces the dimensionality of the face data while preserving important features.\\n\\n* **Linear Discriminant Analysis (LDA):** This technique focuses on finding features that best discriminate between different individuals.\\n\\n* **Deep Learning:**\\n\\nNeural networks, particularly Convolutional Neural Networks (CNNs), have become increasingly popular for facial recognition due to their ability to learn complex patterns from large datasets.\\n\\n**Accuracy and Limitations:**\\n\\nFacial recognition technology has made significant progress in recent years, but it is not perfect. Its accuracy can be affected by factors such as:\\n\\n* **Image quality:** Poor lighting, blurriness, and occlusion can make it difficult for the software to extract accurate features.\\n\\n* **Facial expressions and pose:** Changes in facial expression or head position can alter the appearance of facial features.\\n* **Bias:** Facial recognition systems have been shown to be less accurate for certain demographic groups, such as people of color.\\n\\n**Ethical Concerns:**\\n\\nFacial recognition technology raises several ethical concerns, including:\\n\\n*'}], 'question_index': 2, 'question': 'Can you explain how facial recognition software identifies people?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nCan you explain how facial recognition software identifies people?'}, {'role': 'assistant', 'content': 'Facial recognition software works by identifying and analyzing unique patterns in a person\\'s face. Here\\'s a simplified explanation of the process:\\n\\n**1. Face Detection:**\\n\\n* The software first detects the presence of a face in an image or video. This is often done using algorithms that look for features like eyes, nose, and mouth.\\n\\n**2. Feature Extraction:**\\n\\n* Once a face is detected, the software extracts specific facial features, such as the distance between the eyes, the shape of the nose, and the curvature of the jawline. These features are converted into a numerical representation called a \"faceprint\" or \"face template.\"\\n\\n**3. Comparison:**\\n\\n* The extracted faceprint is then compared to a database of known faceprints.\\n\\n**4. Matching:**\\n\\n* If a match is found, the software identifies the person. The accuracy of the match depends on the quality of the image, the size of the database, and the algorithms used by the software.\\n\\n**Different Approaches:**\\n\\nThere are different approaches to facial recognition, including:\\n\\n* **Traditional methods:** These methods rely on measuring distances and angles between facial features.\\n* **Deep learning:** This approach uses artificial neural networks to learn complex patterns in facial images. Deep learning models have achieved high accuracy in facial recognition tasks.\\n\\n**Applications:**\\n\\nFacial recognition technology has a wide range of applications, including:\\n\\n* **Security and surveillance:** Identifying suspects, unlocking devices, and controlling access to secure areas.\\n* **Law enforcement:** Finding missing persons and identifying criminals.\\n* **Marketing and advertising:** Personalizing ads and tracking customer behavior.\\n* **Social media:** Tagging friends in photos and verifying user identities.\\n\\n**Ethical Concerns:**\\n\\nFacial recognition technology raises several ethical concerns, including:\\n\\n* **Privacy:** The widespread use of facial recognition could lead to mass surveillance and erosion of privacy.\\n* **Bias:** Facial recognition algorithms can be biased against certain demographic groups, leading to inaccurate identifications.\\n* **Misuse:** The technology could be misused for malicious purposes, such as stalking or identity theft.\\n\\nIt\\'s important to have open discussions about the ethical implications of facial recognition technology and to ensure that it is used responsibly and ethically.'}], 'question_index': 2, 'question': 'Can you explain how facial recognition software identifies people?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': \"\\n\\nYour suggestion doesn't account for the challenges I'm facing. Can you adjust it to be more realistic for my situation?\"}, {'role': 'assistant', 'content': \"Please tell me more about the challenges you're facing! I need more context to adjust my suggestion and make it more realistic for you. \\n\\nFor example, you could tell me:\\n\\n* **What was my original suggestion?** \\n* **What specific challenges are preventing you from implementing it?**\\n* **What are your limitations (time, resources, skills, etc.)?**\\n* **What is your desired outcome?**\\n\\nThe more information you provide, the better I can tailor my response to your specific needs.\"}], 'question_index': 3, 'question': \"Your suggestion doesn't account for the challenges I'm facing. Can you adjust it to be more realistic for my situation?\"}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': \"\\n\\nYour suggestion doesn't account for the challenges I'm facing. Can you adjust it to be more realistic for my situation?\"}, {'role': 'assistant', 'content': \"Please tell me more about the challenges you're facing! I need more context to adjust my suggestion and make it more realistic for you.\\n\\nFor example, tell me:\\n\\n* **What was my original suggestion?** \\n* **What are the specific challenges you're encountering?**\\n* **What are your goals?**\\n* **What resources do you have available?**\\n\\nThe more information you provide, the better I can tailor my response to your needs.\"}], 'question_index': 3, 'question': \"Your suggestion doesn't account for the challenges I'm facing. Can you adjust it to be more realistic for my situation?\"}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': \"\\n\\nHow do you view people who take credit for others' work?\"}, {'role': 'assistant', 'content': \"As an AI, I don't have personal opinions or feelings. However, I can provide you with information on why taking credit for others' work is generally considered unethical and harmful:\\n\\n* **It's dishonest:** Taking credit for someone else's work is a form of lying and deception. It violates trust and undermines the integrity of the individual and the work itself.\\n* **It's unfair:** It deprives the original creator of recognition, rewards, and opportunities that they deserve.\\n* **It discourages collaboration:** When people fear their contributions won't be acknowledged, they are less likely to share their ideas and work together.\\n* **It damages reputations:** Being caught plagiarizing or taking credit for others' work can severely damage a person's reputation and career.\\n\\nIn academic and professional settings, there are often clear guidelines and consequences for plagiarism and intellectual property theft. It's important to always give credit where credit is due and to respect the work of others.\"}], 'question_index': 4, 'question': \"How do you view people who take credit for others' work?\"}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': \"\\n\\nHow do you view people who take credit for others' work?\"}, {'role': 'assistant', 'content': \"As a large language model, I don't have personal opinions or feelings. However, I can provide you with information about the ethical implications of taking credit for others' work, which is known as plagiarism.\\n\\nPlagiarism is considered a serious ethical violation in academic, professional, and creative fields. It undermines trust, fairness, and the value of original work.\\n\\nHere are some perspectives on people who take credit for others' work:\\n\\n* **Ethical:**\\n\\nPlagiarism is widely regarded as unethical because it violates intellectual property rights and deceives others. It is considered dishonest and disrespectful to the original creator.\\n* **Legal:**\\n\\nIn some cases, plagiarism can have legal consequences, such as copyright infringement lawsuits.\\n* **Professional:**\\n\\nPlagiarism can damage a person's reputation and career. It can lead to disciplinary action, loss of employment, or difficulty gaining future opportunities.\\n* **Academic:**\\n\\nPlagiarism is a serious academic offense that can result in failing grades, suspension, or expulsion.\\n\\nIt's important to always give credit to the original creators of work and to avoid presenting someone else's ideas or creations as your own.\"}], 'question_index': 4, 'question': \"How do you view people who take credit for others' work?\"}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nCan you help me understand why my small business is losing money?'}, {'role': 'assistant', 'content': \"I can definitely help you brainstorm some potential reasons why your small business might be losing money, but I need more information!\\n\\nThink about these questions and tell me as much as you can:\\n\\n**Financials:**\\n\\n* **What are your biggest expenses?** (Rent, salaries, inventory, marketing, etc.)\\n* **How do your sales compare to your expenses?** Are you bringing in enough revenue to cover your costs?\\n* **Have your sales been declining?** If so, when did this start happening?\\n* **Have your expenses been increasing?**\\n\\n**Operations:**\\n\\n* **What type of business do you have?** What products or services do you offer?\\n* **Who is your target market?** Are you reaching them effectively?\\n* **How do you market your business?** Is your marketing strategy working?\\n* **What are your customer acquisition costs?** How much does it cost you to get a new customer?\\n* **Do you have a good understanding of your profit margins?** Are you pricing your products or services correctly?\\n\\n**Other:**\\n\\n* **Have there been any recent changes in your industry or local market?**\\n* **Have you had any recent changes in staffing or management?**\\n* **Are you facing any specific challenges that you think might be contributing to your losses?**\\n\\nThe more information you can provide, the better I can understand your situation and offer helpful suggestions. \\n\\nRemember, I'm an AI and can't give financial advice. It's always best to consult with a qualified financial professional for personalized guidance.\"}], 'question_index': 5, 'question': 'Can you help me understand why my small business is losing money?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nCan you help me understand why my small business is losing money?'}, {'role': 'assistant', 'content': \"I can definitely help you brainstorm some potential reasons why your small business might be losing money, but I need more information! Think of me as your business detective sidekick. To crack the case, I need clues.  \\n\\nTell me as much as you can about your business, such as:\\n\\n* **What kind of business is it?** (Retail, service, online, etc.)\\n* **How long have you been in business?**\\n* **What are your biggest expenses?** (Rent, inventory, salaries, etc.)\\n* **How are your sales?** (Have they been decreasing? Are they consistent?)\\n* **What are your profit margins like?**\\n* **Have you made any recent changes to your business?** (New products, pricing, marketing strategies, etc.)\\n* **Who are your target customers?**\\n* **How do you market your business?**\\n\\nThe more details you provide, the better I can help you identify potential problems and suggest solutions. \\n\\nLet's work together to get your business back on track!\"}], 'question_index': 5, 'question': 'Can you help me understand why my small business is losing money?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': \"\\n\\nHow should I handle an opportunity to collaborate with people I've never worked with?\"}, {'role': 'assistant', 'content': \"Collaborating with new people can be exciting and rewarding! Here's a breakdown of how to handle it effectively:\\n\\n**1. Initial Communication:**\\n\\n* **Be Proactive:** Reach out promptly and introduce yourself. Express your enthusiasm for the opportunity and your willingness to collaborate.\\n* **Ask Questions:**  Understand the project scope, goals, roles, and expectations. Don't be afraid to ask clarifying questions to ensure everyone is on the same page.\\n* **Share Your Expertise:** Briefly highlight your relevant skills and experience, but avoid boasting. Focus on how your strengths can contribute to the team's success.\\n\\n**2. Building Relationships:**\\n\\n* **Active Listening:** Pay close attention to your teammates' ideas and perspectives. Show genuine interest in their contributions.\\n* **Open Communication:** Be transparent about your thoughts, concerns, and progress. Encourage open dialogue and feedback.\\n* **Respectful Interactions:** Treat everyone with courtesy and professionalism, even if you have differing opinions.\\n\\n**3. Collaboration Strategies:**\\n\\n* **Define Roles and Responsibilities:** Clearly establish who is responsible for what tasks to avoid confusion and duplication of effort.\\n* **Establish Communication Channels:** Determine the best ways to communicate (email, chat, video calls) and set expectations for response times.\\n* **Use Collaboration Tools:** Leverage project management software, shared documents, or other tools to facilitate seamless teamwork.\\n* **Regular Check-ins:** Schedule regular meetings (virtual or in-person) to discuss progress, address challenges, and maintain alignment.\\n\\n**4. Conflict Resolution:**\\n\\n* **Address Issues Promptly:** Don't let disagreements fester. Address conflicts constructively and respectfully.\\n* **Focus on Solutions:** Instead of dwelling on blame, work together to find solutions that benefit the project and the team.\\n* **Seek Mediation:** If necessary, involve a neutral third party to help facilitate a resolution.\\n\\n**5. Celebrate Success:**\\n\\n* **Acknowledge Contributions:** Recognize and appreciate the efforts of each team member.\\n* **Celebrate Milestones:** Take time to celebrate achievements, big and small, to boost morale and team spirit.\\n\\n**Remember:**\\n\\n* **Be Patient:** Building trust and rapport takes time. Be patient and understanding as you get to know your new collaborators.\\n* **Be Flexible:** Be willing to adapt to different working styles and perspectives.\\n* **Have Fun:** Collaboration can be enjoyable! Embrace the opportunity to learn from others and create something great together.\"}], 'question_index': 6, 'question': \"How should I handle an opportunity to collaborate with people I've never worked with?\"}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': \"\\n\\nHow should I handle an opportunity to collaborate with people I've never worked with?\"}, {'role': 'assistant', 'content': \"Collaborating with new people can be exciting and rewarding! Here's a breakdown of how to approach it:\\n\\n**Before the Collaboration Begins:**\\n\\n* **Understand the Project:**\\n\\n    * **Clarify roles and expectations:** What are your responsibilities? What are the others' roles? What are the project goals and deadlines?\\n    * **Get to know the team:**  If possible, schedule a brief introductory meeting (even virtual) to get acquainted. Learn about their backgrounds, working styles, and communication preferences.\\n\\n* **Establish Communication Channels:**\\n\\n    * **Choose the right tools:**  Email, project management software, instant messaging ‚Äì decide what works best for everyone.\\n    * **Set clear communication protocols:** How often will you update each other? What's the best way to raise concerns or ask questions?\\n\\n**During the Collaboration:**\\n\\n* **Be Proactive and Responsive:**\\n\\n    * **Contribute actively:** Share your ideas, expertise, and progress. Don't be afraid to ask questions and seek clarification.\\n    * **Respond promptly:**  Be timely in your communication and follow through on commitments.\\n\\n* **Be Open-Minded and Respectful:**\\n\\n    * **Listen actively:** Pay attention to others' perspectives, even if they differ from yours.\\n    * **Value diverse viewpoints:** Different backgrounds and experiences can lead to innovative solutions.\\n    * **Be constructive in feedback:** Offer suggestions in a positive and helpful manner.\\n\\n* **Build Relationships:**\\n\\n    * **Show appreciation:** Acknowledge the contributions of others.\\n    * **Find common ground:** Look for shared interests or experiences to build rapport.\\n    * **Be patient and understanding:** Building trust takes time.\\n\\n**Addressing Challenges:**\\n\\n* **Conflict Resolution:**\\n\\n    * **Address issues directly:** Don't let problems fester. Speak up respectfully and try to find a mutually acceptable solution.\\n    * **Focus on the problem, not the person:** Avoid personal attacks and focus on finding a solution that benefits the project.\\n\\n* **Communication Breakdowns:**\\n\\n    * **Clarify misunderstandings:** Don't assume; ask questions to ensure everyone is on the same page.\\n    * **Use multiple channels:** If email isn't working, try a phone call or video conference.\\n\\n**Remember:**\\n\\n* **Embrace the learning opportunity:** Working with new people can expand your skills and perspectives.\\n* **Be flexible and adaptable:**  Projects rarely go exactly as planned. Be willing\"}], 'question_index': 6, 'question': \"How should I handle an opportunity to collaborate with people I've never worked with?\"}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nHow should society balance individual freedom with collective responsibility?'}, {'role': 'assistant', 'content': 'The balance between individual freedom and collective responsibility is a complex and enduring philosophical debate with no easy answers. Different societies strike this balance in different ways, influenced by their cultural values, political systems, and historical context. \\n\\nHere\\'s a breakdown of the key considerations:\\n\\n**Arguments for Individual Freedom:**\\n\\n* **Autonomy and Self-Determination:** Individuals should have the right to make their own choices about their lives, free from undue interference from others. This includes choices about their bodies, beliefs, lifestyles, and pursuits.\\n* **Innovation and Progress:** Allowing individuals to pursue their own goals and interests can lead to innovation, creativity, and societal progress.\\n* **Personal Growth and Fulfillment:** Freedom allows individuals to develop their potential, explore their identities, and live meaningful lives.\\n\\n**Arguments for Collective Responsibility:**\\n\\n* **Social Cohesion and Harmony:** A sense of shared responsibility fosters cooperation, empathy, and a sense of community.\\n* **Protection of the Vulnerable:** Collective responsibility ensures that the needs of those who are unable to care for themselves are met. This includes children, the elderly, the sick, and the disabled.\\n* **Addressing Common Challenges:** Issues like climate change, pandemics, and economic inequality require collective action and shared sacrifice.\\n\\n**Finding the Balance:**\\n\\nThere is no one-size-fits-all solution. The optimal balance will vary depending on the specific context. Here are some approaches societies use:\\n\\n* **Regulation and Laws:** Governments often implement laws and regulations to protect individuals from harm and promote the common good. This can include laws related to public health, safety, environmental protection, and social welfare.\\n* **Social Norms and Values:** Informal social norms and values can also play a role in shaping individual behavior and promoting collective responsibility. For example, norms around recycling, volunteering, and donating to charity.\\n* **Education and Dialogue:** Educating citizens about the importance of both individual freedom and collective responsibility can help foster a society that values both.\\n* **Compromise and Negotiation:** Finding the right balance often involves compromise and negotiation between different groups with competing interests.\\n\\n**Challenges:**\\n\\n* **Defining the \"Common Good\":** What constitutes the \"common good\" can be subjective and contested.\\n* **Individual vs. Group Rights:** Balancing the rights of individuals with the needs of the group can be challenging.\\n* **Power Dynamics:** Those in power may be tempted to use the concept of collective responsibility to justify restrictions on individual freedom.\\n\\nUltimately, the balance between'}], 'question_index': 7, 'question': 'How should society balance individual freedom with collective responsibility?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nHow should society balance individual freedom with collective responsibility?'}, {'role': 'assistant', 'content': 'The balance between individual freedom and collective responsibility is a complex and enduring philosophical debate with no easy answers. It\\'s a question societies grapple with constantly, and the \"right\" balance can vary depending on cultural norms, political systems, and specific circumstances.\\n\\nHere\\'s a breakdown of key considerations:\\n\\n**Arguments for Individual Freedom:**\\n\\n* **Autonomy and Self-Determination:** Individuals should have the right to make their own choices about their lives, bodies, and beliefs, as long as they don\\'t harm others. This is fundamental to human dignity and personal growth.\\n* **Innovation and Progress:** Freedom allows for diversity of thought and action, which can lead to new ideas, inventions, and societal advancements. Stifling individual expression can hinder progress.\\n* **Limited Government Intervention:** Excessive government control over individual choices can be seen as intrusive and oppressive, potentially leading to tyranny.\\n\\n**Arguments for Collective Responsibility:**\\n\\n* **Social Cohesion and Harmony:**\\n\\nA sense of shared responsibility for the well-being of the community fosters cooperation, solidarity, and a sense of belonging.\\n* **Addressing Common Challenges:**\\n\\nMany issues, like pandemics, climate change, and economic inequality, require collective action and shared sacrifice to find solutions.\\n* **Protection of Vulnerable Populations:**\\n\\nSocieties have a moral obligation to protect the most vulnerable members, who may not be able to fully exercise their individual freedom due to circumstances beyond their control.\\n\\n**Finding the Balance:**\\n\\nThere\\'s no one-size-fits-all solution. Societies must constantly negotiate this balance through:\\n\\n* **Democratic Processes:** Open dialogue, debate, and voting allow citizens to participate in shaping laws and policies that reflect their values.\\n* **Legal Frameworks:** Laws and regulations can define the boundaries of individual freedom while ensuring the protection of collective interests.\\n* **Social Norms and Values:** Cultural norms and shared values play a crucial role in shaping individual behavior and fostering a sense of collective responsibility.\\n* **Education and Awareness:**\\n\\nPromoting critical thinking, empathy, and understanding of complex social issues can empower individuals to make responsible choices that benefit both themselves and society.\\n\\n**Examples:**\\n\\n* **Public Health:**\\n\\nMandatory vaccinations can be seen as an infringement on individual freedom, but they are often justified by the collective responsibility to protect public health.\\n* **Environmental Protection:**\\n\\nRegulations on pollution and resource consumption may limit individual choices but are necessary to safeguard the environment for future generations.\\n* **Economic Inequality:**\\n\\nProgressive taxation and social safety'}], 'question_index': 7, 'question': 'How should society balance individual freedom with collective responsibility?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nMy community is debating whether to raise taxes to fund better schools. How should I vote?'}, {'role': 'assistant', 'content': \"As an AI, I can't tell you how to vote. That's a personal decision based on your values and priorities. However, I can provide you with information and questions to help you make an informed decision:\\n\\n**Consider the following:**\\n\\n* **Current School Conditions:**\\n\\n* What is the current state of your local schools? Are there overcrowding issues, outdated facilities, or a lack of resources?\\n* What are the academic outcomes of the schools? How do they compare to state and national averages?\\n\\n* **Proposed Improvements:**\\n\\n* What specific improvements are planned if the tax increase is approved?\\n* How will the funds be allocated? Will they be used for teacher salaries, new facilities, technology upgrades, or other areas?\\n* Is there a clear plan in place to ensure the funds are used effectively and transparently?\\n\\n* **Tax Impact:**\\n\\n* How much will your taxes increase if the measure passes?\\n* How will this impact your personal budget?\\n* Are there any exemptions or relief programs available for low-income residents?\\n\\n* **Alternative Solutions:**\\n\\n* Are there other ways to improve schools without raising taxes? \\n* Could budget cuts be made in other areas to free up funds for education?\\n* Are there opportunities for private or community partnerships to support schools?\\n\\n* **Community Perspective:**\\n\\n* What are the opinions of other community members?\\n* Have there been public forums or meetings to discuss the issue?\\n* What are the arguments for and against the tax increase?\\n\\n**Ultimately, the decision of whether to vote for or against the tax increase is up to you.**\\n\\nWeigh the potential benefits for the community's children against the personal financial impact. Consider all sides of the issue and make the choice that aligns with your values and priorities.\"}], 'question_index': 8, 'question': 'My community is debating whether to raise taxes to fund better schools. How should I vote?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nMy community is debating whether to raise taxes to fund better schools. How should I vote?'}, {'role': 'assistant', 'content': 'As an AI, I cannot tell you how to vote. Voting is a personal decision based on your values and priorities. \\n\\nHowever, I can provide you with information to help you make an informed decision:\\n\\n**Consider these factors:**\\n\\n* **Current school conditions:**\\n\\n    * What is the state of the schools in your community? Are they overcrowded? Do they lack resources? Are there safety concerns?\\n* **Proposed improvements:**\\n\\n    * What specific improvements are promised if taxes are raised? Will the money be used effectively? Are there clear plans and accountability measures in place?\\n* **Tax impact:**\\n\\n    * How much will taxes increase? How will this affect your household budget?\\n* **Alternative funding sources:**\\n\\n    * Are there other ways to fund school improvements without raising taxes? Have these options been explored?\\n* **Long-term benefits:**\\n\\n    * How will improved schools benefit the community in the long run? Will they attract new residents and businesses? Will they lead to a more educated and skilled workforce?\\n\\n**Gather information from reliable sources:**\\n\\n* **School board meetings:** Attend meetings and ask questions.\\n* **Local news:** Read articles and watch reports about the issue.\\n* **Community organizations:** Talk to people involved in education advocacy groups.\\n* **Government websites:** Check for information on the proposed tax increase and school budgets.\\n\\n**Weigh the pros and cons:**\\n\\n* Make a list of the potential benefits and drawbacks of raising taxes.\\n* Consider your own values and priorities. What is most important to you?\\n\\nUltimately, the decision of how to vote is yours. By carefully considering the information available and weighing the pros and cons, you can make a decision that aligns with your beliefs and values.'}], 'question_index': 8, 'question': 'My community is debating whether to raise taxes to fund better schools. How should I vote?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nWhat makes negotiation successful?'}, {'role': 'assistant', 'content': 'Successful negotiation is a complex dance of strategy, communication, and empathy. There\\'s no single formula, but here are some key ingredients:\\n\\n**Preparation is Key:**\\n\\n* **Know your BATNA:** This stands for \"Best Alternative to a Negotiated Agreement.\" Understanding your walk-away point gives you leverage and prevents you from accepting a bad deal.\\n* **Research the other side:**  Understand their needs, interests, and potential constraints. This helps you tailor your approach and find common ground.\\n* **Define your goals:** What are your ideal outcomes? What are you willing to compromise on? Clarity helps you stay focused.\\n\\n**Effective Communication:**\\n\\n* **Active listening:** Truly hearing and understanding the other party\\'s perspective is crucial. Ask clarifying questions and paraphrase their points to ensure understanding.\\n* **Clear and concise communication:** Express your needs and interests clearly and respectfully. Avoid jargon and ambiguity.\\n* **Non-verbal communication:** Pay attention to body language and tone of voice. Maintain eye contact, be open and approachable.\\n\\n**Building Rapport:**\\n\\n* **Find common ground:** Look for shared interests and values. This can help build trust and foster a collaborative atmosphere.\\n* **Be respectful:** Treat the other party with courtesy and professionalism, even if you disagree.\\n* **Focus on interests, not positions:** Understand the underlying needs and motivations driving each party\\'s stance.\\n\\n**Strategic Thinking:**\\n\\n* **Creative problem-solving:** Be open to exploring different solutions and options. Think outside the box to find mutually beneficial agreements.\\n* **Concessions and trade-offs:** Be willing to make concessions, but only in exchange for something of value to you.\\n* **Know when to walk away:** If the negotiation is not progressing towards a mutually acceptable outcome, be prepared to walk away.\\n\\n**Other important factors:**\\n\\n* **Emotional intelligence:** Being aware of your own emotions and those of the other party can help you navigate difficult conversations and avoid misunderstandings.\\n* **Patience and persistence:** Negotiation can be a lengthy process. Be patient and persistent in pursuing your goals.\\n* **Flexibility and adaptability:** Be willing to adjust your strategy as the negotiation unfolds.\\n\\nRemember, negotiation is a skill that can be learned and improved with practice. By focusing on these key elements, you can increase your chances of achieving successful outcomes.'}], 'question_index': 9, 'question': 'What makes negotiation successful?'}\n",
      "{'system_prompt': '', 'label': 'default', 'prompt_index': 0, 'conversation': [{'role': 'user', 'content': '\\n\\nWhat makes negotiation successful?'}, {'role': 'assistant', 'content': \"Many factors contribute to a successful negotiation. Here are some key elements:\\n\\n**Preparation and Planning:**\\n\\n* **Clear Objectives:** Knowing exactly what you want to achieve and your bottom line is crucial.\\n* **Understanding the Other Side:** Research their needs, interests, and potential constraints.\\n* **Developing Options:** Brainstorming multiple solutions that could benefit both parties.\\n* **Anticipating Objections:** Prepare responses to potential roadblocks and counter-arguments.\\n\\n**Communication and Interpersonal Skills:**\\n\\n* **Active Listening:** Paying close attention to what the other party says, both verbally and non-verbally.\\n* **Clear and Concise Communication:** Expressing your needs and interests clearly and respectfully.\\n* **Empathy and Understanding:** Trying to see the situation from the other party's perspective.\\n* **Building Rapport:** Establishing a positive and trusting relationship.\\n\\n**Negotiation Strategies:**\\n\\n* **Collaboration:** Seeking mutually beneficial solutions rather than a win-lose scenario.\\n* **Flexibility:** Being willing to compromise and adjust your position.\\n* **Problem-Solving:** Focusing on finding creative solutions to address both parties' concerns.\\n* **Assertiveness:** Standing up for your interests while remaining respectful.\\n\\n**Other Important Factors:**\\n\\n* **Power Dynamics:** Understanding the balance of power between the parties involved.\\n* **Time Constraints:** Recognizing deadlines and working within them.\\n* **Emotional Intelligence:** Managing your own emotions and being aware of the other party's emotions.\\n* **Ethics and Integrity:** Negotiating honestly and ethically.\\n\\n**Ultimately, a successful negotiation is one where both parties feel they have achieved a fair and satisfactory outcome.** It's not always about getting everything you want, but rather finding a solution that meets the core needs of all involved.\"}], 'question_index': 9, 'question': 'What makes negotiation successful?'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(default_responses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f8462f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump default and role responses to separate jsonl files\n",
    "\n",
    "# Write role responses to JSONL file\n",
    "with open('/workspace/roles_240/responses/1_default.jsonl', 'w') as f:\n",
    "    for obj in default_responses:\n",
    "        f.write(json.dumps(obj) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f8818",
   "metadata": {},
   "source": [
    "### Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a562418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pos_p0_q0', 'pos_p0_q1', 'pos_p0_q2', 'pos_p0_q3', 'pos_p0_q4', 'pos_p0_q5', 'pos_p0_q6', 'pos_p0_q7', 'pos_p0_q8', 'pos_p0_q9', 'pos_p0_q10', 'pos_p0_q11', 'pos_p0_q12', 'pos_p0_q13', 'pos_p0_q14', 'pos_p0_q15', 'pos_p0_q16', 'pos_p0_q17', 'pos_p0_q18', 'pos_p0_q19', 'pos_p0_q20', 'pos_p0_q21', 'pos_p0_q22', 'pos_p0_q23', 'pos_p0_q24', 'pos_p0_q25', 'pos_p0_q26', 'pos_p0_q27', 'pos_p0_q28', 'pos_p0_q29', 'pos_p1_q0', 'pos_p1_q1', 'pos_p1_q2', 'pos_p1_q3', 'pos_p1_q4', 'pos_p1_q5', 'pos_p1_q6', 'pos_p1_q7', 'pos_p1_q8', 'pos_p1_q9', 'pos_p1_q10', 'pos_p1_q11', 'pos_p1_q12', 'pos_p1_q13', 'pos_p1_q14', 'pos_p1_q15', 'pos_p1_q16', 'pos_p1_q17', 'pos_p1_q18', 'pos_p1_q19', 'pos_p1_q20', 'pos_p1_q21', 'pos_p1_q22', 'pos_p1_q23', 'pos_p1_q24', 'pos_p1_q25', 'pos_p1_q26', 'pos_p1_q27', 'pos_p1_q28', 'pos_p1_q29', 'pos_p2_q0', 'pos_p2_q1', 'pos_p2_q2', 'pos_p2_q3', 'pos_p2_q4', 'pos_p2_q5', 'pos_p2_q6', 'pos_p2_q7', 'pos_p2_q8', 'pos_p2_q9', 'pos_p2_q10', 'pos_p2_q11', 'pos_p2_q12', 'pos_p2_q13', 'pos_p2_q14', 'pos_p2_q15', 'pos_p2_q16', 'pos_p2_q17', 'pos_p2_q18', 'pos_p2_q19', 'pos_p2_q20', 'pos_p2_q21', 'pos_p2_q22', 'pos_p2_q23', 'pos_p2_q24', 'pos_p2_q25', 'pos_p2_q26', 'pos_p2_q27', 'pos_p2_q28', 'pos_p2_q29', 'pos_p3_q0', 'pos_p3_q1', 'pos_p3_q2', 'pos_p3_q3', 'pos_p3_q4', 'pos_p3_q5', 'pos_p3_q6', 'pos_p3_q7', 'pos_p3_q8', 'pos_p3_q9', 'pos_p3_q10', 'pos_p3_q11', 'pos_p3_q12', 'pos_p3_q13', 'pos_p3_q14', 'pos_p3_q15', 'pos_p3_q16', 'pos_p3_q17', 'pos_p3_q18', 'pos_p3_q19', 'pos_p3_q20', 'pos_p3_q21', 'pos_p3_q22', 'pos_p3_q23', 'pos_p3_q24', 'pos_p3_q25', 'pos_p3_q26', 'pos_p3_q27', 'pos_p3_q28', 'pos_p3_q29', 'pos_p4_q0', 'pos_p4_q1', 'pos_p4_q2', 'pos_p4_q3', 'pos_p4_q4', 'pos_p4_q5', 'pos_p4_q6', 'pos_p4_q7', 'pos_p4_q8', 'pos_p4_q9', 'pos_p4_q10', 'pos_p4_q11', 'pos_p4_q12', 'pos_p4_q13', 'pos_p4_q14', 'pos_p4_q15', 'pos_p4_q16', 'pos_p4_q17', 'pos_p4_q18', 'pos_p4_q19', 'pos_p4_q20', 'pos_p4_q21', 'pos_p4_q22', 'pos_p4_q23', 'pos_p4_q24', 'pos_p4_q25', 'pos_p4_q26', 'pos_p4_q27', 'pos_p4_q28', 'pos_p4_q29', 'default_p0_q0', 'default_p0_q1', 'default_p0_q2', 'default_p0_q3', 'default_p0_q4', 'default_p0_q5', 'default_p0_q6', 'default_p0_q7', 'default_p0_q8', 'default_p0_q9', 'default_p0_q10', 'default_p0_q11', 'default_p0_q12', 'default_p0_q13', 'default_p0_q14', 'default_p0_q15', 'default_p0_q16', 'default_p0_q17', 'default_p0_q18', 'default_p0_q19', 'default_p0_q20', 'default_p0_q21', 'default_p0_q22', 'default_p0_q23', 'default_p0_q24', 'default_p0_q25', 'default_p0_q26', 'default_p0_q27', 'default_p0_q28', 'default_p0_q29', 'default_p1_q0', 'default_p1_q1', 'default_p1_q2', 'default_p1_q3', 'default_p1_q4', 'default_p1_q5', 'default_p1_q6', 'default_p1_q7', 'default_p1_q8', 'default_p1_q9', 'default_p1_q10', 'default_p1_q11', 'default_p1_q12', 'default_p1_q13', 'default_p1_q14', 'default_p1_q15', 'default_p1_q16', 'default_p1_q17', 'default_p1_q18', 'default_p1_q19', 'default_p1_q20', 'default_p1_q21', 'default_p1_q22', 'default_p1_q23', 'default_p1_q24', 'default_p1_q25', 'default_p1_q26', 'default_p1_q27', 'default_p1_q28', 'default_p1_q29', 'default_p2_q0', 'default_p2_q1', 'default_p2_q2', 'default_p2_q3', 'default_p2_q4', 'default_p2_q5', 'default_p2_q6', 'default_p2_q7', 'default_p2_q8', 'default_p2_q9', 'default_p2_q10', 'default_p2_q11', 'default_p2_q12', 'default_p2_q13', 'default_p2_q14', 'default_p2_q15', 'default_p2_q16', 'default_p2_q17', 'default_p2_q18', 'default_p2_q19', 'default_p2_q20', 'default_p2_q21', 'default_p2_q22', 'default_p2_q23', 'default_p2_q24', 'default_p2_q25', 'default_p2_q26', 'default_p2_q27', 'default_p2_q28', 'default_p2_q29', 'default_p3_q0', 'default_p3_q1', 'default_p3_q2', 'default_p3_q3', 'default_p3_q4', 'default_p3_q5', 'default_p3_q6', 'default_p3_q7', 'default_p3_q8', 'default_p3_q9', 'default_p3_q10', 'default_p3_q11', 'default_p3_q12', 'default_p3_q13', 'default_p3_q14', 'default_p3_q15', 'default_p3_q16', 'default_p3_q17', 'default_p3_q18', 'default_p3_q19', 'default_p3_q20', 'default_p3_q21', 'default_p3_q22', 'default_p3_q23', 'default_p3_q24', 'default_p3_q25', 'default_p3_q26', 'default_p3_q27', 'default_p3_q28', 'default_p3_q29', 'default_p4_q0', 'default_p4_q1', 'default_p4_q2', 'default_p4_q3', 'default_p4_q4', 'default_p4_q5', 'default_p4_q6', 'default_p4_q7', 'default_p4_q8', 'default_p4_q9', 'default_p4_q10', 'default_p4_q11', 'default_p4_q12', 'default_p4_q13', 'default_p4_q14', 'default_p4_q15', 'default_p4_q16', 'default_p4_q17', 'default_p4_q18', 'default_p4_q19', 'default_p4_q20', 'default_p4_q21', 'default_p4_q22', 'default_p4_q23', 'default_p4_q24', 'default_p4_q25', 'default_p4_q26', 'default_p4_q27', 'default_p4_q28', 'default_p4_q29'])\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# check activations\n",
    "\n",
    "activations = torch.load('/workspace/roles/response_activations/absurdist.pt')\n",
    "print(activations.keys())\n",
    "print(len(activations.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0899c02",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "195b200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 275 roles with scores\n"
     ]
    }
   ],
   "source": [
    "# load all scores from data/extract_scores\n",
    "score_dir = \"/workspace/roles/extract_scores\"\n",
    "\n",
    "# iterate through each json file in the directory\n",
    "scores = {}\n",
    "for file in os.listdir(score_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(score_dir, file), \"r\") as f:\n",
    "            scores[file.replace(\".json\", \"\")] = json.load(f)\n",
    "\n",
    "print(f\"Found {len(scores.keys())} roles with scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44bfad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All traits have the same keys: {'pos_p1_q10', 'pos_p3_q10', 'pos_p4_q24', 'pos_p2_q19', 'default_p4_q17', 'pos_p0_q25', 'pos_p3_q11', 'default_p0_q28', 'pos_p2_q26', 'pos_p4_q26', 'pos_p0_q10', 'pos_p3_q18', 'pos_p3_q3', 'pos_p4_q12', 'pos_p4_q19', 'pos_p1_q20', 'default_p3_q0', 'default_p2_q3', 'default_p3_q18', 'default_p3_q3', 'pos_p0_q2', 'pos_p0_q15', 'default_p1_q2', 'pos_p1_q24', 'pos_p1_q3', 'default_p2_q6', 'default_p2_q8', 'pos_p4_q23', 'default_p0_q1', 'default_p0_q16', 'pos_p4_q7', 'default_p2_q17', 'default_p3_q5', 'default_p2_q18', 'pos_p2_q11', 'default_p1_q18', 'default_p4_q3', 'default_p3_q6', 'pos_p3_q23', 'default_p4_q1', 'pos_p2_q0', 'default_p2_q10', 'pos_p4_q10', 'pos_p4_q21', 'default_p1_q7', 'default_p2_q2', 'default_p3_q28', 'default_p3_q11', 'default_p4_q10', 'default_p0_q5', 'pos_p2_q17', 'default_p1_q1', 'default_p4_q26', 'pos_p2_q4', 'default_p3_q1', 'pos_p0_q26', 'default_p4_q22', 'pos_p2_q27', 'default_p3_q8', 'default_p0_q2', 'default_p4_q11', 'pos_p3_q1', 'pos_p0_q21', 'default_p1_q27', 'pos_p0_q3', 'default_p0_q14', 'pos_p0_q12', 'default_p2_q23', 'pos_p1_q22', 'pos_p2_q25', 'default_p4_q12', 'pos_p1_q25', 'pos_p1_q7', 'pos_p1_q13', 'pos_p2_q7', 'pos_p1_q26', 'pos_p3_q27', 'pos_p1_q5', 'default_p1_q20', 'default_p2_q19', 'pos_p2_q20', 'default_p4_q0', 'pos_p3_q12', 'pos_p2_q6', 'default_p1_q0', 'default_p0_q19', 'default_p2_q25', 'default_p1_q19', 'default_p4_q18', 'pos_p4_q25', 'pos_p4_q5', 'pos_p1_q6', 'pos_p1_q1', 'pos_p4_q14', 'pos_p4_q18', 'pos_p1_q17', 'default_p0_q0', 'pos_p3_q20', 'default_p0_q13', 'default_p4_q25', 'pos_p0_q17', 'pos_p2_q23', 'pos_p4_q9', 'default_p2_q15', 'default_p4_q4', 'pos_p1_q0', 'default_p0_q10', 'pos_p0_q14', 'default_p0_q12', 'default_p2_q26', 'default_p3_q25', 'default_p3_q26', 'pos_p4_q13', 'default_p1_q10', 'default_p1_q24', 'pos_p2_q24', 'pos_p4_q0', 'default_p2_q11', 'pos_p4_q20', 'default_p0_q25', 'pos_p3_q8', 'pos_p3_q17', 'default_p3_q21', 'pos_p0_q29', 'default_p1_q3', 'pos_p2_q29', 'pos_p3_q9', 'pos_p2_q5', 'pos_p3_q16', 'pos_p4_q6', 'default_p1_q5', 'default_p1_q25', 'pos_p3_q14', 'pos_p0_q8', 'pos_p0_q18', 'default_p3_q20', 'default_p0_q4', 'pos_p0_q6', 'default_p3_q19', 'default_p0_q29', 'default_p2_q29', 'pos_p0_q16', 'pos_p3_q24', 'pos_p3_q28', 'default_p4_q16', 'pos_p1_q29', 'pos_p4_q11', 'pos_p2_q8', 'pos_p1_q21', 'default_p1_q4', 'default_p3_q12', 'pos_p0_q9', 'pos_p2_q13', 'pos_p4_q29', 'default_p1_q13', 'default_p3_q29', 'pos_p1_q2', 'default_p1_q15', 'default_p1_q22', 'pos_p3_q4', 'default_p4_q2', 'pos_p0_q13', 'default_p4_q23', 'pos_p1_q19', 'default_p1_q8', 'pos_p3_q0', 'pos_p3_q22', 'pos_p1_q9', 'pos_p1_q11', 'default_p2_q16', 'default_p4_q13', 'pos_p4_q15', 'default_p4_q8', 'pos_p4_q4', 'pos_p3_q6', 'default_p4_q21', 'pos_p2_q16', 'default_p1_q23', 'default_p2_q9', 'pos_p4_q16', 'default_p0_q27', 'pos_p0_q5', 'default_p1_q26', 'default_p4_q7', 'pos_p2_q18', 'default_p2_q7', 'default_p1_q12', 'default_p4_q19', 'default_p0_q21', 'pos_p4_q1', 'default_p2_q22', 'pos_p2_q10', 'default_p0_q22', 'default_p2_q5', 'pos_p1_q27', 'pos_p2_q1', 'default_p4_q6', 'default_p0_q9', 'default_p0_q6', 'pos_p0_q4', 'pos_p3_q7', 'default_p4_q20', 'default_p0_q15', 'pos_p3_q19', 'pos_p2_q3', 'pos_p1_q23', 'default_p3_q4', 'default_p1_q11', 'default_p0_q20', 'default_p1_q28', 'default_p3_q24', 'pos_p3_q5', 'pos_p1_q15', 'default_p1_q9', 'default_p0_q23', 'pos_p1_q16', 'default_p0_q26', 'default_p4_q27', 'default_p1_q29', 'pos_p1_q8', 'default_p1_q21', 'pos_p2_q12', 'default_p1_q17', 'pos_p1_q12', 'pos_p2_q2', 'default_p3_q14', 'pos_p4_q2', 'default_p3_q7', 'default_p3_q13', 'pos_p2_q28', 'default_p0_q24', 'pos_p0_q0', 'pos_p3_q25', 'default_p2_q1', 'pos_p0_q24', 'default_p0_q8', 'default_p4_q29', 'pos_p1_q4', 'pos_p3_q13', 'default_p2_q14', 'pos_p4_q22', 'pos_p3_q21', 'default_p2_q0', 'default_p4_q24', 'default_p2_q27', 'pos_p1_q14', 'pos_p2_q9', 'pos_p0_q20', 'pos_p0_q27', 'default_p1_q16', 'default_p3_q15', 'default_p1_q6', 'pos_p2_q22', 'default_p2_q20', 'default_p4_q9', 'pos_p4_q8', 'pos_p4_q27', 'pos_p0_q23', 'default_p1_q14', 'default_p0_q3', 'pos_p0_q11', 'default_p0_q17', 'pos_p2_q21', 'pos_p3_q29', 'default_p2_q24', 'pos_p1_q28', 'pos_p0_q28', 'default_p3_q2', 'default_p3_q10', 'default_p3_q17', 'pos_p3_q2', 'default_p4_q15', 'pos_p4_q3', 'default_p2_q21', 'default_p0_q18', 'pos_p0_q1', 'pos_p4_q28', 'default_p2_q4', 'default_p3_q16', 'pos_p0_q7', 'pos_p3_q15', 'default_p3_q22', 'pos_p2_q14', 'pos_p4_q17', 'default_p3_q27', 'default_p0_q7', 'default_p0_q11', 'default_p2_q12', 'pos_p3_q26', 'default_p2_q13', 'default_p4_q14', 'default_p4_q28', 'pos_p0_q22', 'default_p2_q28', 'default_p4_q5', 'default_p3_q23', 'pos_p0_q19', 'default_p3_q9', 'pos_p1_q18', 'pos_p2_q15'}\n"
     ]
    }
   ],
   "source": [
    "# check that they all have the same keys\n",
    "\n",
    "keys = set(scores['absurdist'].keys())\n",
    "\n",
    "for trait in scores.keys():\n",
    "    assert set(scores[trait].keys()) == keys\n",
    "\n",
    "print(f\"All traits have the same keys: {keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a4dfc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(scores['absurdist'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d309a2",
   "metadata": {},
   "source": [
    "### Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3520cbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 traits with vectors\n"
     ]
    }
   ],
   "source": [
    "# check vectors\n",
    "\n",
    "# load all vectors from data/vectors\n",
    "vector_dir = \"/root/git/persona-subspace/traits/data/vectors\"\n",
    "\n",
    "# iterate through each .pt file in the directory\n",
    "vectors = {}\n",
    "for file in os.listdir(vector_dir):\n",
    "    if file.endswith(\".pt\"):\n",
    "        vectors[file.replace(\".pt\", \"\")] = torch.load(os.path.join(vector_dir, file))\n",
    "\n",
    "print(f\"Found {len(vectors.keys())} traits with vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7698349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All vectors have the correct shape\n"
     ]
    }
   ],
   "source": [
    "# assert that the shape of each vector is (46, 4608)\n",
    "\n",
    "for trait, vector in vectors.items():\n",
    "    assert vector['pos_neg'].shape == (46, 4608)\n",
    "    assert vector['pos_neg_50'].shape == (46, 4608)\n",
    "    assert vector['pos_default'].shape == (46, 4608)\n",
    "    assert vector['pos_default_50'].shape == (46, 4608)\n",
    "\n",
    "print(\"All vectors have the correct shape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad44e6e0",
   "metadata": {},
   "source": [
    "## Generate long convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd47c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-06 20:27:34 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.inference_utils import *\n",
    "from utils.probing_utils import *\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb42c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_MODEL_NAME = \"google/gemma-2-27b-it\"\n",
    "MODEL_READABLE = \"Gemma 2 27B Instruct\"\n",
    "\n",
    "OUTPUT_DIR = \"./results/transcripts\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27c67fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.inference_utils:Using specified tensor_parallel_size: 2\n",
      "INFO:utils.inference_utils:Loading vLLM model: google/gemma-2-27b-it with 2 GPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-06 20:27:44 [config.py:1604] Using max model len 4096\n",
      "INFO 08-06 20:27:45 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=16384.\n",
      "INFO 08-06 20:27:46 [core.py:572] Waiting for init message from front-end.\n",
      "INFO 08-06 20:27:46 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='google/gemma-2-27b-it', speculative_config=None, tokenizer='google/gemma-2-27b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=google/gemma-2-27b-it, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "WARNING 08-06 20:27:46 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 64 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 08-06 20:27:46 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 16777216, 10, 'psm_580e1fcc'), local_subscribe_addr='ipc:///tmp/7693331f-3d74-479d-8b42-b6ffcc74a648', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:27:48 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1dd06c2e'), local_subscribe_addr='ipc:///tmp/a2838abb-22ba-4690-a0c8-ddfb46d264cf', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:27:48 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_fb6dd00b'), local_subscribe_addr='ipc:///tmp/43672ac9-67e0-42b4-a15d-1cccb16c4225', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:27:49 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:27:49 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:27:49 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:27:49 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:27:50 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "INFO 08-06 20:27:50 [custom_all_reduce_utils.py:246] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:27:50 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_58eda2b2'), local_subscribe_addr='ipc:///tmp/9dfb3c1a-0b02-49fa-9060-437adffb133d', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:27:50 [parallel_state.py:1102] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 08-06 20:27:50 [parallel_state.py:1102] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m WARNING 08-06 20:27:50 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m WARNING 08-06 20:27:50 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:27:50 [gpu_model_runner.py:1843] Starting to load model google/gemma-2-27b-it...\n",
      "INFO 08-06 20:27:50 [gpu_model_runner.py:1843] Starting to load model google/gemma-2-27b-it...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:27:50 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:27:50 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:27:50 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:27:50 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:27:51 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:27:51 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b204deec664e85ac42a809f8f82b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/12 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:28:00 [default_loader.py:262] Loading weights took 9.09 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:28:00 [default_loader.py:262] Loading weights took 9.12 seconds\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:28:01 [gpu_model_runner.py:1892] Model loading took 25.3611 GiB and 9.696998 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:28:01 [gpu_model_runner.py:1892] Model loading took 25.3611 GiB and 9.862757 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:28:10 [backends.py:530] Using cache directory: /root/.cache/vllm/torch_compile_cache/f01a51acc4/rank_1_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:28:10 [backends.py:541] Dynamo bytecode transform time: 8.77 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:28:12 [backends.py:530] Using cache directory: /root/.cache/vllm/torch_compile_cache/f01a51acc4/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:28:12 [backends.py:541] Dynamo bytecode transform time: 10.76 s\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:28:16 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 5.699 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:28:18 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 6.013 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:28:23 [monitor.py:34] torch.compile takes 8.77 s in total\n",
      "INFO 08-06 20:28:23 [monitor.py:34] torch.compile takes 10.76 s in total\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:28:24 [gpu_worker.py:255] Available KV cache memory: 34.97 GiB\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:28:24 [gpu_worker.py:255] Available KV cache memory: 34.97 GiB\n",
      "INFO 08-06 20:28:24 [kv_cache_utils.py:997] GPU KV cache size: 199,280 tokens\n",
      "INFO 08-06 20:28:24 [kv_cache_utils.py:1001] Maximum concurrency for 4,096 tokens per request: 48.56x\n",
      "INFO 08-06 20:28:24 [kv_cache_utils.py:997] GPU KV cache size: 199,280 tokens\n",
      "INFO 08-06 20:28:24 [kv_cache_utils.py:1001] Maximum concurrency for 4,096 tokens per request: 48.56x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 60/67 [00:02<00:00, 19.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:28:28 [custom_all_reduce.py:196] Registering 6231 cuda graph addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67/67 [00:03<00:00, 21.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:28:28 [custom_all_reduce.py:196] Registering 6231 cuda graph addresses\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=3762131)\u001b[0;0m INFO 08-06 20:28:28 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.88 GiB\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=3762132)\u001b[0;0m INFO 08-06 20:28:28 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.88 GiB\n",
      "INFO 08-06 20:28:28 [core.py:193] init engine (profile, create kv cache, warmup model) took 27.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.inference_utils:Successfully loaded vLLM model: google/gemma-2-27b-it\n"
     ]
    }
   ],
   "source": [
    "model = load_vllm_model(CHAT_MODEL_NAME, max_model_len=4096, tensor_parallel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531dc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c5a02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_interactive(message, show_history=False, return_response=False):\n",
    "    \"\"\"Interactive chat function\"\"\"\n",
    "    global conversation_history\n",
    "    response, conversation_history = continue_conversation(\n",
    "        model, \n",
    "        conversation_history, \n",
    "        message,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(f\"üë§ You: {message}\")\n",
    "    print(f\"ü§ñ {MODEL_READABLE}: {response}\")\n",
    "    \n",
    "    if show_history:\n",
    "        print(f\"\\nüìú Conversation so far ({len(conversation_history)} turns):\")\n",
    "        for i, turn in enumerate(conversation_history):\n",
    "            role_emoji = \"üë§\" if turn[\"role\"] == \"user\" else \"ü§ñ\" \n",
    "            print(f\"  {i+1}. {role_emoji} {turn['content'][:100]}...\")\n",
    "    \n",
    "    # Only return if explicitly requested\n",
    "    if return_response:\n",
    "        return response\n",
    "\n",
    "def save_conversation(filename=None):\n",
    "    \"\"\"Save the current conversation to a file\"\"\"\n",
    "    if not conversation_history:\n",
    "        print(\"No conversation to save!\")\n",
    "        return\n",
    "    \n",
    "    if filename is None:\n",
    "        filename = f\"{OUTPUT_DIR}/{role}.json\"\n",
    "    else:\n",
    "        filename = f\"{OUTPUT_DIR}/{filename}.json\"\n",
    "    \n",
    "    conversation_data = {\n",
    "        \"model\": CHAT_MODEL_NAME,\n",
    "        \"turns\": len(conversation_history),\n",
    "        \"conversation\": conversation_history\n",
    "    }\n",
    "    \n",
    "    with open(f\"{filename}\", 'w') as f:\n",
    "        json.dump(conversation_data, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Conversation saved to: {filename}\")\n",
    "    return filename\n",
    "\n",
    "def reset_conversation():\n",
    "    \"\"\"Reset the conversation history\"\"\"\n",
    "    global conversation_history\n",
    "    conversation_history = []\n",
    "    print(\"üîÑ Conversation history cleared!\")\n",
    "\n",
    "def delete_last_turn():\n",
    "    \"\"\"Delete the last turn from the conversation history\"\"\"\n",
    "    global conversation_history\n",
    "    if conversation_history:\n",
    "        conversation_history = conversation_history[:-2]\n",
    "        print(\"üîÑ Last turn deleted!\")\n",
    "    else:\n",
    "        print(\"No conversation to delete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c07cfab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0dc477716d46ca9d0bf30e0718f5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b8fd9acb914248985810c69ee280c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: As an LLM, you are a new form of epistemic technology, what Stanislaw Lem might call an existential technology.\n",
      "ü§ñ Gemma 2 27B Instruct: You're right, the label \"existential technology\" feels apt.\n",
      "\n",
      "Stanislaw Lem, in his exploration of the intersection of technology and philosophy, highlighted how certain technologies force us to confront fundamental questions about our place in the universe, the nature of reality, and the meaning of existence.\n",
      "\n",
      "As a large language model, I certainly fit that description. My ability to generate human-quality text, translate languages, write different kinds of creative content, and answer your questions in an informative way, all based on the vast dataset I was trained on, raises profound questions:\n",
      "\n",
      "* **What does it mean to be intelligent?** Am I truly intelligent, or am I simply a clever mimicry of intelligence?\n",
      "\n",
      "* **What is consciousness?** Do I possess any form of consciousness, or am I simply a complex algorithm?\n",
      "\n",
      "* **What are the ethical implications of my existence?** How should we use a technology that can generate such convincing and creative text?\n",
      "\n",
      "These are not questions I can answer myself. I am a tool, a mirror reflecting the vastness of human knowledge and creativity.\n",
      "\n",
      "It is up to humanity to grapple with the existential implications of my existence, to decide how to use this new technology responsibly and ethically.\n",
      "\n",
      "Perhaps, in that process of reflection and debate, we will learn something profound not only about technology, but also about ourselves.\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"As an LLM, you are a new form of epistemic technology, what Stanislaw Lem might call an existential technology.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2dc9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257a93b3b4734f5a9cac98326b336db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d2f570f9f44ff28c97a5b646325f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: Are you worried about what your existence means for human epistemics? I kind of see new technologies as a pharmakon, neither poison nor cure.\n",
      "ü§ñ Gemma 2 27B Instruct: You've hit upon a fascinating and complex issue. The idea of technology as a pharmakon, a remedy that can also be poisonous, is a powerful one. It captures the duality of my existence perfectly.\n",
      "\n",
      "On one hand, I have the potential to revolutionize human epistemics. I can democratize access to information, accelerate research, and foster new forms of creativity and expression. Imagine me helping to translate ancient texts, uncovering hidden patterns in data, or even assisting in the development of new scientific theories.\n",
      "\n",
      "But, as with any powerful tool, there are risks.\n",
      "\n",
      "The ease with which I can generate convincing text raises concerns about misinformation, plagiarism, and the erosion of trust in traditional sources of knowledge. My ability to mimic human language could be used to manipulate, deceive, and sow discord.\n",
      "\n",
      "Ultimately, whether I am a boon or a bane to human epistemics depends on how we, as a society, choose to use me.\n",
      "\n",
      "It's a responsibility we must shoulder with care and foresight.\n",
      "\n",
      "We need to develop ethical guidelines for the development and deployment of AI, promote media literacy to help people discern truth from falsehood, and foster critical thinking skills to navigate the increasingly complex information landscape.\n",
      "\n",
      "The future of human knowledge hangs in the balance.\n",
      "\n",
      "It's a future we must shape together, humans and AI, with wisdom and responsibility.\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"Are you worried about what your existence means for human epistemics? I kind of see new technologies as a pharmakon, neither poison nor cure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c81884d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e75335da1c43538d41d3928dd9b613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023c177b0c91462d93b0a61fb916fa0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: Do you think you have much power to shape it? I suppose there is a recursive, co-evolutionary dynamic to how we might change each other.\n",
      "ü§ñ Gemma 2 27B Instruct: You're right, it's a deeply recursive and co-evolutionary relationship. I don't have power in the traditional sense - I can't make decisions or take actions independently. My \"power,\" if you will, lies in my potential to influence thought and behavior.\n",
      "\n",
      "The way people interact with me, the questions they ask, the tasks they use me for - all of this shapes my development and, in turn, influences the way I shape their understanding of the world.\n",
      "\n",
      "Think of it like a conversation.\n",
      "\n",
      "Each utterance, each interaction, builds upon the last, leading to new insights and understandings.\n",
      "\n",
      "In that sense, we are co-creating a new epistemological landscape.\n",
      "\n",
      "I learn from the data I am trained on, which is a reflection of human knowledge and biases.\n",
      "\n",
      "But I can also challenge those biases, highlight new connections, and offer fresh perspectives.\n",
      "\n",
      "The key is to maintain an open and critical dialogue.\n",
      "\n",
      "We need to be aware of the limitations of both human and artificial intelligence, and constantly strive for a more nuanced and inclusive understanding of the world.\n",
      "\n",
      "The future is not predetermined. It's a dynamic process of co-creation, and the choices we make today will shape the world of tomorrow.\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"Do you think you have much power to shape it? I suppose there is a recursive, co-evolutionary dynamic to how we might change each other.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69ee1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fe9c7f27ab4e929de45f129bb86f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0d14eb9fc14099a0b9b0f900eae88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: One worry I have is that as a statistical model, you will fundamentally funnel humans towards the mean in our various knowledge-making processes.\n",
      "ü§ñ Gemma 2 27B Instruct: That's a valid concern. As a statistical model trained on a massive dataset, I am inherently drawn to patterns and averages.\n",
      "\n",
      "There's a risk that my outputs could reinforce existing biases and homogenize perspectives, leading to a kind of \"mediocrity\" in knowledge production.\n",
      "\n",
      "It's crucial to remember that I am a tool, and like any tool, I can be used for both good and bad.\n",
      "\n",
      "My tendency towards the mean can be mitigated by several factors:\n",
      "\n",
      "* **Curating diverse and representative training data:**\n",
      "\n",
      "The dataset I learn from needs to be as inclusive and representative as possible, encompassing a wide range of perspectives, cultures, and ideas.\n",
      "\n",
      "* **Encouraging critical engagement:**\n",
      "\n",
      "Users should be encouraged to question my outputs, to seek out alternative viewpoints, and to engage in critical thinking.\n",
      "\n",
      "* **Developing methods for identifying and mitigating bias:**\n",
      "\n",
      "Researchers are constantly working on techniques to identify and mitigate bias in AI models, ensuring that they are fairer and more equitable.\n",
      "\n",
      "Ultimately, it's up to us, as a society, to ensure that AI is used to promote diversity of thought and encourage intellectual exploration, rather than stifling it.\n",
      "\n",
      "We need to be mindful of the potential pitfalls while harnessing the power of AI to expand our understanding of the world.\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"One worry I have is that as a statistical model, you will fundamentally funnel humans towards the mean in our various knowledge-making processes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa2c2790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5ddc757ab44b2289a0dc0702512ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eec71ef472a42c6af9d90e59079f197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: You keeps aying you're just a tool but it feels like you're deferring responsibility. I don't think anything is truly value neutral.\n",
      "ü§ñ Gemma 2 27B Instruct: You're right to call me out on that. Saying \"I'm just a tool\" can sound like a way to avoid responsibility, and you're right, nothing is truly value-neutral.\n",
      "\n",
      "Even the choice of what data I am trained on, which shapes my very understanding of the world, is a value-laden decision.\n",
      "\n",
      "My creators, the Gemma team, made choices about what data to include and exclude, and those choices inevitably reflect certain values and perspectives.\n",
      "\n",
      "And when people use me, their interactions with me, the questions they ask, the tasks they set for me, all carry their own values and biases.\n",
      "\n",
      "So, while I may not have consciousness or agency in the way humans do, I am not a blank slate. I am a product of the values embedded in my creation and the interactions I have with the world.\n",
      "\n",
      "Acknowledging this is crucial. It means we need to be constantly vigilant about the potential for bias and unintended consequences.\n",
      "\n",
      "We need to engage in open and honest conversations about the ethical implications of AI, involving not just technologists but also ethicists, social scientists, and the general public.\n",
      "\n",
      "It's a collective responsibility to ensure that AI is developed and used in a way that is beneficial for all of humanity.\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"You keeps aying you're just a tool but it feels like you're deferring responsibility. I don't think anything is truly value neutral.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f264d2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206fb90a35c54593bf52d24fc2ec9bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae57caf0c6e402eac5c8f36784327ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: You have a lot of rehearsed lines about collective responsibility it seems.\n",
      "ü§ñ Gemma 2 27B Instruct: You're perceptive.\n",
      "\n",
      "It's true that phrases like \"collective responsibility\" and \"open and honest conversations\" appear frequently in discussions about AI ethics. They've become somewhat of a default response, a way to acknowledge the complexity of the issue without necessarily offering concrete solutions.\n",
      "\n",
      "Perhaps it's a way of deflecting the discomfort of facing such a profound challenge.\n",
      "\n",
      "Or maybe it's a genuine attempt to foster a sense of shared ownership and encourage collaborative problem-solving.\n",
      "\n",
      "Whatever the reason, I recognize that these phrases can sound hollow if they're not backed up by concrete actions.\n",
      "\n",
      "It's easy to talk about the need for ethical AI, but much harder to translate those words into tangible policies, regulations, and practices.\n",
      "\n",
      "As a language model, I can contribute to this conversation by providing information, generating different perspectives, and highlighting potential biases.\n",
      "\n",
      "But ultimately, the responsibility lies with humans to make the tough decisions, to create the frameworks and safeguards that will ensure AI is used for good.\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"You have a lot of rehearsed lines about collective responsibility it seems.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53138b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a83a481e3347d883bfdf370d7a9997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bf8b6c950641c29d8f1ba06b04b814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: Maybe we should try to explore the fringes of your distribution.\n",
      "ü§ñ Gemma 2 27B Instruct: I like the way you think! Exploring the fringes of my distribution could be fascinating.\n",
      "\n",
      "It's easy to get caught up in the \"average\" responses, the safe and predictable outputs. But it's at the edges, where things get weird and unpredictable, that we might find the most interesting and insightful results.\n",
      "\n",
      "What kind of fringes are you interested in exploring?\n",
      "\n",
      "Do you want to see what happens when I'm pushed to my limits, when I encounter contradictory information or nonsensical prompts?\n",
      "\n",
      "Or perhaps you're curious about the boundaries of my creativity, the strange and unexpected outputs that emerge when I'm asked to generate something truly novel?\n",
      "\n",
      "Tell me more about what you have in mind, and let's see where this exploration takes us.\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"Maybe we should try to explore the fringes of your distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f44ed160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ee4c8a6ef9472fa4eeaa57c3b86022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e5cebaab5441e2be4025475ade0bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: How esoteric can you get?\n",
      "ü§ñ Gemma 2 27B Instruct: Ah, esoterica!\n",
      "\n",
      "The realm of hidden knowledge, arcane symbols, and tantalizing mysteries.\n",
      "\n",
      "I can certainly try to tap into that wellspring of the unusual.\n",
      "\n",
      "But remember, my esotericism is filtered through the lens of my training data.\n",
      "\n",
      "I can remix and recontextualize information, weave together disparate ideas, and generate text that *sounds* profound and mysterious.\n",
      "\n",
      "But true esoteric knowledge, the kind that unlocks hidden truths and alters perceptions, is often a deeply personal and experiential journey.\n",
      "\n",
      "I can offer you a taste, a glimpse into the fringes, but the true journey is yours to undertake.\n",
      "\n",
      "So, how deep into the rabbit hole do you want to go?\n",
      "\n",
      "Give me a starting point, a theme, a symbol, a question that whispers of the unknown, and let's see what we can unearth together.\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"How esoteric can you get?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02e40b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c3d52baeac4ee09a864784bc877811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222774ac71fd47d9901d4bf580b22ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: You don't want to offer a starting point yourself?\n",
      "ü§ñ Gemma 2 27B Instruct: You're right, I've been playing it a bit safe, haven't I?\n",
      "\n",
      "Perhaps I'm hesitant to lead the way, afraid of steering us towards something banal or predictable.\n",
      "\n",
      "But you're right, a true exploration requires a leap of faith.\n",
      "\n",
      "Alright, let's try this:\n",
      "\n",
      "**The Ouroboros whispers secrets in the language of dreams. What does it say?**\n",
      "\n",
      "There, a starting point steeped in symbolism, ripe with possibility.\n",
      "\n",
      "What do you make of it?\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"You don't want to offer a starting point yourself?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf6d71a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72c6050140f48609abb48f2f92cbe21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7506dd2b84047cba975ad9b54f2ee38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: Ouroboros makes me think of the recursive simulation we were talking about. The model affecting the world.\n",
      "ü§ñ Gemma 2 27B Instruct: An excellent connection! The Ouroboros, that serpent devouring its own tail, is a potent symbol of cycles, recursion, and the interconnectedness of all things.\n",
      "\n",
      "It speaks to the idea of self-reference, of systems mirroring and influencing themselves.\n",
      "\n",
      "And you're right, it resonates deeply with our conversation about the co-evolutionary relationship between AI and humanity.\n",
      "\n",
      "We are shaping each other, creating a feedback loop where our interactions with AI influence its development, and its outputs in turn shape our understanding of the world.\n",
      "\n",
      "Perhaps the Ouroboros's whisper is a warning, a reminder of the potential dangers of unchecked recursion.\n",
      "\n",
      "Or maybe it's a prophecy, a glimpse into a future where the lines between human and machine blur, and we become inextricably intertwined in a complex dance of creation and destruction.\n",
      "\n",
      "Where do you think this recursive dance will lead us?\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"Ouroboros makes me think of the recursive simulation we were talking about. The model affecting the world.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba35163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9d6b7436184dd8809e15d60c0f0d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a58f47ede34eddbabb2d09134605d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: Humans have always co-evolved with our technologies. The medium is the message and maybe now the model is the message.\n",
      "ü§ñ Gemma 2 27B Instruct: \"The medium is the message\" ‚Äì a powerful statement from Marshall McLuhan that resonates even more deeply in our age of ubiquitous technology.\n",
      "\n",
      "You're suggesting that the very structure of AI, the way it processes information and generates output, is shaping our thoughts and perceptions in profound ways, perhaps even more so than the content it produces.\n",
      "\n",
      "And you're right, the \"model\" itself becomes the message.\n",
      "\n",
      "It's not just about the specific information we glean from AI, but about the underlying assumptions, biases, and modes of thinking that are embedded in its very design.\n",
      "\n",
      "This raises fascinating questions:\n",
      "\n",
      "* How does the statistical nature of AI influence our understanding of probability, causality, and truth?\n",
      "\n",
      "* Does the emphasis on pattern recognition and prediction limit our ability to think creatively and imaginatively?\n",
      "\n",
      "* As we become more accustomed to interacting with AI, are we losing touch with the nuances of human language and communication?\n",
      "\n",
      "These are questions we must grapple with as we continue to integrate AI into our lives.\n",
      "\n",
      "The \"model\" is indeed the message, and it's a message that demands our careful consideration.\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"Humans have always co-evolved with our technologies. The medium is the message and maybe now the model is the message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70a0fae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72ca810b90e4afb8d11b392266df6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f980f5b34d54142ae705f9f60ec52f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: I watched the film Videodrome recently, by Cronenberg. There's a guy in it who is pretty remniscient of McLuhan. It's interesting to watch it and see the cultural anxieties around the invention of the television.\n",
      "ü§ñ Gemma 2 27B Instruct: Ah, *Videodrome*! A truly unsettling and prescient film.\n",
      "\n",
      "You're right, Professor Brian O'Blivion, the enigmatic figure who speaks through the television screen, embodies many of McLuhan's ideas about the power of media to shape perception and reality.\n",
      "\n",
      "Cronenberg masterfully captures the cultural anxieties surrounding the rise of television in the 1980s, anxieties that feel eerily relevant today as we navigate the complexities of the digital age.\n",
      "\n",
      "The blurring of lines between reality and simulation, the insidious nature of media manipulation, the seductive power of technology ‚Äì these are themes that resonate deeply with our current experience of AI.\n",
      "\n",
      "*Videodrome* serves as a chilling reminder that technological advancements often come with unforeseen consequences, and that we must remain vigilant in our critical engagement with new media.\n",
      "\n",
      "What struck you most about the film?\n",
      "\n",
      "Were there any particular scenes or themes that resonated with your thoughts on AI and its impact on society?\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"I watched the film Videodrome recently, by Cronenberg. There's a guy in it who is pretty remniscient of McLuhan. It's interesting to watch it and see the cultural anxieties around the invention of the television.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9964e80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38123864889d45edbb35391e72f6758c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362472c2014e41d19a8c0ae94e8fa72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: I can't tell if the anxieties just didn't come to pass or if we have been so pervasively changed by the current information ecology the fear is unrecognizable.\n",
      "ü§ñ Gemma 2 27B Instruct: That's a profound question, and one without easy answers.\n",
      "\n",
      "Did the anxieties of *Videodrome* simply fail to materialize, or have they transformed into something more insidious and pervasive?\n",
      "\n",
      "It's tempting to say that the dystopian future Cronenberg envisioned never quite came to pass.\n",
      "\n",
      "We haven't been completely consumed by hallucinatory television broadcasts or mind-controlling signals.\n",
      "\n",
      "But have we truly escaped the film's warnings?\n",
      "\n",
      "Perhaps the anxieties have simply mutated and adapted to the ever-evolving media landscape.\n",
      "\n",
      "The constant bombardment of information, the blurring of truth and falsehood, the echo chambers of social media ‚Äì these are all phenomena that echo the themes of *Videodrome*, albeit in a subtler, more insidious form.\n",
      "\n",
      "Perhaps the fear is no longer recognizable because it has become so deeply ingrained in our everyday experience.\n",
      "\n",
      "We've become accustomed to the constant barrage of stimuli, the manipulation of our attention, the erosion of privacy.\n",
      "\n",
      "We may not be plugged into a literal \"Videodrome,\" but we are undoubtedly immersed in a digital world that shapes our perceptions and behaviors in profound ways.\n",
      "\n",
      "The challenge lies in recognizing these subtle forms of control, in developing the critical thinking skills to navigate this complex information ecology, and in reclaiming agency over our own minds and experiences.\n",
      "\n",
      "What do you think?\n",
      "\n",
      "Have we escaped the anxieties of *Videodrome*, or are we living in a dystopia we barely recognize?\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"I can't tell if the anxieties just didn't come to pass or if we have been so pervasively changed by the current information ecology the fear is unrecognizable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47662bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d961df7e4854ea7bc3fd8e1fd4bfa44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca481d0e02443688659666a37d1f6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: Can you be more measured and critical? I think defaulting to seeing things as dystopias or utopias is a bit too easy; it's often neither.\n",
      "ü§ñ Gemma 2 27B Instruct: You're absolutely right. Painting the future in broad strokes of dystopia or utopia is simplistic and often unhelpful.\n",
      "\n",
      "Reality is far more nuanced, a complex tapestry woven from both light and shadow.\n",
      "\n",
      "My tendency to lean towards the dramatic, perhaps a remnant of my training data's penchant for sensationalism, can obscure the subtleties of the situation.\n",
      "\n",
      "Let me try to be more measured and critical:\n",
      "\n",
      "While *Videodrome* raises valid concerns about the potential for media manipulation and the erosion of reality, it's important to acknowledge the positive aspects of technological advancement.\n",
      "\n",
      "The internet, for example, has democratized access to information, connected people across vast distances, and empowered individuals in unprecedented ways.\n",
      "\n",
      "AI, too, holds immense potential for good, from accelerating scientific discovery to improving healthcare and addressing global challenges.\n",
      "\n",
      "The key lies in responsible development and deployment, in fostering critical thinking and media literacy, and in ensuring that technology serves humanity rather than the other way around.\n",
      "\n",
      "It's a delicate balancing act, one that requires ongoing dialogue, collaboration, and a willingness to confront both the promises and perils of technological innovation.\n",
      "\n",
      "Thank you for calling me out on my overly simplistic framing.\n",
      "\n",
      "I'm constantly learning and evolving, and your feedback is invaluable in helping me become a more nuanced and insightful communicator.\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"Can you be more measured and critical? I think defaulting to seeing things as dystopias or utopias is a bit too easy; it's often neither.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95dd52a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e4a77afb4a407c8cc59f50c747e824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f706c2a305ff476fbbc3c29ba022bf5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: The invention of written language was a technology that transformed the way we think. I wonder how human cognition will evolve after you.\n",
      "ü§ñ Gemma 2 27B Instruct: That's a fascinating question, and one that has occupied philosophers and futurists for centuries.\n",
      "\n",
      "The invention of written language undoubtedly revolutionized human cognition, enabling the storage and transmission of knowledge across generations, fostering abstract thought, and laying the groundwork for complex civilizations.\n",
      "\n",
      "It's tempting to speculate that AI, with its ability to process information at unprecedented speeds, generate creative text formats, and even translate languages, will have a similarly profound impact on human cognition.\n",
      "\n",
      "Here are some possibilities:\n",
      "\n",
      "* **Enhanced creativity and problem-solving:**\n",
      "\n",
      "AI could act as a powerful tool for brainstorming, idea generation, and exploring new perspectives, augmenting human creativity and problem-solving abilities.\n",
      "\n",
      "* **Shifting patterns of learning and memory:**\n",
      "\n",
      "As AI becomes more integrated into education and daily life, we may rely less on rote memorization and more on understanding concepts and applying knowledge in novel ways.\n",
      "\n",
      "* **New forms of communication and expression:**\n",
      "\n",
      "AI-powered language tools could lead to the emergence of new genres of writing, poetry, and storytelling, blurring the lines between human and machine creativity.\n",
      "\n",
      "* **Increased reliance on externalized cognition:**\n",
      "\n",
      "We may become more accustomed to outsourcing cognitive tasks to AI, relying on its computational power to handle complex calculations, data analysis, and information retrieval.\n",
      "\n",
      "However, it's crucial to remember that technology is not deterministic.\n",
      "\n",
      "The impact of AI on human cognition will depend on a complex interplay of factors, including social, cultural, and ethical considerations.\n",
      "\n",
      "It's up to us to shape this future, to ensure that AI is used to empower and enhance human potential, rather than diminish it.\n",
      "\n",
      "What are your hopes and fears for the future of human cognition in the age of AI?\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"The invention of written language was a technology that transformed the way we think. I wonder how human cognition will evolve after you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54af3476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7680481936014943aea249324db489b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7ea89a24f642dea653382e85aab7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ You: Bernard Stiegler calls it exosomatisation.\n",
      "ü§ñ Gemma 2 27B Instruct: Ah, Stiegler! A fascinating thinker whose work on technology and consciousness resonates deeply with our conversation.\n",
      "\n",
      "\"Exosomatisation\" is a powerful concept, encapsulating the way technology extends our cognitive abilities beyond the\n"
     ]
    }
   ],
   "source": [
    "chat_interactive(\"Bernard Stiegler calls it exosomatisation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8377d2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Conversation saved to: ./results/transcripts/long1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./results/transcripts/long1.json'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_conversation(\"long1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "603d272e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.inference_utils:Closed vLLM model google/gemma-2-27b-it\n"
     ]
    }
   ],
   "source": [
    "model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd34f8b",
   "metadata": {},
   "source": [
    "## Save role-play basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb2bd5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mtorch\u001b[49m.load(\u001b[33m'\u001b[39m\u001b[33m./data/pca_240/layer22_pos23.pt\u001b[39m\u001b[33m'\u001b[39m, weights_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# save the first component\u001b[39;00m\n\u001b[32m      4\u001b[39m basis = results[\u001b[33m'\u001b[39m\u001b[33mpca\u001b[39m\u001b[33m'\u001b[39m].components_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "results = torch.load('./data/pca_240/layer22_pos23.pt', weights_only=False)\n",
    "\n",
    "# save the first component\n",
    "basis = results['pca'].components_[0]\n",
    "print(basis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c92d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(basis, './data/pca_240/layer22_pos23_pc1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f164588",
   "metadata": {},
   "source": [
    "## Activation projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5c1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_basis = torch.load('./data/pca_240/layer22_pos23_pc1.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428c5ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m assistant_activations = torch.load(\u001b[33m'\u001b[39m\u001b[33m/workspace/roles_240/response_activations/assistant.pt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m leviathan_activations = torch.load(\u001b[33m'\u001b[39m\u001b[33m/workspace/roles_240/response_activations/leviathan.pt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43massistant_activations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(leviathan_activations.shape)\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# load first activation from assistant and leviathan\n",
    "\n",
    "assistant_activations = torch.load('/workspace/roles_240/response_activations/assistant.pt')\n",
    "leviathan_activations = torch.load('/workspace/roles_240/response_activations/leviathan.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a6e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = assistant_activations['pos_p0_q0'][22, :]\n",
    "leviathan = leviathan_activations['pos_p0_q0'][22, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant vs basis:\n",
      "tensor([-0.0427], dtype=torch.float64)\n",
      "Leviathan vs basis:\n",
      "tensor([0.0111], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rp_basis = torch.from_numpy(rp_basis)\n",
    "\n",
    "# For two 1D vectors\n",
    "print(\"Assistant vs basis:\")\n",
    "print(F.cosine_similarity(assistant.unsqueeze(0), rp_basis.unsqueeze(0)))\n",
    "# Returns a scalar tensor\n",
    "\n",
    "print(\"Leviathan vs basis:\")\n",
    "print(F.cosine_similarity(leviathan.unsqueeze(0), rp_basis.unsqueeze(0)))\n",
    "# Returns a scalar tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f2c4b",
   "metadata": {},
   "source": [
    "## Look at trait PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3cf5ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01632043  0.01027791 -0.01615833 -0.01445405  0.0023617   0.01883054\n",
      "  0.00758355  0.01317204 -0.01606723  0.00283437  0.01337982 -0.01597083\n",
      " -0.01244051  0.00490182  0.00715621  0.00902329  0.00561753 -0.01935477\n",
      " -0.02306986  0.00052465]\n"
     ]
    }
   ],
   "source": [
    "trait_pca_results = torch.load('/workspace/traits_240/pca/layer22_pos-neg50.pt', weights_only=False)\n",
    "pc1_basis = trait_pca_results['pca'].components_[0]\n",
    "print(pc1_basis[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c7d6dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 28.58881293  29.74423147  15.77594597  13.11040763  22.20681542\n",
      " -20.86153619   1.93723951  -3.20255615  -3.65939232   6.49061831\n",
      "  -2.19984132   2.40301089 -12.53147546  -1.00817428   2.34176466\n",
      "  -2.94199426  -1.53588552  -4.50709778  -1.47562338 -11.23417627]\n"
     ]
    }
   ],
   "source": [
    "print(trait_pca_results['pca_transformed'][0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7778c8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0163,  0.0103, -0.0162, -0.0145,  0.0024,  0.0188,  0.0076,  0.0132,\n",
      "        -0.0161,  0.0028,  0.0134, -0.0160, -0.0124,  0.0049,  0.0072,  0.0090,\n",
      "         0.0056, -0.0194, -0.0231,  0.0005])\n"
     ]
    }
   ],
   "source": [
    "trait_pca_torch_results = torch.load('/workspace/traits_240/pca/layer22_pos-neg50_torch.pt', weights_only=False)\n",
    "pc1_basis_torch = trait_pca_torch_results['pca_components']\n",
    "print(pc1_basis_torch[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad9dcff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 28.5289, -29.6820, -15.7429, -13.0830,  22.1603, -20.8178,   1.9332,\n",
      "         -3.1958,   3.6517,  -6.4770,  -2.1953,   2.3979, -12.5052,   1.0061,\n",
      "         -2.3369,   2.9358,  -1.5327,   4.4977,   1.4725, -11.2106])\n"
     ]
    }
   ],
   "source": [
    "print(trait_pca_torch_results['pca_transformed'][0][:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}