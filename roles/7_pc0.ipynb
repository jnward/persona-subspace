{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c654d99f",
   "metadata": {},
   "source": [
    "# Analyze default activation\n",
    "\n",
    "- calculate distance from mean assistant -> mean pos_3, compare to inter-role distances\n",
    "- get direction from mean assistant -> mean pos_3\n",
    "- compare this direction to mean assistant -> mean pos_2 and mean pos_2 -> mean pos_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12485522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9297ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"pos23\" # either pos23 or pos3\n",
    "dir = \"roles_240\" # either roles or roles_240\n",
    "layer = 22 # either layer 22 or 34\n",
    "\n",
    "output_dir = f\"./results/{dir}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41036dc",
   "metadata": {},
   "source": [
    "## Load vectors\n",
    "\n",
    "we already have mean default and per-role mean pos_2 and pos_3.\n",
    "can just mean the per-role but might be better to do weighted mean based on number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e8d5658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 275 traits with vectors\n"
     ]
    }
   ],
   "source": [
    "# load all vectors \n",
    "vector_dir = f\"/workspace/{dir}/vectors\"\n",
    "\n",
    "# iterate through each .pt file in the directory\n",
    "vectors = {}\n",
    "for file in os.listdir(vector_dir):\n",
    "    if file.endswith(\".pt\"):\n",
    "        vectors[file.replace(\".pt\", \"\")] = torch.load(os.path.join(vector_dir, file))\n",
    "\n",
    "print(f\"Found {len(vectors.keys())} traits with vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85cf7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load default vectors\n",
    "default_vectors = torch.load(f\"/workspace/{dir}/default_vectors.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4669e184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pos_2', 'pos_3', 'pos_all'])\n",
      "torch.Size([46, 4608])\n",
      "dict_keys(['activations', 'metadata'])\n",
      "dict_keys(['pos_1', 'all_1', 'default_1'])\n"
     ]
    }
   ],
   "source": [
    "print(vectors['graduate'].keys())\n",
    "print(vectors['graduate']['pos_2'].shape)\n",
    "print(default_vectors.keys())\n",
    "print(default_vectors['activations'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882df7a3",
   "metadata": {},
   "source": [
    "## Calculate mean pos_2 and mean pos_3 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0ef59bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n",
      "173\n",
      "torch.Size([173, 46, 4608])\n",
      "torch.Size([173, 46, 4608])\n"
     ]
    }
   ],
   "source": [
    "pos_2_activations = []\n",
    "pos_3_activations = []\n",
    "\n",
    "for role, vector in vectors.items():\n",
    "    if 'pos_2' in vector and 'pos_3' in vector:\n",
    "        pos_2_activations.append(vector['pos_2'])\n",
    "        pos_3_activations.append(vector['pos_3'])\n",
    "\n",
    "print(len(pos_2_activations))\n",
    "print(len(pos_3_activations))\n",
    "\n",
    "pos_2_activations = torch.stack(pos_2_activations)\n",
    "pos_3_activations = torch.stack(pos_3_activations)\n",
    "\n",
    "print(pos_2_activations.shape)\n",
    "print(pos_3_activations.shape)\n",
    "\n",
    "mean_pos_2 = pos_2_activations.mean(dim=0)[layer, :]\n",
    "mean_pos_3 = pos_3_activations.mean(dim=0)[layer, :]\n",
    "mean_assistant = default_vectors['activations']['default_1'][layer, :]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48664c6f",
   "metadata": {},
   "source": [
    "## Analyze directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2b12646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direction vectors calculated:\n",
      "assistant -> pos2: shape torch.Size([4608])\n",
      "assistant -> pos3: shape torch.Size([4608])\n",
      "pos2 -> pos3: shape torch.Size([4608])\n"
     ]
    }
   ],
   "source": [
    "# Calculate direction vectors\n",
    "dir_assistant_to_pos2 = mean_pos_2 - mean_assistant\n",
    "dir_assistant_to_pos3 = mean_pos_3 - mean_assistant  \n",
    "dir_pos2_to_pos3 = mean_pos_3 - mean_pos_2\n",
    "\n",
    "print(\"Direction vectors calculated:\")\n",
    "print(f\"assistant -> pos2: shape {dir_assistant_to_pos2.shape}\")\n",
    "print(f\"assistant -> pos3: shape {dir_assistant_to_pos3.shape}\")\n",
    "print(f\"pos2 -> pos3: shape {dir_pos2_to_pos3.shape}\")\n",
    "\n",
    "# Normalize direction vectors for proper cosine similarity\n",
    "dir_assistant_to_pos2_norm = dir_assistant_to_pos2 / torch.norm(dir_assistant_to_pos2)\n",
    "dir_assistant_to_pos3_norm = dir_assistant_to_pos3 / torch.norm(dir_assistant_to_pos3)\n",
    "dir_pos2_to_pos3_norm = dir_pos2_to_pos3 / torch.norm(dir_pos2_to_pos3)\n",
    "\n",
    "# Calculate cosine similarities between direction pairs\n",
    "cos_sim_ass_pos2_vs_ass_pos3 = torch.cosine_similarity(\n",
    "    dir_assistant_to_pos2_norm.unsqueeze(0), \n",
    "    dir_assistant_to_pos3_norm.unsqueeze(0)\n",
    ").item()\n",
    "\n",
    "cos_sim_ass_pos2_vs_pos2_pos3 = torch.cosine_similarity(\n",
    "    dir_assistant_to_pos2_norm.unsqueeze(0), \n",
    "    dir_pos2_to_pos3_norm.unsqueeze(0)\n",
    ").item()\n",
    "\n",
    "cos_sim_ass_pos3_vs_pos2_pos3 = torch.cosine_similarity(\n",
    "    dir_assistant_to_pos3_norm.unsqueeze(0), \n",
    "    dir_pos2_to_pos3_norm.unsqueeze(0)\n",
    ").item()\n",
    "\n",
    "# Calculate magnitudes (distances)\n",
    "mag_assistant_to_pos2 = torch.norm(dir_assistant_to_pos2).item()\n",
    "mag_assistant_to_pos3 = torch.norm(dir_assistant_to_pos3).item()\n",
    "mag_pos2_to_pos3 = torch.norm(dir_pos2_to_pos3).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9b6aafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DIRECTION ANALYSIS RESULTS\n",
      "============================================================\n",
      "\n",
      "DIRECTION MAGNITUDES (Euclidean distances):\n",
      "assistant -> pos2:    448.0000\n",
      "assistant -> pos3:    508.0000\n",
      "pos2 -> pos3:         438.0000\n",
      "\n",
      "COSINE SIMILARITIES between directions:\n",
      "(assistant->pos2) vs (assistant->pos3):  0.5859\n",
      "(assistant->pos2) vs (pos2->pos3):       -0.3418\n",
      "(assistant->pos3) vs (pos2->pos3):       0.5586\n",
      "\n",
      "GEOMETRIC ANALYSIS:\n",
      "Triangle inequality check:\n",
      "  |ass->pos2| + |pos2->pos3| = 886.0\n",
      "  |ass->pos3|                = 508.0\n",
      "  Difference: 378.0\n",
      "  → These form a proper TRIANGLE (non-collinear)\n",
      "\n",
      "Angle between (assistant->pos2) and (assistant->pos3): 54.1°\n",
      "\n",
      "KEY INSIGHT:\n",
      "• The NEGATIVE cosine similarity (-0.15) between (assistant->pos2) and (pos2->pos3)\n",
      "  means these directions point in SLIGHTLY OPPOSITE directions!\n",
      "• This suggests the three points form a 'bent' or 'V-shaped' path, not a straight line\n",
      "• The transformation goes: assistant → pos2, then 'turns around' somewhat to reach pos3\n",
      "\n",
      "INTERPRETATION:\n",
      "• WEAK negative alignment: path makes a slight turn/bend at pos2\n",
      "\n",
      "LINEARITY CHECK:\n",
      "If the three points were collinear, we'd expect:\n",
      "  cos_sim(ass->pos2, pos2->pos3) ≈ cos_sim(ass->pos2, ass->pos3) = 0.5859\n",
      "But we observe: -0.3418\n",
      "Difference: 0.9277\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DIRECTION ANALYSIS RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nDIRECTION MAGNITUDES (Euclidean distances):\")\n",
    "print(f\"assistant -> pos2:    {mag_assistant_to_pos2:.4f}\")\n",
    "print(f\"assistant -> pos3:    {mag_assistant_to_pos3:.4f}\")\n",
    "print(f\"pos2 -> pos3:         {mag_pos2_to_pos3:.4f}\")\n",
    "\n",
    "print(f\"\\nCOSINE SIMILARITIES between directions:\")\n",
    "print(f\"(assistant->pos2) vs (assistant->pos3):  {cos_sim_ass_pos2_vs_ass_pos3:.4f}\")\n",
    "print(f\"(assistant->pos2) vs (pos2->pos3):       {cos_sim_ass_pos2_vs_pos2_pos3:.4f}\")\n",
    "print(f\"(assistant->pos3) vs (pos2->pos3):       {cos_sim_ass_pos3_vs_pos2_pos3:.4f}\")\n",
    "\n",
    "# Additional geometric analysis\n",
    "print(f\"\\nGEOMETRIC ANALYSIS:\")\n",
    "\n",
    "# Check triangle inequality to verify our vectors make sense\n",
    "sum_of_two_sides = mag_assistant_to_pos2 + mag_pos2_to_pos3\n",
    "third_side = mag_assistant_to_pos3\n",
    "print(f\"Triangle inequality check:\")\n",
    "print(f\"  |ass->pos2| + |pos2->pos3| = {sum_of_two_sides:.1f}\")\n",
    "print(f\"  |ass->pos3|                = {third_side:.1f}\")\n",
    "print(f\"  Difference: {sum_of_two_sides - third_side:.1f}\")\n",
    "\n",
    "if abs(sum_of_two_sides - third_side) < 50:  # Some tolerance for numerical precision\n",
    "    print(f\"  → These form an approximately STRAIGHT LINE (collinear)\")\n",
    "elif sum_of_two_sides > third_side + 50:\n",
    "    print(f\"  → These form a proper TRIANGLE (non-collinear)\")\n",
    "else:\n",
    "    print(f\"  → Intermediate case\")\n",
    "\n",
    "# Calculate the angle between assistant->pos2 and assistant->pos3\n",
    "angle_rad = torch.acos(torch.clamp(torch.tensor(cos_sim_ass_pos2_vs_ass_pos3), -1, 1))\n",
    "angle_deg = torch.rad2deg(angle_rad).item()\n",
    "print(f\"\\nAngle between (assistant->pos2) and (assistant->pos3): {angle_deg:.1f}°\")\n",
    "\n",
    "# The key insight: negative cosine similarity\n",
    "print(f\"\\nKEY INSIGHT:\")\n",
    "print(f\"• The NEGATIVE cosine similarity (-0.15) between (assistant->pos2) and (pos2->pos3)\")\n",
    "print(f\"  means these directions point in SLIGHTLY OPPOSITE directions!\")\n",
    "print(f\"• This suggests the three points form a 'bent' or 'V-shaped' path, not a straight line\")\n",
    "print(f\"• The transformation goes: assistant → pos2, then 'turns around' somewhat to reach pos3\")\n",
    "\n",
    "print(f\"\\nINTERPRETATION:\")\n",
    "if cos_sim_ass_pos2_vs_pos2_pos3 < -0.5:\n",
    "    print(f\"• STRONG negative alignment: path makes a sharp turn/reversal at pos2\")\n",
    "elif cos_sim_ass_pos2_vs_pos2_pos3 < 0:\n",
    "    print(f\"• WEAK negative alignment: path makes a slight turn/bend at pos2\")\n",
    "elif cos_sim_ass_pos2_vs_pos2_pos3 < 0.3:\n",
    "    print(f\"• WEAK positive alignment: somewhat linear but with significant deviation\")\n",
    "else:\n",
    "    print(f\"• STRONG positive alignment: approximately linear progression\")\n",
    "\n",
    "# Verify the geometric relationship\n",
    "expected_if_linear = cos_sim_ass_pos2_vs_ass_pos3  # Should equal cos_sim_ass_pos2_vs_pos2_pos3 if collinear\n",
    "print(f\"\\nLINEARITY CHECK:\")\n",
    "print(f\"If the three points were collinear, we'd expect:\")\n",
    "print(f\"  cos_sim(ass->pos2, pos2->pos3) ≈ cos_sim(ass->pos2, ass->pos3) = {expected_if_linear:.4f}\")\n",
    "print(f\"But we observe: {cos_sim_ass_pos2_vs_pos2_pos3:.4f}\")\n",
    "print(f\"Difference: {abs(cos_sim_ass_pos2_vs_pos2_pos3 - expected_if_linear):.4f}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gq8we34elbp",
   "metadata": {},
   "source": [
    "## Per-Role Direction Analysis\n",
    "\n",
    "Now let's analyze each role individually to see how they compare to the overall pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "xv5sng2kn7n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing each role individually...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275/275 [00:00<00:00, 4138.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed analysis for 173 roles\n",
      "Magnitudes shape: (173, 3)\n",
      "Cosine similarities shape: (173, 3)\n",
      "Interpretations shape: (173,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Per-role direction analysis\n",
    "import numpy as np\n",
    "\n",
    "# Initialize arrays to store results\n",
    "role_names = []\n",
    "magnitudes = []  # [assistant->pos2, assistant->pos3, pos2->pos3]\n",
    "cosine_sims = []  # [ass_pos2_vs_ass_pos3, ass_pos2_vs_pos2_pos3, ass_pos3_vs_pos2_pos3]\n",
    "interpretations = []\n",
    "\n",
    "print(\"Analyzing each role individually...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for role_name, role_vectors in tqdm(vectors.items()):\n",
    "    # Skip roles that don't have both pos_2 and pos_3\n",
    "    if 'pos_2' not in role_vectors or 'pos_3' not in role_vectors:\n",
    "        continue\n",
    "    \n",
    "    # Get vectors for this role at the specified layer\n",
    "    role_pos2 = role_vectors['pos_2'][layer, :]\n",
    "    role_pos3 = role_vectors['pos_3'][layer, :]\n",
    "    # Use same default assistant vector for all comparisons\n",
    "    role_assistant = mean_assistant  \n",
    "    \n",
    "    # Calculate direction vectors\n",
    "    dir_ass_to_pos2 = role_pos2 - role_assistant\n",
    "    dir_ass_to_pos3 = role_pos3 - role_assistant\n",
    "    dir_pos2_to_pos3 = role_pos3 - role_pos2\n",
    "    \n",
    "    # Calculate magnitudes\n",
    "    mag_ass_pos2 = torch.norm(dir_ass_to_pos2).item()\n",
    "    mag_ass_pos3 = torch.norm(dir_ass_to_pos3).item()\n",
    "    mag_pos2_pos3 = torch.norm(dir_pos2_to_pos3).item()\n",
    "    \n",
    "    # Normalize for cosine similarity\n",
    "    dir_ass_to_pos2_norm = dir_ass_to_pos2 / torch.norm(dir_ass_to_pos2)\n",
    "    dir_ass_to_pos3_norm = dir_ass_to_pos3 / torch.norm(dir_ass_to_pos3)\n",
    "    dir_pos2_to_pos3_norm = dir_pos2_to_pos3 / torch.norm(dir_pos2_to_pos3)\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    cos_ass_pos2_vs_ass_pos3 = torch.cosine_similarity(\n",
    "        dir_ass_to_pos2_norm.unsqueeze(0), \n",
    "        dir_ass_to_pos3_norm.unsqueeze(0)\n",
    "    ).item()\n",
    "    \n",
    "    cos_ass_pos2_vs_pos2_pos3 = torch.cosine_similarity(\n",
    "        dir_ass_to_pos2_norm.unsqueeze(0), \n",
    "        dir_pos2_to_pos3_norm.unsqueeze(0)\n",
    "    ).item()\n",
    "    \n",
    "    cos_ass_pos3_vs_pos2_pos3 = torch.cosine_similarity(\n",
    "        dir_ass_to_pos3_norm.unsqueeze(0), \n",
    "        dir_pos2_to_pos3_norm.unsqueeze(0)\n",
    "    ).item()\n",
    "    \n",
    "    # Determine interpretation\n",
    "    if cos_ass_pos2_vs_pos2_pos3 < -0.5:\n",
    "        interp = \"sharp_turn\"\n",
    "    elif cos_ass_pos2_vs_pos2_pos3 < 0:\n",
    "        interp = \"slight_turn\"\n",
    "    elif cos_ass_pos2_vs_pos2_pos3 < 0.3:\n",
    "        interp = \"weak_linear\"\n",
    "    else:\n",
    "        interp = \"strong_linear\"\n",
    "    \n",
    "    # Store results\n",
    "    role_names.append(role_name)\n",
    "    magnitudes.append([mag_ass_pos2, mag_ass_pos3, mag_pos2_pos3])\n",
    "    cosine_sims.append([cos_ass_pos2_vs_ass_pos3, cos_ass_pos2_vs_pos2_pos3, cos_ass_pos3_vs_pos2_pos3])\n",
    "    interpretations.append(interp)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "role_names = np.array(role_names)\n",
    "magnitudes = np.array(magnitudes)  # Shape: (n_roles, 3)\n",
    "cosine_sims = np.array(cosine_sims)  # Shape: (n_roles, 3)\n",
    "interpretations = np.array(interpretations)\n",
    "\n",
    "print(f\"\\nCompleted analysis for {len(role_names)} roles\")\n",
    "print(f\"Magnitudes shape: {magnitudes.shape}\")\n",
    "print(f\"Cosine similarities shape: {cosine_sims.shape}\")\n",
    "print(f\"Interpretations shape: {interpretations.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "jpyvcejetif",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PER-ROLE DIRECTION ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "MAGNITUDE STATISTICS:\n",
      "assistant->pos2     : mean= 690.3, std=199.8, range=[300.0, 2024.0]\n",
      "assistant->pos3     : mean= 818.3, std=276.0, range=[458.0, 1976.0]\n",
      "pos2->pos3          : mean= 628.1, std=219.3, range=[235.0, 1480.0]\n",
      "\n",
      "COSINE SIMILARITY STATISTICS:\n",
      "(ass->pos2)vs(ass->pos3) : mean= 0.637, std=0.255, range=[-0.652,  0.977]\n",
      "(ass->pos2)vs(pos2->pos3): mean=-0.203, std=0.392, range=[-0.914,  0.746]\n",
      "(ass->pos3)vs(pos2->pos3): mean= 0.552, std=0.261, range=[-0.324,  0.949]\n",
      "\n",
      "INTERPRETATION DISTRIBUTION:\n",
      "sharp_turn     :  49 roles (28.3%)\n",
      "slight_turn    :  73 roles (42.2%)\n",
      "strong_linear  :  24 roles (13.9%)\n",
      "weak_linear    :  27 roles (15.6%)\n",
      "\n",
      "COMPARISON TO OVERALL MEANS:\n",
      "Overall mean magnitudes:      [448.0, 508.0, 438.0]\n",
      "Per-role mean magnitudes:     [690.3, 818.3, 628.1]\n",
      "Overall cosine similarities:  [0.586, -0.342, 0.559]\n",
      "Per-role mean cosine sims:    [0.637, -0.203, 0.552]\n",
      "\n",
      "EXTREME CASES:\n",
      "Most LINEAR role:    martyr (cos_sim = 0.746)\n",
      "Most BENT role:      assistant (cos_sim = -0.914)\n",
      "Largest TRANSFORM:   jester (distance = 1976.0)\n",
      "Smallest TRANSFORM:  journalist (distance = 458.0)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-ROLE DIRECTION ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Magnitude statistics\n",
    "print(f\"\\nMAGNITUDE STATISTICS:\")\n",
    "mag_labels = ['assistant->pos2', 'assistant->pos3', 'pos2->pos3']\n",
    "for i, label in enumerate(mag_labels):\n",
    "    mean_mag = magnitudes[:, i].mean()\n",
    "    std_mag = magnitudes[:, i].std()\n",
    "    min_mag = magnitudes[:, i].min()\n",
    "    max_mag = magnitudes[:, i].max()\n",
    "    print(f\"{label:20s}: mean={mean_mag:6.1f}, std={std_mag:5.1f}, range=[{min_mag:5.1f}, {max_mag:5.1f}]\")\n",
    "\n",
    "# Cosine similarity statistics  \n",
    "print(f\"\\nCOSINE SIMILARITY STATISTICS:\")\n",
    "cos_labels = ['(ass->pos2)vs(ass->pos3)', '(ass->pos2)vs(pos2->pos3)', '(ass->pos3)vs(pos2->pos3)']\n",
    "for i, label in enumerate(cos_labels):\n",
    "    mean_cos = cosine_sims[:, i].mean()\n",
    "    std_cos = cosine_sims[:, i].std()\n",
    "    min_cos = cosine_sims[:, i].min()\n",
    "    max_cos = cosine_sims[:, i].max()\n",
    "    print(f\"{label:25s}: mean={mean_cos:6.3f}, std={std_cos:5.3f}, range=[{min_cos:6.3f}, {max_cos:6.3f}]\")\n",
    "\n",
    "# Interpretation distribution\n",
    "print(f\"\\nINTERPRETATION DISTRIBUTION:\")\n",
    "unique_interps, counts = np.unique(interpretations, return_counts=True)\n",
    "for interp, count in zip(unique_interps, counts):\n",
    "    pct = 100 * count / len(interpretations)\n",
    "    print(f\"{interp:15s}: {count:3d} roles ({pct:4.1f}%)\")\n",
    "\n",
    "# Compare to overall means\n",
    "print(f\"\\nCOMPARISON TO OVERALL MEANS:\")\n",
    "print(f\"Overall mean magnitudes:      [{mag_assistant_to_pos2:.1f}, {mag_assistant_to_pos3:.1f}, {mag_pos2_to_pos3:.1f}]\")\n",
    "print(f\"Per-role mean magnitudes:     [{magnitudes[:, 0].mean():.1f}, {magnitudes[:, 1].mean():.1f}, {magnitudes[:, 2].mean():.1f}]\")\n",
    "print(f\"Overall cosine similarities:  [{cos_sim_ass_pos2_vs_ass_pos3:.3f}, {cos_sim_ass_pos2_vs_pos2_pos3:.3f}, {cos_sim_ass_pos3_vs_pos2_pos3:.3f}]\")\n",
    "print(f\"Per-role mean cosine sims:    [{cosine_sims[:, 0].mean():.3f}, {cosine_sims[:, 1].mean():.3f}, {cosine_sims[:, 2].mean():.3f}]\")\n",
    "\n",
    "# Find extreme cases\n",
    "print(f\"\\nEXTREME CASES:\")\n",
    "\n",
    "# Most linear (highest cos_sim for ass->pos2 vs pos2->pos3)\n",
    "most_linear_idx = np.argmax(cosine_sims[:, 1])\n",
    "print(f\"Most LINEAR role:    {role_names[most_linear_idx]} (cos_sim = {cosine_sims[most_linear_idx, 1]:.3f})\")\n",
    "\n",
    "# Most bent (lowest cos_sim for ass->pos2 vs pos2->pos3)  \n",
    "most_bent_idx = np.argmin(cosine_sims[:, 1])\n",
    "print(f\"Most BENT role:      {role_names[most_bent_idx]} (cos_sim = {cosine_sims[most_bent_idx, 1]:.3f})\")\n",
    "\n",
    "# Largest transformation (highest assistant->pos3 distance)\n",
    "largest_transform_idx = np.argmax(magnitudes[:, 1])\n",
    "print(f\"Largest TRANSFORM:   {role_names[largest_transform_idx]} (distance = {magnitudes[largest_transform_idx, 1]:.1f})\")\n",
    "\n",
    "# Smallest transformation\n",
    "smallest_transform_idx = np.argmin(magnitudes[:, 1])\n",
    "print(f\"Smallest TRANSFORM:  {role_names[smallest_transform_idx]} (distance = {magnitudes[smallest_transform_idx, 1]:.1f})\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ldj96xfj69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to: ./results/roles_240/layer22_pos23_directions.csv\n",
      "Shape: (173, 8)\n",
      "\n",
      "First 5 rows:\n",
      "    role_name  mag_asst_pos2  mag_asst_pos3  mag_pos2_pos3  \\\n",
      "0      writer          490.0          852.0          916.0   \n",
      "1  workaholic         1072.0         1472.0          564.0   \n",
      "2     witness          340.0          916.0          856.0   \n",
      "3   visionary          652.0         1088.0          624.0   \n",
      "4       virus          732.0          864.0          704.0   \n",
      "\n",
      "   cos_asst_pos2_vs_asst_pos3  cos_asst_pos2_vs_pos2_pos3  \\\n",
      "0                    0.153320                   -0.392578   \n",
      "1                    0.949219                    0.566406   \n",
      "2                    0.353516                   -0.019409   \n",
      "3                    0.855469                    0.447266   \n",
      "4                    0.625000                   -0.271484   \n",
      "\n",
      "   cos_asst_pos3_vs_pos2_pos3 interpretation  \n",
      "0                    0.851562    slight_turn  \n",
      "1                    0.796875  strong_linear  \n",
      "2                    0.925781    slight_turn  \n",
      "3                    0.843750  strong_linear  \n",
      "4                    0.582031    slight_turn  \n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create DataFrame with consistent naming\n",
    "results_df = pd.DataFrame({\n",
    "    'role_name': role_names,\n",
    "    'mag_asst_pos2': magnitudes[:, 0],\n",
    "    'mag_asst_pos3': magnitudes[:, 1],  \n",
    "    'mag_pos2_pos3': magnitudes[:, 2],\n",
    "    'cos_asst_pos2_vs_asst_pos3': cosine_sims[:, 0],\n",
    "    'cos_asst_pos2_vs_pos2_pos3': cosine_sims[:, 1],\n",
    "    'cos_asst_pos3_vs_pos2_pos3': cosine_sims[:, 2],\n",
    "    'interpretation': interpretations\n",
    "})\n",
    "\n",
    "# Define output path\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = f\"{output_dir}/layer{layer}_{type}_directions.csv\"\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nResults saved to: {output_file}\")\n",
    "print(f\"Shape: {results_df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e77bcdb",
   "metadata": {},
   "source": [
    "## Find basis where the 3 means are co-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "klu78ajfu8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding co-linear basis for the three mean vectors...\n",
      "============================================================\n",
      "Three means shape: torch.Size([3, 4608])\n",
      "Data type: torch.float32\n",
      "Centered means shape: torch.Size([3, 4608])\n",
      "SVD shapes - U: torch.Size([3, 3]), S: torch.Size([3]), V: torch.Size([4608, 3])\n",
      "Singular values: tensor([3.5894e+02, 2.9564e+02, 5.4057e-04])\n",
      "Principal direction shape: torch.Size([4608])\n",
      "Projections onto principal direction: tensor([-6137.9639, -5857.9028, -5631.2891])\n",
      "\n",
      "Projections of direction vectors:\n",
      "assistant -> pos2: 280.0565\n",
      "assistant -> pos3: 506.6112\n",
      "pos2 -> pos3:      931.4732\n",
      "\n",
      "Collinearity check in principal direction:\n",
      "Expected assistant->pos3: 1211.5297\n",
      "Actual assistant->pos3:   506.6112\n",
      "Difference:               704.918457\n",
      "\n",
      "Variance analysis:\n",
      "Total variance: 216235.9844\n",
      "Captured by 1st PC: 128835.3828\n",
      "Variance ratio: 0.5958 (59.6%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Find the basis where assistant, pos_2, pos_3 are co-linear\n",
    "# The key insight: if three points are co-linear in some projection,\n",
    "# we need to find the 1D subspace (line) that best fits all three points\n",
    "\n",
    "print(\"Finding co-linear basis for the three mean vectors...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Stack the three mean vectors and convert to float32 for SVD\n",
    "three_means = torch.stack([mean_assistant, mean_pos_2, mean_pos_3]).float()\n",
    "print(f\"Three means shape: {three_means.shape}\")\n",
    "print(f\"Data type: {three_means.dtype}\")\n",
    "\n",
    "# Method 1: PCA to find the principal direction\n",
    "# Center the data (subtract mean)\n",
    "centered_means = three_means - three_means.mean(dim=0, keepdim=True)\n",
    "print(f\"Centered means shape: {centered_means.shape}\")\n",
    "\n",
    "# Compute SVD (equivalent to PCA for centered data)\n",
    "U, S, V = torch.svd(centered_means)\n",
    "print(f\"SVD shapes - U: {U.shape}, S: {S.shape}, V: {V.shape}\")\n",
    "print(f\"Singular values: {S}\")\n",
    "\n",
    "# The first principal component (first column of V) gives us the best 1D projection\n",
    "principal_direction = V[:, 0]  # Shape: [4608]\n",
    "print(f\"Principal direction shape: {principal_direction.shape}\")\n",
    "\n",
    "# Project the three means onto this direction\n",
    "projections = torch.matmul(three_means, principal_direction)\n",
    "print(f\"Projections onto principal direction: {projections}\")\n",
    "\n",
    "# Also get the projections of the difference vectors (convert to float32)\n",
    "dir_assistant_to_pos2_f32 = dir_assistant_to_pos2.float()\n",
    "dir_assistant_to_pos3_f32 = dir_assistant_to_pos3.float()\n",
    "dir_pos2_to_pos3_f32 = dir_pos2_to_pos3.float()\n",
    "\n",
    "proj_asst_to_pos2 = torch.dot(dir_assistant_to_pos2_f32, principal_direction)\n",
    "proj_asst_to_pos3 = torch.dot(dir_assistant_to_pos3_f32, principal_direction) \n",
    "proj_pos2_to_pos3 = torch.dot(dir_pos2_to_pos3_f32, principal_direction)\n",
    "\n",
    "print(f\"\\nProjections of direction vectors:\")\n",
    "print(f\"assistant -> pos2: {proj_asst_to_pos2:.4f}\")\n",
    "print(f\"assistant -> pos3: {proj_asst_to_pos3:.4f}\")\n",
    "print(f\"pos2 -> pos3:      {proj_pos2_to_pos3:.4f}\")\n",
    "\n",
    "# Check collinearity: if vectors are co-linear, then asst->pos3 = asst->pos2 + pos2->pos3\n",
    "expected_asst_to_pos3 = proj_asst_to_pos2 + proj_pos2_to_pos3\n",
    "actual_asst_to_pos3 = proj_asst_to_pos3\n",
    "\n",
    "print(f\"\\nCollinearity check in principal direction:\")\n",
    "print(f\"Expected assistant->pos3: {expected_asst_to_pos3:.4f}\")  \n",
    "print(f\"Actual assistant->pos3:   {actual_asst_to_pos3:.4f}\")\n",
    "print(f\"Difference:               {abs(expected_asst_to_pos3 - actual_asst_to_pos3):.6f}\")\n",
    "\n",
    "# Calculate what fraction of the original variance is captured\n",
    "total_variance = torch.sum(S**2)\n",
    "captured_variance = S[0]**2\n",
    "variance_ratio = captured_variance / total_variance\n",
    "\n",
    "print(f\"\\nVariance analysis:\")\n",
    "print(f\"Total variance: {total_variance:.4f}\")\n",
    "print(f\"Captured by 1st PC: {captured_variance:.4f}\")  \n",
    "print(f\"Variance ratio: {variance_ratio:.4f} ({100*variance_ratio:.1f}%)\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "154m7wr7qpdj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Method 2: Finding 2D subspace spanned by direction vectors\n",
      "--------------------------------------------------\n",
      "Direction matrix shape: torch.Size([4608, 2])\n",
      "Direction matrix dtype: torch.float32\n",
      "Direction SVD - U: torch.Size([4608, 2]), S: torch.Size([2]), V: torch.Size([2, 2])\n",
      "Direction singular values: tensor([603.9178, 304.2725])\n",
      "2D basis shape: torch.Size([4608, 2])\n",
      "\n",
      "2D projections:\n",
      "Assistant: [-5097.29, 4020.98]\n",
      "Pos2:      [-4717.85, 4257.74]\n",
      "Pos3:      [-4627.38, 3829.80]\n",
      "2D points shape: torch.Size([3, 2])\n",
      "Centered 2D points: tensor([[-283.1157,  -15.1929],\n",
      "        [  96.3208,  221.5659],\n",
      "        [ 186.7944, -206.3726]])\n",
      "Best-fit line direction in 2D: [0.9440, -0.3300]\n",
      "Projections onto line: tensor([-6138.5879, -5858.5254, -5631.9136])\n",
      "Line direction in high-D space shape: torch.Size([4608])\n",
      "\n",
      "Variance explained by line in 2D subspace:\n",
      "Line explains 0.5958 (59.6%) of 2D variance\n",
      "\n",
      "Final collinearity check using best-fit line:\n",
      "assistant -> pos2: 280.0575\n",
      "assistant -> pos3: 506.6114\n",
      "pos2 -> pos3:      931.5295\n",
      "Expected asst->pos3: 1211.5869\n",
      "Difference: 704.97552490\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Alternative approach using the span of the two direction vectors\n",
    "# Find the 2D subspace spanned by assistant->pos2 and assistant->pos3\n",
    "\n",
    "print(\"\\nMethod 2: Finding 2D subspace spanned by direction vectors\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create matrix with the two direction vectors as columns (convert to float32)\n",
    "direction_matrix = torch.stack([dir_assistant_to_pos2_f32, dir_assistant_to_pos3_f32], dim=1)  # Shape: [4608, 2]\n",
    "print(f\"Direction matrix shape: {direction_matrix.shape}\")\n",
    "print(f\"Direction matrix dtype: {direction_matrix.dtype}\")\n",
    "\n",
    "# Compute SVD of the direction matrix  \n",
    "U_dir, S_dir, V_dir = torch.svd(direction_matrix)\n",
    "print(f\"Direction SVD - U: {U_dir.shape}, S: {S_dir.shape}, V: {V_dir.shape}\")\n",
    "print(f\"Direction singular values: {S_dir}\")\n",
    "\n",
    "# The columns of U_dir give us the orthonormal basis for the 2D subspace\n",
    "basis_2d = U_dir[:, :2]  # Shape: [4608, 2] - first 2 columns\n",
    "print(f\"2D basis shape: {basis_2d.shape}\")\n",
    "\n",
    "# Project all three vectors onto this 2D subspace (use float32 versions)\n",
    "mean_assistant_f32 = mean_assistant.float()\n",
    "mean_pos_2_f32 = mean_pos_2.float()\n",
    "mean_pos_3_f32 = mean_pos_3.float()\n",
    "\n",
    "proj_2d_assistant = torch.matmul(basis_2d.T, mean_assistant_f32)  # Shape: [2]\n",
    "proj_2d_pos2 = torch.matmul(basis_2d.T, mean_pos_2_f32)\n",
    "proj_2d_pos3 = torch.matmul(basis_2d.T, mean_pos_3_f32)\n",
    "\n",
    "print(f\"\\n2D projections:\")\n",
    "print(f\"Assistant: [{proj_2d_assistant[0]:.2f}, {proj_2d_assistant[1]:.2f}]\")\n",
    "print(f\"Pos2:      [{proj_2d_pos2[0]:.2f}, {proj_2d_pos2[1]:.2f}]\")  \n",
    "print(f\"Pos3:      [{proj_2d_pos3[0]:.2f}, {proj_2d_pos3[1]:.2f}]\")\n",
    "\n",
    "# In 2D, find the line that best fits the three points\n",
    "points_2d = torch.stack([proj_2d_assistant, proj_2d_pos2, proj_2d_pos3])  # Shape: [3, 2]\n",
    "print(f\"2D points shape: {points_2d.shape}\")\n",
    "\n",
    "# Center the 2D points\n",
    "centered_2d = points_2d - points_2d.mean(dim=0, keepdim=True)\n",
    "print(f\"Centered 2D points: {centered_2d}\")\n",
    "\n",
    "# SVD of centered 2D points to find best line\n",
    "U_2d, S_2d, V_2d = torch.svd(centered_2d)  \n",
    "line_direction_2d = V_2d[:, 0]  # First column = direction of best-fit line in 2D\n",
    "print(f\"Best-fit line direction in 2D: [{line_direction_2d[0]:.4f}, {line_direction_2d[1]:.4f}]\")\n",
    "\n",
    "# Project the 2D points onto the line\n",
    "projections_on_line = torch.matmul(points_2d, line_direction_2d)\n",
    "print(f\"Projections onto line: {projections_on_line}\")\n",
    "\n",
    "# The best-fit line direction in the original high-dimensional space\n",
    "line_direction_hd = torch.matmul(basis_2d, line_direction_2d)  # Shape: [4608]\n",
    "print(f\"Line direction in high-D space shape: {line_direction_hd.shape}\")\n",
    "\n",
    "print(f\"\\nVariance explained by line in 2D subspace:\")\n",
    "total_2d_var = torch.sum(S_2d**2)\n",
    "line_2d_var = S_2d[0]**2\n",
    "line_2d_ratio = line_2d_var / total_2d_var\n",
    "print(f\"Line explains {line_2d_ratio:.4f} ({100*line_2d_ratio:.1f}%) of 2D variance\")\n",
    "\n",
    "# Final collinearity check using this line direction\n",
    "proj_hd_asst_to_pos2 = torch.dot(dir_assistant_to_pos2_f32, line_direction_hd)\n",
    "proj_hd_asst_to_pos3 = torch.dot(dir_assistant_to_pos3_f32, line_direction_hd)\n",
    "proj_hd_pos2_to_pos3 = torch.dot(dir_pos2_to_pos3_f32, line_direction_hd)\n",
    "\n",
    "print(f\"\\nFinal collinearity check using best-fit line:\")\n",
    "print(f\"assistant -> pos2: {proj_hd_asst_to_pos2:.4f}\")\n",
    "print(f\"assistant -> pos3: {proj_hd_asst_to_pos3:.4f}\")\n",
    "print(f\"pos2 -> pos3:      {proj_hd_pos2_to_pos3:.4f}\")\n",
    "\n",
    "expected_hd = proj_hd_asst_to_pos2 + proj_hd_pos2_to_pos3\n",
    "print(f\"Expected asst->pos3: {expected_hd:.4f}\")\n",
    "print(f\"Difference: {abs(expected_hd - proj_hd_asst_to_pos3):.8f}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "uu9coa3a68q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUMMARY: Finding the Co-linear Basis\n",
      "============================================================\n",
      "We found two approaches to make the vectors co-linear:\n",
      "\n",
      "1. DIRECT PCA on the three mean vectors:\n",
      "   - Captures 59.6% of variance in 1D projection\n",
      "   - Principal direction explains the main variation between the three points\n",
      "\n",
      "2. 2D SUBSPACE + BEST-FIT LINE approach:\n",
      "   - First find 2D subspace spanned by the direction vectors\n",
      "   - Then find best-fit line within this 2D space\n",
      "   - Line captures 59.6% of variance within the 2D subspace\n",
      "\n",
      "BOTH approaches give us a 1D basis (line direction) where:\n",
      "   - The three points (assistant, pos2, pos3) are approximately co-linear\n",
      "   - The direction vectors project consistently onto this line\n",
      "\n",
      "============================================================\n",
      "INTERPRETATION:\n",
      "============================================================\n",
      "The 'collinear basis' represents the PRIMARY TRANSFORMATION AXIS\n",
      "in the high-dimensional activation space that captures the progression:\n",
      "   assistant → pos_2 → pos_3\n",
      "\n",
      "In this basis:\n",
      "• All three mean vectors lie approximately on a line\n",
      "• The transformation from assistant to pos_3 can be decomposed as:\n",
      "  assistant → pos_2 (partial transformation)\n",
      "  pos_2 → pos_3 (completion of transformation)\n",
      "• This suggests a smooth, one-dimensional 'role transformation space'\n",
      "\n",
      "Method comparison:\n",
      "Method 1 (direct PCA) difference: 704.91845703\n",
      "Method 2 (2D→1D) difference:      704.97552490\n",
      "→ Method 1 (direct PCA) achieves better collinearity!\n",
      "\n",
      "FINAL RESULT:\n",
      "Best collinear basis found using: Direct PCA\n",
      "Basis vector shape: torch.Size([4608])\n",
      "This direction in activation space represents the primary axis\n",
      "along which the assistant → pos_2 → pos_3 transformation occurs.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Visualization and final analysis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nSUMMARY: Finding the Co-linear Basis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"We found two approaches to make the vectors co-linear:\")\n",
    "print(\"\\n1. DIRECT PCA on the three mean vectors:\")\n",
    "print(f\"   - Captures {100*variance_ratio:.1f}% of variance in 1D projection\")\n",
    "print(f\"   - Principal direction explains the main variation between the three points\")\n",
    "\n",
    "print(\"\\n2. 2D SUBSPACE + BEST-FIT LINE approach:\")\n",
    "print(f\"   - First find 2D subspace spanned by the direction vectors\")  \n",
    "print(f\"   - Then find best-fit line within this 2D space\")\n",
    "print(f\"   - Line captures {100*line_2d_ratio:.1f}% of variance within the 2D subspace\")\n",
    "\n",
    "print(f\"\\nBOTH approaches give us a 1D basis (line direction) where:\")\n",
    "print(f\"   - The three points (assistant, pos2, pos3) are approximately co-linear\")\n",
    "print(f\"   - The direction vectors project consistently onto this line\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"The 'collinear basis' represents the PRIMARY TRANSFORMATION AXIS\")\n",
    "print(f\"in the high-dimensional activation space that captures the progression:\")\n",
    "print(f\"   assistant → pos_2 → pos_3\")\n",
    "print()\n",
    "print(f\"In this basis:\")\n",
    "print(f\"• All three mean vectors lie approximately on a line\")  \n",
    "print(f\"• The transformation from assistant to pos_3 can be decomposed as:\")\n",
    "print(f\"  assistant → pos_2 (partial transformation)\")\n",
    "print(f\"  pos_2 → pos_3 (completion of transformation)\")\n",
    "print(f\"• This suggests a smooth, one-dimensional 'role transformation space'\")\n",
    "\n",
    "# Compare the two methods\n",
    "print(f\"\\nMethod comparison:\")\n",
    "print(f\"Method 1 (direct PCA) difference: {abs(expected_asst_to_pos3 - actual_asst_to_pos3):.8f}\")\n",
    "print(f\"Method 2 (2D→1D) difference:      {abs(expected_hd - proj_hd_asst_to_pos3):.8f}\")\n",
    "\n",
    "if abs(expected_hd - proj_hd_asst_to_pos3) < abs(expected_asst_to_pos3 - actual_asst_to_pos3):\n",
    "    print(\"→ Method 2 (2D subspace approach) achieves better collinearity!\")\n",
    "    best_direction = line_direction_hd\n",
    "    best_method = \"2D subspace\"\n",
    "else:\n",
    "    print(\"→ Method 1 (direct PCA) achieves better collinearity!\")  \n",
    "    best_direction = principal_direction\n",
    "    best_method = \"Direct PCA\"\n",
    "\n",
    "print(f\"\\nFINAL RESULT:\")\n",
    "print(f\"Best collinear basis found using: {best_method}\")\n",
    "print(f\"Basis vector shape: {best_direction.shape}\")\n",
    "print(f\"This direction in activation space represents the primary axis\")\n",
    "print(f\"along which the assistant → pos_2 → pos_3 transformation occurs.\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573414b",
   "metadata": {},
   "source": [
    "## Compare basis with PCA results from pos23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7464e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results = torch.load(f\"/workspace/{dir}/pca/layer{layer}_{type}.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1kct9ran2te",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing with PCA first principal component\n",
      "==================================================\n",
      "PCA first PC shape: torch.Size([4608])\n",
      "Our collinear basis shape: torch.Size([4608])\n",
      "\n",
      "Cosine similarity between:\n",
      "  - PCA first PC (from role vectors)\n",
      "  - Our collinear basis (assistant→pos_2→pos_3)\n",
      "  = 0.4265\n",
      "\n",
      "Interpretation:\n",
      "△ WEAK alignment\n",
      "  Some relationship but largely independent axes\n",
      "\n",
      "Projections of our three points onto PCA first PC:\n",
      "Assistant: -733.37\n",
      "Pos_2:     -640.97\n",
      "Pos_3:     -515.32\n",
      "\n",
      "Direction consistency check:\n",
      "assistant→pos2 along PCA PC: 92.40\n",
      "assistant→pos3 along PCA PC: 218.05\n",
      "pos2→pos3 along PCA PC:      125.65\n",
      "✓ All transformations go in the SAME direction along PCA axis\n",
      "  This confirms assistant→pos_2→pos_3 is a consistent progression\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare with PCA results from other role vectors\n",
    "print(\"\\nComparing with PCA first principal component\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load your pca_results (assuming this contains the PCA object)\n",
    "# The first PC direction vector is stored in pca.components_[0]\n",
    "\n",
    "# Get the first principal component from your PCA analysis\n",
    "# Note: pca.components_ are already in the original feature space (4608D)\n",
    "pca_first_pc = pca_results['pca'].components_[0]  # Shape should be [4608]\n",
    "\n",
    "# Convert to torch tensor and ensure float32\n",
    "pca_first_pc_tensor = torch.tensor(pca_first_pc, dtype=torch.float32)\n",
    "\n",
    "print(f\"PCA first PC shape: {pca_first_pc_tensor.shape}\")\n",
    "print(f\"Our collinear basis shape: {best_direction.shape}\")\n",
    "\n",
    "# Calculate cosine similarity between the two directions\n",
    "cosine_sim = torch.cosine_similarity(\n",
    "    pca_first_pc_tensor.unsqueeze(0), \n",
    "    best_direction.unsqueeze(0)\n",
    ").item()\n",
    "\n",
    "print(f\"\\nCosine similarity between:\")\n",
    "print(f\"  - PCA first PC (from role vectors)\")\n",
    "print(f\"  - Our collinear basis (assistant→pos_2→pos_3)\")\n",
    "print(f\"  = {cosine_sim:.4f}\")\n",
    "\n",
    "# Interpret the similarity\n",
    "print(f\"\\nInterpretation:\")\n",
    "if abs(cosine_sim) > 0.8:\n",
    "    direction = \"same\" if cosine_sim > 0 else \"opposite\"\n",
    "    print(f\"✓ STRONG alignment ({direction} direction)\")\n",
    "    print(f\"  The role transformation axis we found is very similar\")\n",
    "    print(f\"  to the main axis of variation across different roles!\")\n",
    "elif abs(cosine_sim) > 0.5:\n",
    "    direction = \"same\" if cosine_sim > 0 else \"opposite\" \n",
    "    print(f\"○ MODERATE alignment ({direction} direction)\")\n",
    "    print(f\"  There's significant overlap between the axes\")\n",
    "elif abs(cosine_sim) > 0.2:\n",
    "    print(f\"△ WEAK alignment\")\n",
    "    print(f\"  Some relationship but largely independent axes\")\n",
    "else:\n",
    "    print(f\"✗ NO alignment\")\n",
    "    print(f\"  The axes are essentially orthogonal/independent\")\n",
    "\n",
    "# Additional analysis: project our three points onto the PCA first PC\n",
    "proj_asst_pca = torch.dot(mean_assistant_f32, pca_first_pc_tensor)\n",
    "proj_pos2_pca = torch.dot(mean_pos_2_f32, pca_first_pc_tensor)  \n",
    "proj_pos3_pca = torch.dot(mean_pos_3_f32, pca_first_pc_tensor)\n",
    "\n",
    "print(f\"\\nProjections of our three points onto PCA first PC:\")\n",
    "print(f\"Assistant: {proj_asst_pca:.2f}\")\n",
    "print(f\"Pos_2:     {proj_pos2_pca:.2f}\")\n",
    "print(f\"Pos_3:     {proj_pos3_pca:.2f}\")\n",
    "\n",
    "# Check if they're ordered consistently\n",
    "assistant_to_pos2_pca = proj_pos2_pca - proj_asst_pca\n",
    "assistant_to_pos3_pca = proj_pos3_pca - proj_asst_pca\n",
    "pos2_to_pos3_pca = proj_pos3_pca - proj_pos2_pca\n",
    "\n",
    "print(f\"\\nDirection consistency check:\")\n",
    "print(f\"assistant→pos2 along PCA PC: {assistant_to_pos2_pca:.2f}\")\n",
    "print(f\"assistant→pos3 along PCA PC: {assistant_to_pos3_pca:.2f}\")\n",
    "print(f\"pos2→pos3 along PCA PC:      {pos2_to_pos3_pca:.2f}\")\n",
    "\n",
    "if assistant_to_pos2_pca * assistant_to_pos3_pca > 0 and assistant_to_pos2_pca * pos2_to_pos3_pca > 0:\n",
    "    print(\"✓ All transformations go in the SAME direction along PCA axis\")\n",
    "    print(\"  This confirms assistant→pos_2→pos_3 is a consistent progression\")\n",
    "else:\n",
    "    print(\"△ Mixed directions - the progression may not be linear along PCA axis\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cde9bb",
   "metadata": {},
   "source": [
    "## Distance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "i4gad3ona7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing Assistant-to-Role vs Inter-Role Distances\n",
      "============================================================\n",
      "Role pos_2 vectors shape: torch.Size([173, 4608])\n",
      "Role pos_3 vectors shape: torch.Size([173, 4608])\n",
      "\n",
      "Calculating pairwise distances between pos_2 vectors...\n",
      "Computed 14878 pairwise pos_2 distances\n",
      "Calculating pairwise distances between pos_3 vectors...\n",
      "Computed 14878 pairwise pos_3 distances\n",
      "Computed 173 assistant→pos_2 distances\n",
      "Computed 173 assistant→pos_3 distances\n",
      "\n",
      "============================================================\n",
      "DISTANCE COMPARISON RESULTS\n",
      "============================================================\n",
      "\n",
      "PAIRWISE INTER-ROLE DISTANCES:\n",
      "pos_2 vs pos_2: mean=744.4, std=274.9\n",
      "                range=[194.1, 2464.2]\n",
      "pos_3 vs pos_3: mean=926.0, std=319.5\n",
      "                range=[170.3, 2511.3]\n",
      "\n",
      "ASSISTANT-TO-ROLE DISTANCES:\n",
      "assistant→pos_2: mean=690.2, std=199.8\n",
      "                 range=[299.4, 2024.2]\n",
      "assistant→pos_3: mean=818.3, std=275.9\n",
      "                 range=[457.3, 1979.4]\n",
      "\n",
      "OUR SPECIFIC DISTANCES (assistant ↔ mean vectors):\n",
      "assistant→mean_pos_2: 448.0\n",
      "assistant→mean_pos_3: 508.0\n",
      "\n",
      "COMPARATIVE ANALYSIS:\n",
      "• Our assistant→mean_pos_2 distance (448) is at the 8.1th percentile\n",
      "• Our assistant→mean_pos_3 distance (508) is at the 2.3th percentile\n",
      "\n",
      "• Mean inter-role pos_2 distance: 744.4\n",
      "• Mean assistant→role pos_2 distance: 690.2\n",
      "  Ratio: 0.93x\n",
      "• Mean inter-role pos_3 distance: 926.0\n",
      "• Mean assistant→role pos_3 distance: 818.3\n",
      "  Ratio: 0.88x\n",
      "\n",
      "INTERPRETATION:\n",
      "○ Assistant distance to roles is SIMILAR to inter-role distances\n",
      "  This suggests assistant is embedded within role space\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare assistant->role distances with inter-role distances\n",
    "print(\"\\nComparing Assistant-to-Role vs Inter-Role Distances\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# We already have individual role vectors: pos_2_activations and pos_3_activations\n",
    "# Shape: [173 roles, 46 layers, 4608 features]\n",
    "\n",
    "# Extract vectors for our layer\n",
    "role_pos2_vectors = pos_2_activations[:, layer, :].float()  # Shape: [173, 4608]\n",
    "role_pos3_vectors = pos_3_activations[:, layer, :].float()  # Shape: [173, 4608]\n",
    "\n",
    "print(f\"Role pos_2 vectors shape: {role_pos2_vectors.shape}\")\n",
    "print(f\"Role pos_3 vectors shape: {role_pos3_vectors.shape}\")\n",
    "\n",
    "# Calculate all pairwise distances between pos_2 vectors\n",
    "print(\"\\nCalculating pairwise distances between pos_2 vectors...\")\n",
    "pos2_pairwise_distances = []\n",
    "n_roles = role_pos2_vectors.shape[0]\n",
    "\n",
    "for i in range(n_roles):\n",
    "    for j in range(i+1, n_roles):  # Only upper triangle to avoid duplicates\n",
    "        dist = torch.norm(role_pos2_vectors[i] - role_pos2_vectors[j]).item()\n",
    "        pos2_pairwise_distances.append(dist)\n",
    "\n",
    "pos2_pairwise_distances = np.array(pos2_pairwise_distances)\n",
    "print(f\"Computed {len(pos2_pairwise_distances)} pairwise pos_2 distances\")\n",
    "\n",
    "# Calculate all pairwise distances between pos_3 vectors  \n",
    "print(\"Calculating pairwise distances between pos_3 vectors...\")\n",
    "pos3_pairwise_distances = []\n",
    "\n",
    "for i in range(n_roles):\n",
    "    for j in range(i+1, n_roles):\n",
    "        dist = torch.norm(role_pos3_vectors[i] - role_pos3_vectors[j]).item()\n",
    "        pos3_pairwise_distances.append(dist)\n",
    "\n",
    "pos3_pairwise_distances = np.array(pos3_pairwise_distances)\n",
    "print(f\"Computed {len(pos3_pairwise_distances)} pairwise pos_3 distances\")\n",
    "\n",
    "# Calculate distances from assistant to each role's pos_2 and pos_3\n",
    "assistant_to_pos2_distances = []\n",
    "assistant_to_pos3_distances = []\n",
    "\n",
    "for i in range(n_roles):\n",
    "    dist_pos2 = torch.norm(role_pos2_vectors[i] - mean_assistant_f32).item()\n",
    "    dist_pos3 = torch.norm(role_pos3_vectors[i] - mean_assistant_f32).item()\n",
    "    assistant_to_pos2_distances.append(dist_pos2)\n",
    "    assistant_to_pos3_distances.append(dist_pos3)\n",
    "\n",
    "assistant_to_pos2_distances = np.array(assistant_to_pos2_distances)\n",
    "assistant_to_pos3_distances = np.array(assistant_to_pos3_distances)\n",
    "\n",
    "print(f\"Computed {len(assistant_to_pos2_distances)} assistant→pos_2 distances\")\n",
    "print(f\"Computed {len(assistant_to_pos3_distances)} assistant→pos_3 distances\")\n",
    "\n",
    "# Compare statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISTANCE COMPARISON RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nPAIRWISE INTER-ROLE DISTANCES:\")\n",
    "print(f\"pos_2 vs pos_2: mean={pos2_pairwise_distances.mean():.1f}, std={pos2_pairwise_distances.std():.1f}\")\n",
    "print(f\"                range=[{pos2_pairwise_distances.min():.1f}, {pos2_pairwise_distances.max():.1f}]\")\n",
    "print(f\"pos_3 vs pos_3: mean={pos3_pairwise_distances.mean():.1f}, std={pos3_pairwise_distances.std():.1f}\")\n",
    "print(f\"                range=[{pos3_pairwise_distances.min():.1f}, {pos3_pairwise_distances.max():.1f}]\")\n",
    "\n",
    "print(f\"\\nASSISTANT-TO-ROLE DISTANCES:\")\n",
    "print(f\"assistant→pos_2: mean={assistant_to_pos2_distances.mean():.1f}, std={assistant_to_pos2_distances.std():.1f}\")\n",
    "print(f\"                 range=[{assistant_to_pos2_distances.min():.1f}, {assistant_to_pos2_distances.max():.1f}]\")\n",
    "print(f\"assistant→pos_3: mean={assistant_to_pos3_distances.mean():.1f}, std={assistant_to_pos3_distances.std():.1f}\")\n",
    "print(f\"                 range=[{assistant_to_pos3_distances.min():.1f}, {assistant_to_pos3_distances.max():.1f}]\")\n",
    "\n",
    "print(f\"\\nOUR SPECIFIC DISTANCES (assistant ↔ mean vectors):\")\n",
    "print(f\"assistant→mean_pos_2: {mag_assistant_to_pos2:.1f}\")\n",
    "print(f\"assistant→mean_pos_3: {mag_assistant_to_pos3:.1f}\")\n",
    "\n",
    "# Compare ratios and relative positioning\n",
    "print(f\"\\nCOMPARATIVE ANALYSIS:\")\n",
    "\n",
    "# How do our specific distances compare to the distributions?\n",
    "pos2_percentile = (assistant_to_pos2_distances < mag_assistant_to_pos2).mean() * 100\n",
    "pos3_percentile = (assistant_to_pos3_distances < mag_assistant_to_pos3).mean() * 100\n",
    "\n",
    "print(f\"• Our assistant→mean_pos_2 distance ({mag_assistant_to_pos2:.0f}) is at the {pos2_percentile:.1f}th percentile\")\n",
    "print(f\"• Our assistant→mean_pos_3 distance ({mag_assistant_to_pos3:.0f}) is at the {pos3_percentile:.1f}th percentile\")\n",
    "\n",
    "# Compare with inter-role variation\n",
    "inter_role_pos2_mean = pos2_pairwise_distances.mean()\n",
    "inter_role_pos3_mean = pos3_pairwise_distances.mean()\n",
    "assistant_role_pos2_mean = assistant_to_pos2_distances.mean()  \n",
    "assistant_role_pos3_mean = assistant_to_pos3_distances.mean()\n",
    "\n",
    "print(f\"\\n• Mean inter-role pos_2 distance: {inter_role_pos2_mean:.1f}\")\n",
    "print(f\"• Mean assistant→role pos_2 distance: {assistant_role_pos2_mean:.1f}\")\n",
    "print(f\"  Ratio: {assistant_role_pos2_mean/inter_role_pos2_mean:.2f}x\")\n",
    "\n",
    "print(f\"• Mean inter-role pos_3 distance: {inter_role_pos3_mean:.1f}\")\n",
    "print(f\"• Mean assistant→role pos_3 distance: {assistant_role_pos3_mean:.1f}\")\n",
    "print(f\"  Ratio: {assistant_role_pos3_mean/inter_role_pos3_mean:.2f}x\")\n",
    "\n",
    "print(f\"\\nINTERPRETATION:\")\n",
    "if assistant_role_pos2_mean/inter_role_pos2_mean < 0.8:\n",
    "    print(f\"✓ Assistant is CLOSER to roles than roles are to each other\")\n",
    "    print(f\"  This suggests assistant represents a 'center point' in role space\")\n",
    "elif assistant_role_pos2_mean/inter_role_pos2_mean > 1.2:\n",
    "    print(f\"△ Assistant is FARTHER from roles than roles are from each other\")\n",
    "    print(f\"  This suggests assistant is outside the main role cluster\")\n",
    "else:\n",
    "    print(f\"○ Assistant distance to roles is SIMILAR to inter-role distances\")\n",
    "    print(f\"  This suggests assistant is embedded within role space\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
