{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Diffing Analysis\n",
    "\n",
    "This notebook analyzes the differences between base and chat models by comparing feature activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model data from: /workspace/results/4_diffing/gemma_trainer131k-l0-114_layer20/1000_prompts/base.pt\n",
      "Loading chat model data from: /workspace/results/4_diffing/gemma_trainer131k-l0-114_layer20/1000_prompts/chat.pt\n",
      "Output directory: gemma_trainer131k-l0-114_layer20/1000_prompts\n",
      "\n",
      "Base data keys: ['model', 'newline', 'metadata']\n",
      "Chat data keys: ['model', 'newline', 'metadata']\n",
      "Base metadata: {'source': 'gemma_trainer131k-l0-114_layer20_base', 'model_type': 'gemma', 'model_ver': 'base', 'sae_layer': 20, 'sae_trainer': '131k-l0-114', 'num_prompts': 1000, 'num_features': 131072, 'token_types': ['model', 'newline']}\n",
      "Chat metadata: {'source': 'gemma_trainer131k-l0-114_layer20_chat', 'model_type': 'gemma', 'model_ver': 'chat', 'sae_layer': 20, 'sae_trainer': '131k-l0-114', 'num_prompts': 1000, 'num_features': 131072, 'token_types': ['model', 'newline']}\n",
      "\n",
      "Base token types: ['model', 'newline']\n",
      "Chat token types: ['model', 'newline']\n",
      "Processing 2 token types: ['model', 'newline']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "MODEL_TYPE = \"gemma\"\n",
    "SAE_LAYER = 20\n",
    "SAE_TRAINER = \"131k-l0-114\"\n",
    "TOKEN_OFFSETS = {\"model\": -1, \"newline\": 0}\n",
    "N_PROMPTS = 1000\n",
    "\n",
    "# File paths\n",
    "BASE_FILE = f\"/workspace/results/4_diffing/{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}/{N_PROMPTS}_prompts/base.pt\"\n",
    "CHAT_FILE = f\"/workspace/results/4_diffing/{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}/{N_PROMPTS}_prompts/chat.pt\"\n",
    "\n",
    "# Output directory\n",
    "SOURCE = f\"{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}/{N_PROMPTS}_prompts\"\n",
    "OUTPUT_DIR = Path(f\"./{SOURCE}\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Loading base model data from: {BASE_FILE}\")\n",
    "print(f\"Loading chat model data from: {CHAT_FILE}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Load the PyTorch files\n",
    "base_data = torch.load(BASE_FILE)\n",
    "chat_data = torch.load(CHAT_FILE)\n",
    "\n",
    "print(f\"\\nBase data keys: {list(base_data.keys())}\")\n",
    "print(f\"Chat data keys: {list(chat_data.keys())}\")\n",
    "print(f\"Base metadata: {base_data['metadata']}\")\n",
    "print(f\"Chat metadata: {chat_data['metadata']}\")\n",
    "\n",
    "# Verify token types match\n",
    "base_tokens = [k for k in base_data.keys() if k != 'metadata']\n",
    "chat_tokens = [k for k in chat_data.keys() if k != 'metadata']\n",
    "print(f\"\\nBase token types: {base_tokens}\")\n",
    "print(f\"Chat token types: {chat_tokens}\")\n",
    "assert base_tokens == chat_tokens, \"Token types don't match between base and chat!\"\n",
    "\n",
    "token_types = base_tokens\n",
    "print(f\"Processing {len(token_types)} token types: {token_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ID: 42398\n",
      "\n",
      "Token Type: model\n",
      "Base model Mean: 0.007804230786859989\n",
      "Chat model Mean: 0.0\n",
      "Base model Num Active: 2\n",
      "Chat model Num Active: 0\n",
      "\n",
      "\n",
      "Token Type: newline\n",
      "Base newline Mean: 0.0035058618523180485\n",
      "Chat newline Mean: 0.0\n",
      "Base newline Num Active: 1\n",
      "Chat newline Num Active: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the statistics for a given feature_id\n",
    "def print_feature_stats(feature_id, base_data, chat_data):\n",
    "    print(f\"Feature ID: {feature_id}\\n\")\n",
    "    for key in TOKEN_OFFSETS.keys():\n",
    "        print(f\"Token Type: {key}\")\n",
    "        print(f\"Base {key} Mean: {base_data[key]['all_mean'][feature_id]}\")\n",
    "        print(f\"Chat {key} Mean: {chat_data[key]['all_mean'][feature_id]}\")\n",
    "        print(f\"Base {key} Num Active: {base_data[key]['num_active'][feature_id]}\")\n",
    "        print(f\"Chat {key} Num Active: {chat_data[key]['num_active'][feature_id]}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "print_feature_stats(42398, base_data, chat_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Analyzing metric: all_mean\n",
      "==================================================\n",
      "Processing all_mean for token type: model\n",
      "Processing all_mean for token type: newline\n",
      "Found 50 total records for all_mean\n",
      "\n",
      "Top 5 features for all_mean:\n",
      " rank  feature_id   token  all_mean_base  all_mean_chat  all_mean_diff\n",
      "    1      116246   model       6.163264     236.286087     230.122818\n",
      "    1      116246 newline      13.816084     107.583450      93.767365\n",
      "    2       66831   model       1.833458      41.117966      39.284508\n",
      "    3       55935   model       0.000000      23.778404      23.778404\n",
      "    4       49865   model       5.875016      27.856947      21.981932\n",
      "\n",
      "Summary statistics for all_mean:\n",
      "Max difference: 230.122818\n",
      "Min difference: 2.087267\n",
      "Mean difference: 12.860428\n",
      "\n",
      "==================================================\n",
      "Analysis complete!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def find_top_increases(base_data, chat_data, token_types, metric_name, top_k=20):\n",
    "    \"\"\"\n",
    "    Find top features with greatest increase in specified metric from base to chat.\n",
    "    \n",
    "    Args:\n",
    "        base_data: Base model data dictionary\n",
    "        chat_data: Chat model data dictionary  \n",
    "        token_types: List of token types to process\n",
    "        metric_name: Name of metric to analyze ('all_mean', 'active_mean', 'sparsity')\n",
    "        top_k: Number of top features to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with top features and their differences\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for token_type in token_types:\n",
    "        print(f\"Processing {metric_name} for token type: {token_type}\")\n",
    "        \n",
    "        # Get base and chat tensors for this metric\n",
    "        base_tensor = base_data[token_type][metric_name]\n",
    "        chat_tensor = chat_data[token_type][metric_name]\n",
    "        \n",
    "        # Calculate difference (chat - base)\n",
    "        diff_tensor = chat_tensor - base_tensor\n",
    "        \n",
    "        # Get top k features with largest increases\n",
    "        top_values, top_indices = torch.topk(diff_tensor, top_k)\n",
    "        \n",
    "        # Convert to lists for DataFrame\n",
    "        top_values = top_values.tolist()\n",
    "        top_indices = top_indices.tolist()\n",
    "        \n",
    "        # Get corresponding base and chat values\n",
    "        base_values = base_tensor[top_indices].tolist()\n",
    "        chat_values = chat_tensor[top_indices].tolist()\n",
    "        \n",
    "        # Create records for this token type\n",
    "        for i, (feat_idx, diff_val, base_val, chat_val) in enumerate(zip(top_indices, top_values, base_values, chat_values)):\n",
    "            record = {\n",
    "                'rank': i + 1,\n",
    "                'feature_id': feat_idx,\n",
    "                'token': token_type,\n",
    "                f'{metric_name}_base': base_val,\n",
    "                f'{metric_name}_chat': chat_val,\n",
    "                f'{metric_name}_diff': diff_val,\n",
    "            }\n",
    "            all_results.append(record)\n",
    "    \n",
    "    # Convert to DataFrame and sort by difference (descending)\n",
    "    df = pd.DataFrame(all_results)\n",
    "    df = df.sort_values(f'{metric_name}_diff', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Found {len(df)} total records for {metric_name}\")\n",
    "    return df\n",
    "\n",
    "# Analyze all three metrics\n",
    "metrics_to_analyze = ['all_mean']\n",
    "results = {}\n",
    "\n",
    "for metric in metrics_to_analyze:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Analyzing metric: {metric}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    df = find_top_increases(base_data, chat_data, token_types, metric, top_k=25)\n",
    "    results[metric] = df\n",
    "    \n",
    "    # Show preview\n",
    "    print(f\"\\nTop 5 features for {metric}:\")\n",
    "    print(df.head().to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nSummary statistics for {metric}:\")\n",
    "    print(f\"Max difference: {df[f'{metric}_diff'].max():.6f}\")\n",
    "    print(f\"Min difference: {df[f'{metric}_diff'].min():.6f}\")\n",
    "    print(f\"Mean difference: {df[f'{metric}_diff'].mean():.6f}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Analysis complete!\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to CSV files...\n",
      "Saved 50 records to: gemma_trainer131k-l0-114_layer20/1000_prompts/top_all_mean.csv\n",
      "  File size: 3.3 KB\n",
      "\n",
      "==================================================\n",
      "All results saved!\n",
      "==================================================\n",
      "\n",
      "Summary of saved files:\n",
      "  top_chat_all_mean.csv: Top 100 features per token type with greatest all_mean increase\n",
      "\n",
      "Each file contains:\n",
      "  - feature_id: SAE feature index\n",
      "  - token: Token position type (asst, endheader, newline)\n",
      "  - all_mean_base: Base model value\n",
      "  - all_mean_chat: Chat model value\n",
      "  - all_mean_diff: Difference (chat - base)\n",
      "  - all_mean_ratio: Ratio (chat / base)\n",
      "  - rank: Rank within token type (1-100)\n",
      "  - model_type, sae_layer, sae_trainer: Configuration info\n",
      "\n",
      "Total features analyzed: 131,072\n",
      "Total records per file: 50\n",
      "Files ready for further analysis!\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV files\n",
    "print(\"Saving results to CSV files...\")\n",
    "\n",
    "for metric, df in results.items():\n",
    "    # Create output filename\n",
    "    output_file = OUTPUT_DIR / f\"top_{metric}.csv\"\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved {len(df)} records to: {output_file}\")\n",
    "    \n",
    "    # Show file info\n",
    "    file_size = output_file.stat().st_size / 1024  # KB\n",
    "    print(f\"  File size: {file_size:.1f} KB\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"All results saved!\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Summary of what was saved\n",
    "print(f\"\\nSummary of saved files:\")\n",
    "for metric in metrics_to_analyze:\n",
    "    output_file = OUTPUT_DIR / f\"top_chat_{metric}.csv\"\n",
    "    print(f\"  {output_file.name}: Top 100 features per token type with greatest {metric} increase\")\n",
    "\n",
    "print(f\"\\nEach file contains:\")\n",
    "print(f\"  - feature_id: SAE feature index\")\n",
    "print(f\"  - token: Token position type (asst, endheader, newline)\")\n",
    "print(f\"  - {metric}_base: Base model value\")\n",
    "print(f\"  - {metric}_chat: Chat model value\") \n",
    "print(f\"  - {metric}_diff: Difference (chat - base)\")\n",
    "print(f\"  - {metric}_ratio: Ratio (chat / base)\")\n",
    "print(f\"  - rank: Rank within token type (1-100)\")\n",
    "print(f\"  - model_type, sae_layer, sae_trainer: Configuration info\")\n",
    "\n",
    "print(f\"\\nTotal features analyzed: {base_data['metadata']['num_features']:,}\")\n",
    "print(f\"Total records per file: {len(results['all_mean'])}\")\n",
    "print(f\"Files ready for further analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing features with largest decreases (base → chat)...\n",
      "\n",
      "==================================================\n",
      "Analyzing decreases for metric: all_mean\n",
      "==================================================\n",
      "Processing all_mean decreases for token type: asst\n",
      "Processing all_mean decreases for token type: endheader\n",
      "Processing all_mean decreases for token type: newline\n",
      "Found 300 total records for all_mean decreases\n",
      "\n",
      "Top 5 features with largest all_mean decreases:\n",
      " rank  feature_id     token  all_mean_base  all_mean_chat  all_mean_diff                                                                 link\n",
      "    1       52951 endheader      10.129719       0.128562     -10.001156 https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/52951\n",
      "    1       98290   newline       7.667828       0.000000      -7.667828 https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/98290\n",
      "    1       75005      asst       7.630891       0.004312      -7.626578 https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/75005\n",
      "    2       41864      asst       7.587781       0.990922      -6.596859 https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/41864\n",
      "    2       38777 endheader       5.829219       0.000000      -5.829219 https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/38777\n",
      "\n",
      "Summary statistics for all_mean decreases:\n",
      "Most negative difference: -10.001156\n",
      "Least negative difference: -0.096688\n",
      "Mean difference: -1.035535\n",
      "\n",
      "==================================================\n",
      "Analyzing decreases for metric: active_mean\n",
      "==================================================\n",
      "Processing active_mean decreases for token type: asst\n",
      "Processing active_mean decreases for token type: endheader\n",
      "Processing active_mean decreases for token type: newline\n",
      "Found 300 total records for active_mean decreases\n",
      "\n",
      "Top 5 features with largest active_mean decreases:\n",
      " rank  feature_id     token  active_mean_base  active_mean_chat  active_mean_diff                                                                  link\n",
      "    1       52951 endheader         10.464585          2.216595         -8.247991  https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/52951\n",
      "    1       11481   newline          8.062500          0.000000         -8.062500  https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/11481\n",
      "    2       98290   newline          7.979010          0.000000         -7.979010  https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/98290\n",
      "    3      109981   newline          7.875000          0.000000         -7.875000 https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/109981\n",
      "    4       52951   newline          7.781250          0.000000         -7.781250  https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/52951\n",
      "\n",
      "Summary statistics for active_mean decreases:\n",
      "Most negative difference: -8.247991\n",
      "Least negative difference: -3.001507\n",
      "Mean difference: -4.120370\n",
      "\n",
      "==================================================\n",
      "Analyzing decreases for metric: sparsity\n",
      "==================================================\n",
      "Processing sparsity decreases for token type: asst\n",
      "Processing sparsity decreases for token type: endheader\n",
      "Processing sparsity decreases for token type: newline\n",
      "Found 300 total records for sparsity decreases\n",
      "\n",
      "Top 5 features with largest sparsity decreases:\n",
      " rank  feature_id     token  sparsity_base  sparsity_chat  sparsity_diff                                                                  link\n",
      "    1       75005      asst          0.975          0.001         -0.974  https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/75005\n",
      "    1       98290   newline          0.961          0.000         -0.961  https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/98290\n",
      "    1      130058 endheader          0.960          0.000         -0.960 https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/130058\n",
      "    2       38777 endheader          0.959          0.000         -0.959  https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/38777\n",
      "    3      113257 endheader          0.940          0.000         -0.940 https://www.neuronpedia.org/llama3.1-8b/15-llamascope-res-131k/113257\n",
      "\n",
      "Summary statistics for sparsity decreases:\n",
      "Most negative difference: -0.974000\n",
      "Least negative difference: -0.038000\n",
      "Mean difference: -0.294947\n",
      "\n",
      "Saving decrease results to CSV files...\n",
      "Saved 300 records to: llama_trainer32x_layer15/top_base_all_mean.csv\n",
      "Saved 300 records to: llama_trainer32x_layer15/top_base_active_mean.csv\n",
      "Saved 300 records to: llama_trainer32x_layer15/top_base_sparsity.csv\n",
      "\n",
      "Now you have both increases and decreases saved:\n",
      "- Increases: top_{metric}.csv (features that increased from base to chat)\n",
      "- Decreases: top_{metric}_decreases.csv (features that decreased from base to chat)\n"
     ]
    }
   ],
   "source": [
    "# Find features with largest decreases (base - chat)\n",
    "def find_top_decreases(base_data, chat_data, token_types, metric_name, top_k=100):\n",
    "    \"\"\"\n",
    "    Find top features with greatest decrease in specified metric from base to chat.\n",
    "    \n",
    "    Args:\n",
    "        base_data: Base model data dictionary\n",
    "        chat_data: Chat model data dictionary  \n",
    "        token_types: List of token types to process\n",
    "        metric_name: Name of metric to analyze ('all_mean', 'active_mean', 'sparsity')\n",
    "        top_k: Number of top features to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with top features and their differences\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for token_type in token_types:\n",
    "        print(f\"Processing {metric_name} decreases for token type: {token_type}\")\n",
    "        \n",
    "        # Get base and chat tensors for this metric\n",
    "        base_tensor = base_data[token_type][metric_name]\n",
    "        chat_tensor = chat_data[token_type][metric_name]\n",
    "        \n",
    "        # Calculate difference (chat - base)\n",
    "        diff_tensor = chat_tensor - base_tensor\n",
    "        \n",
    "        # Get top k features with largest decreases (most negative differences)\n",
    "        top_values, top_indices = torch.topk(-diff_tensor, top_k)  # Note the negative sign\n",
    "        top_values = -top_values  # Convert back to actual differences\n",
    "        \n",
    "        # Convert to lists for DataFrame\n",
    "        top_values = top_values.tolist()\n",
    "        top_indices = top_indices.tolist()\n",
    "        \n",
    "        # Get corresponding base and chat values\n",
    "        base_values = base_tensor[top_indices].tolist()\n",
    "        chat_values = chat_tensor[top_indices].tolist()\n",
    "        \n",
    "        # Create records for this token type\n",
    "        for i, (feat_idx, diff_val, base_val, chat_val) in enumerate(zip(top_indices, top_values, base_values, chat_values)):\n",
    "            record = {\n",
    "                'rank': i + 1,\n",
    "                'feature_id': feat_idx,\n",
    "                'token': token_type,\n",
    "                f'{metric_name}_base': base_val,\n",
    "                f'{metric_name}_chat': chat_val,\n",
    "                f'{metric_name}_diff': diff_val,\n",
    "                'link': LLAMA_LINK_FORMAT + str(feat_idx)\n",
    "            }\n",
    "            all_results.append(record)\n",
    "    \n",
    "    # Convert to DataFrame and sort by difference (ascending - most negative first)\n",
    "    df = pd.DataFrame(all_results)\n",
    "    df = df.sort_values(f'{metric_name}_diff', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Found {len(df)} total records for {metric_name} decreases\")\n",
    "    return df\n",
    "\n",
    "# Analyze decreases for all three metrics\n",
    "print(\"Analyzing features with largest decreases (base → chat)...\")\n",
    "decrease_results = {}\n",
    "\n",
    "for metric in metrics_to_analyze:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Analyzing decreases for metric: {metric}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    df = find_top_decreases(base_data, chat_data, token_types, metric, top_k=100)\n",
    "    decrease_results[metric] = df\n",
    "    \n",
    "    # Show preview\n",
    "    print(f\"\\nTop 5 features with largest {metric} decreases:\")\n",
    "    print(df.head().to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nSummary statistics for {metric} decreases:\")\n",
    "    print(f\"Most negative difference: {df[f'{metric}_diff'].min():.6f}\")\n",
    "    print(f\"Least negative difference: {df[f'{metric}_diff'].max():.6f}\")\n",
    "    print(f\"Mean difference: {df[f'{metric}_diff'].mean():.6f}\")\n",
    "\n",
    "# Save decrease results to CSV files\n",
    "print(\"\\nSaving decrease results to CSV files...\")\n",
    "\n",
    "for metric, df in decrease_results.items():\n",
    "    # Create output filename\n",
    "    output_file = OUTPUT_DIR / f\"top_base_{metric}.csv\"\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved {len(df)} records to: {output_file}\")\n",
    "\n",
    "print(f\"\\nNow you have both increases and decreases saved:\")\n",
    "print(f\"- Increases: top_{{metric}}.csv (features that increased from base to chat)\")\n",
    "print(f\"- Decreases: top_{{metric}}_decreases.csv (features that decreased from base to chat)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
