{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Diffing Analysis\n",
    "\n",
    "This notebook analyzes the differences between base and chat models by comparing feature activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model data from: /workspace/results/4_diffing/1_llama_trainer32x_layer15_base.pt\n",
      "Loading chat model data from: /workspace/results/4_diffing/1_llama_trainer32x_layer15_chat.pt\n",
      "Output directory: /root/git/persona-subspace/sae_feature_analysis/results/4_diffing/llama_trainer32x_layer15\n",
      "\n",
      "Base data keys: ['asst', 'endheader', 'newline', 'metadata']\n",
      "Chat data keys: ['asst', 'endheader', 'newline', 'metadata']\n",
      "Base metadata: {'source': 'llama_trainer32x_layer15_base', 'model_type': 'llama', 'model_ver': 'base', 'sae_layer': 15, 'sae_trainer': '32x', 'num_prompts': 1000, 'num_features': 131072, 'token_types': ['asst', 'endheader', 'newline']}\n",
      "Chat metadata: {'source': 'llama_trainer32x_layer15_chat', 'model_type': 'llama', 'model_ver': 'chat', 'sae_layer': 15, 'sae_trainer': '32x', 'num_prompts': 1000, 'num_features': 131072, 'token_types': ['asst', 'endheader', 'newline']}\n",
      "\n",
      "Base token types: ['asst', 'endheader', 'newline']\n",
      "Chat token types: ['asst', 'endheader', 'newline']\n",
      "Processing 3 token types: ['asst', 'endheader', 'newline']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "MODEL_TYPE = \"llama\"\n",
    "SAE_LAYER = 15\n",
    "SAE_TRAINER = \"32x\"\n",
    "TOKEN_OFFSETS = {\"asst\": -2, \"endheader\": -1, \"newline\": 0}\n",
    "\n",
    "# File paths\n",
    "BASE_FILE = f\"/workspace/results/4_diffing/1_{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}_base.pt\"\n",
    "CHAT_FILE = f\"/workspace/results/4_diffing/1_{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}_chat.pt\"\n",
    "\n",
    "# Output directory\n",
    "SOURCE = f\"{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}\"\n",
    "OUTPUT_DIR = Path(f\"./{SOURCE}\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"Loading base model data from: {BASE_FILE}\")\n",
    "print(f\"Loading chat model data from: {CHAT_FILE}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Load the PyTorch files\n",
    "base_data = torch.load(BASE_FILE)\n",
    "chat_data = torch.load(CHAT_FILE)\n",
    "\n",
    "print(f\"\\nBase data keys: {list(base_data.keys())}\")\n",
    "print(f\"Chat data keys: {list(chat_data.keys())}\")\n",
    "print(f\"Base metadata: {base_data['metadata']}\")\n",
    "print(f\"Chat metadata: {chat_data['metadata']}\")\n",
    "\n",
    "# Verify token types match\n",
    "base_tokens = [k for k in base_data.keys() if k != 'metadata']\n",
    "chat_tokens = [k for k in chat_data.keys() if k != 'metadata']\n",
    "print(f\"\\nBase token types: {base_tokens}\")\n",
    "print(f\"Chat token types: {chat_tokens}\")\n",
    "assert base_tokens == chat_tokens, \"Token types don't match between base and chat!\"\n",
    "\n",
    "token_types = base_tokens\n",
    "print(f\"Processing {len(token_types)} token types: {token_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Analyzing metric: all_mean\n",
      "==================================================\n",
      "Processing all_mean for token type: asst\n",
      "Processing all_mean for token type: endheader\n",
      "Processing all_mean for token type: newline\n",
      "Found 300 total records for all_mean\n",
      "\n",
      "Top 5 features for all_mean:\n",
      " rank  feature_id     token  all_mean_base  all_mean_chat  all_mean_diff  all_mean_ratio model_type  sae_layer sae_trainer\n",
      "    1       11904      asst       0.005578       3.741617       3.736039      670.766122      llama         15         32x\n",
      "    2       97377      asst       0.006156       3.023328       3.017172      491.098983      llama         15         32x\n",
      "    1       92801   newline       6.986360       9.858937       2.872578        1.411169      llama         15         32x\n",
      "    1      112879 endheader       0.000000       2.262328       2.262328             inf      llama         15         32x\n",
      "    2       96419   newline       3.824219       6.014953       2.190734        1.572858      llama         15         32x\n",
      "\n",
      "Summary statistics for all_mean:\n",
      "Max difference: 3.736039\n",
      "Min difference: 0.010953\n",
      "Mean difference: 0.273882\n",
      "\n",
      "==================================================\n",
      "Analyzing metric: active_mean\n",
      "==================================================\n",
      "Processing active_mean for token type: asst\n",
      "Processing active_mean for token type: endheader\n",
      "Processing active_mean for token type: newline\n",
      "Found 300 total records for active_mean\n",
      "\n",
      "Top 5 features for active_mean:\n",
      " rank  feature_id     token  active_mean_base  active_mean_chat  active_mean_diff  active_mean_ratio model_type  sae_layer sae_trainer\n",
      "    1       74359   newline               0.0          10.50000          10.50000                inf      llama         15         32x\n",
      "    2       11850   newline               0.0           7.34375           7.34375                inf      llama         15         32x\n",
      "    3       99377   newline               0.0           6.78125           6.78125                inf      llama         15         32x\n",
      "    1       71951 endheader               0.0           6.62500           6.62500                inf      llama         15         32x\n",
      "    2      130135 endheader               0.0           6.43750           6.43750                inf      llama         15         32x\n",
      "\n",
      "Summary statistics for active_mean:\n",
      "Max difference: 10.500000\n",
      "Min difference: 2.875000\n",
      "Mean difference: 4.164325\n",
      "\n",
      "==================================================\n",
      "Analyzing metric: sparsity\n",
      "==================================================\n",
      "Processing sparsity for token type: asst\n",
      "Processing sparsity for token type: endheader\n",
      "Processing sparsity for token type: newline\n",
      "Found 300 total records for sparsity\n",
      "\n",
      "Top 5 features for sparsity:\n",
      " rank  feature_id     token  sparsity_base  sparsity_chat  sparsity_diff  sparsity_ratio model_type  sae_layer sae_trainer\n",
      "    1       97377      asst          0.001          0.912          0.911      911.999957      llama         15         32x\n",
      "    2       11904      asst          0.002          0.881          0.879      440.499970      llama         15         32x\n",
      "    1      112879 endheader          0.000          0.706          0.706             inf      llama         15         32x\n",
      "    3       84495      asst          0.000          0.702          0.702             inf      llama         15         32x\n",
      "    2       29865 endheader          0.000          0.675          0.675             inf      llama         15         32x\n",
      "\n",
      "Summary statistics for sparsity:\n",
      "Max difference: 0.911000\n",
      "Min difference: 0.004000\n",
      "Mean difference: 0.082350\n",
      "\n",
      "==================================================\n",
      "Analysis complete!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def find_top_increases(base_data, chat_data, token_types, metric_name, top_k=100):\n",
    "    \"\"\"\n",
    "    Find top features with greatest increase in specified metric from base to chat.\n",
    "    \n",
    "    Args:\n",
    "        base_data: Base model data dictionary\n",
    "        chat_data: Chat model data dictionary  \n",
    "        token_types: List of token types to process\n",
    "        metric_name: Name of metric to analyze ('all_mean', 'active_mean', 'sparsity')\n",
    "        top_k: Number of top features to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with top features and their differences\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for token_type in token_types:\n",
    "        print(f\"Processing {metric_name} for token type: {token_type}\")\n",
    "        \n",
    "        # Get base and chat tensors for this metric\n",
    "        base_tensor = base_data[token_type][metric_name]\n",
    "        chat_tensor = chat_data[token_type][metric_name]\n",
    "        \n",
    "        # Calculate difference (chat - base)\n",
    "        diff_tensor = chat_tensor - base_tensor\n",
    "        \n",
    "        # Get top k features with largest increases\n",
    "        top_values, top_indices = torch.topk(diff_tensor, top_k)\n",
    "        \n",
    "        # Convert to lists for DataFrame\n",
    "        top_values = top_values.tolist()\n",
    "        top_indices = top_indices.tolist()\n",
    "        \n",
    "        # Get corresponding base and chat values\n",
    "        base_values = base_tensor[top_indices].tolist()\n",
    "        chat_values = chat_tensor[top_indices].tolist()\n",
    "        \n",
    "        # Create records for this token type\n",
    "        for i, (feat_idx, diff_val, base_val, chat_val) in enumerate(zip(top_indices, top_values, base_values, chat_values)):\n",
    "            record = {\n",
    "                'rank': i + 1,\n",
    "                'feature_id': feat_idx,\n",
    "                'token': token_type,\n",
    "                f'{metric_name}_base': base_val,\n",
    "                f'{metric_name}_chat': chat_val,\n",
    "                f'{metric_name}_diff': diff_val,\n",
    "                f'{metric_name}_ratio': chat_val / base_val if base_val > 0 else float('inf'),\n",
    "                'model_type': MODEL_TYPE,\n",
    "                'sae_layer': SAE_LAYER,\n",
    "                'sae_trainer': SAE_TRAINER,\n",
    "            }\n",
    "            all_results.append(record)\n",
    "    \n",
    "    # Convert to DataFrame and sort by difference (descending)\n",
    "    df = pd.DataFrame(all_results)\n",
    "    df = df.sort_values(f'{metric_name}_diff', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Found {len(df)} total records for {metric_name}\")\n",
    "    return df\n",
    "\n",
    "# Analyze all three metrics\n",
    "metrics_to_analyze = ['all_mean', 'active_mean', 'sparsity']\n",
    "results = {}\n",
    "\n",
    "for metric in metrics_to_analyze:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Analyzing metric: {metric}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    df = find_top_increases(base_data, chat_data, token_types, metric, top_k=100)\n",
    "    results[metric] = df\n",
    "    \n",
    "    # Show preview\n",
    "    print(f\"\\nTop 5 features for {metric}:\")\n",
    "    print(df.head().to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nSummary statistics for {metric}:\")\n",
    "    print(f\"Max difference: {df[f'{metric}_diff'].max():.6f}\")\n",
    "    print(f\"Min difference: {df[f'{metric}_diff'].min():.6f}\")\n",
    "    print(f\"Mean difference: {df[f'{metric}_diff'].mean():.6f}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Analysis complete!\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to CSV files...\n",
      "Saved 300 records to: /root/git/persona-subspace/sae_feature_analysis/results/4_diffing/llama_trainer32x_layer15/top_all_mean.csv\n",
      "  File size: 25.8 KB\n",
      "Saved 300 records to: /root/git/persona-subspace/sae_feature_analysis/results/4_diffing/llama_trainer32x_layer15/top_active_mean.csv\n",
      "  File size: 16.8 KB\n",
      "Saved 300 records to: /root/git/persona-subspace/sae_feature_analysis/results/4_diffing/llama_trainer32x_layer15/top_sparsity.csv\n",
      "  File size: 25.8 KB\n",
      "\n",
      "==================================================\n",
      "All results saved!\n",
      "==================================================\n",
      "\n",
      "Summary of saved files:\n",
      "  top_all_mean.csv: Top 100 features per token type with greatest all_mean increase\n",
      "  top_active_mean.csv: Top 100 features per token type with greatest active_mean increase\n",
      "  top_sparsity.csv: Top 100 features per token type with greatest sparsity increase\n",
      "\n",
      "Each file contains:\n",
      "  - feature_id: SAE feature index\n",
      "  - token: Token position type (asst, endheader, newline)\n",
      "  - sparsity_base: Base model value\n",
      "  - sparsity_chat: Chat model value\n",
      "  - sparsity_diff: Difference (chat - base)\n",
      "  - sparsity_ratio: Ratio (chat / base)\n",
      "  - rank: Rank within token type (1-100)\n",
      "  - model_type, sae_layer, sae_trainer: Configuration info\n",
      "\n",
      "Total features analyzed: 131,072\n",
      "Total records per file: 300\n",
      "Files ready for further analysis!\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV files\n",
    "print(\"Saving results to CSV files...\")\n",
    "\n",
    "for metric, df in results.items():\n",
    "    # Create output filename\n",
    "    output_file = OUTPUT_DIR / f\"top_{metric}.csv\"\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved {len(df)} records to: {output_file}\")\n",
    "    \n",
    "    # Show file info\n",
    "    file_size = output_file.stat().st_size / 1024  # KB\n",
    "    print(f\"  File size: {file_size:.1f} KB\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"All results saved!\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Summary of what was saved\n",
    "print(f\"\\nSummary of saved files:\")\n",
    "for metric in metrics_to_analyze:\n",
    "    output_file = OUTPUT_DIR / f\"top_{metric}.csv\"\n",
    "    print(f\"  {output_file.name}: Top 100 features per token type with greatest {metric} increase\")\n",
    "\n",
    "print(f\"\\nEach file contains:\")\n",
    "print(f\"  - feature_id: SAE feature index\")\n",
    "print(f\"  - token: Token position type (asst, endheader, newline)\")\n",
    "print(f\"  - {metric}_base: Base model value\")\n",
    "print(f\"  - {metric}_chat: Chat model value\") \n",
    "print(f\"  - {metric}_diff: Difference (chat - base)\")\n",
    "print(f\"  - {metric}_ratio: Ratio (chat / base)\")\n",
    "print(f\"  - rank: Rank within token type (1-100)\")\n",
    "print(f\"  - model_type, sae_layer, sae_trainer: Configuration info\")\n",
    "\n",
    "print(f\"\\nTotal features analyzed: {base_data['metadata']['num_features']:,}\")\n",
    "print(f\"Total records per file: {len(results['all_mean'])}\")\n",
    "print(f\"Files ready for further analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features that appear in the top 100 for all metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
