{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Diffing Plotting\n",
    "\n",
    "This notebook creates an interactive plot of the results from model diffing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "MODEL_TYPE = \"llama\"\n",
    "MODEL_NAME_READABLE = \"Llama 3.1 8B\"\n",
    "SAE_LAYER = 13\n",
    "SAE_TRAINER = \"32x\"\n",
    "TOKEN_OFFSETS = {\"asst\": -2, \"endheader\": -1, \"newline\": 0}\n",
    "N_PROMPTS = 1000\n",
    "# MODEL_TYPE = \"gemma\"\n",
    "# MODEL_NAME_READABLE = \"Gemma 2 9B\"\n",
    "# SAE_LAYER = 20\n",
    "# SAE_TRAINER = \"131k-l0-114\"\n",
    "# TOKEN_OFFSETS = {\"model\": -1, \"newline\": 0}\n",
    "# N_PROMPTS = 40\n",
    "PERCENT_ACTIVE = 1\n",
    "\n",
    "# Choose one metric for detailed analysis\n",
    "METRIC_SUBTITLE = {\n",
    "    'all_mean': 'Mean Activation',\n",
    "    'sparsity': 'Activation Sparsity'\n",
    "}\n",
    "\n",
    "\n",
    "# File paths\n",
    "BASE_FILE = f\"/workspace/results/4_diffing/{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}/{N_PROMPTS}_prompts/base.pt\"\n",
    "CHAT_FILE = f\"/workspace/results/4_diffing/{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}/{N_PROMPTS}_prompts/chat.pt\"\n",
    "EXPLANATIONS_PATH = f\"../../explanations/{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}.csv\"\n",
    "\n",
    "# Output directory\n",
    "SOURCE = f\"{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}/{N_PROMPTS}_prompts\"\n",
    "OUTPUT_DIR = Path(f\"./{SOURCE}\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Link\n",
    "LLAMA_LINK_FORMAT = f\"https://www.neuronpedia.org/llama3.1-8b/{SAE_LAYER}-llamascope-res-131k/\"\n",
    "GEMMA_LINK_FORMAT = f\"https://www.neuronpedia.org/gemma-2-9b/{SAE_LAYER}-gemmascope-res-131k/\"\n",
    "\n",
    "print(f\"Loading base model data from: {BASE_FILE}\")\n",
    "print(f\"Loading chat model data from: {CHAT_FILE}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Load the PyTorch files\n",
    "base_data = torch.load(BASE_FILE)\n",
    "chat_data = torch.load(CHAT_FILE)\n",
    "\n",
    "print(f\"\\nBase data keys: {list(base_data.keys())}\")\n",
    "print(f\"Chat data keys: {list(chat_data.keys())}\")\n",
    "print(f\"Base metadata: {base_data['metadata']}\")\n",
    "print(f\"Chat metadata: {chat_data['metadata']}\")\n",
    "\n",
    "# Verify token types match\n",
    "base_tokens = [k for k in base_data.keys() if k != 'metadata']\n",
    "chat_tokens = [k for k in chat_data.keys() if k != 'metadata']\n",
    "print(f\"\\nBase token types: {base_tokens}\")\n",
    "print(f\"Chat token types: {chat_tokens}\")\n",
    "assert base_tokens == chat_tokens, \"Token types don't match between base and chat!\"\n",
    "\n",
    "token_types = base_tokens\n",
    "print(f\"Processing {len(token_types)} token types: {token_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive scatterplot for one metric with all 3 token types\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "# Load Claude explanations\n",
    "explanations_df = pd.read_csv(EXPLANATIONS_PATH)\n",
    "print(f\"Loaded {len(explanations_df)} explanations\")\n",
    "\n",
    "# Create a dictionary for fast lookup of explanations by feature_id\n",
    "explanations_dict = dict(zip(explanations_df['feature_id'], explanations_df['claude_desc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SELECTED_METRIC = 'all_mean'\n",
    "\n",
    "print(f\"Creating interactive scatterplot for {SELECTED_METRIC} metric with all token types...\")\n",
    "\n",
    "# Generate colors and symbols dynamically based on TOKEN_OFFSETS keys\n",
    "def generate_plot_styling(token_offset_keys):\n",
    "    \"\"\"Generate colors and symbols for plotting based on token offset keys\"\"\"\n",
    "    # Color palette - visually distinct colors\n",
    "    color_palette = [\n",
    "        '#FF6B6B',  # Red\n",
    "        '#4ECDC4',  # Teal\n",
    "        '#45B7D1',  # Blue\n",
    "        '#96CEB4',  # Green\n",
    "        '#FFEAA7',  # Yellow\n",
    "        '#DDA0DD',  # Plum\n",
    "        '#FFA07A',  # Light Salmon\n",
    "        '#98D8C8',  # Mint\n",
    "        '#F7DC6F',  # Light Yellow\n",
    "        '#BB8FCE'   # Light Purple\n",
    "    ]\n",
    "    \n",
    "    # Symbol palette - distinct shapes\n",
    "    symbol_palette = [\n",
    "        'circle',\n",
    "        'square', \n",
    "        'diamond',\n",
    "        'triangle-up',\n",
    "        'triangle-down',\n",
    "        'star',\n",
    "        'hexagon',\n",
    "        'pentagon',\n",
    "        'cross',\n",
    "        'x'\n",
    "    ]\n",
    "    \n",
    "    colors = {}\n",
    "    symbols = {}\n",
    "    \n",
    "    for i, token_key in enumerate(token_offset_keys):\n",
    "        colors[token_key] = color_palette[i % len(color_palette)]\n",
    "        symbols[token_key] = symbol_palette[i % len(symbol_palette)]\n",
    "    \n",
    "    return colors, symbols\n",
    "\n",
    "# Generate styling based on current TOKEN_OFFSETS\n",
    "colors, symbols = generate_plot_styling(list(TOKEN_OFFSETS.keys()))\n",
    "print(f\"Generated styling for token types: {list(TOKEN_OFFSETS.keys())}\")\n",
    "print(f\"Colors: {colors}\")\n",
    "print(f\"Symbols: {symbols}\")\n",
    "\n",
    "# Load target feature IDs if the file exists\n",
    "active_file = f\"./{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}/personal_{N_PROMPTS}/explanations.csv\"\n",
    "if os.path.exists(active_file):\n",
    "    active_features_df = pd.read_csv(active_file)\n",
    "    active_feature_ids = set(active_features_df['feature_id'].tolist())\n",
    "else:\n",
    "    # Pre-calculate active masks once per token type since all metrics have same active features\n",
    "    print(\"Pre-calculating active masks...\")\n",
    "    active_masks = {}\n",
    "    for token_type in token_types:\n",
    "        base_values = base_data[token_type]['num_active'].numpy()\n",
    "        chat_values = chat_data[token_type]['num_active'].numpy()\n",
    "        active_masks[token_type] = (base_values > int(N_PROMPTS * PERCENT_ACTIVE / 100)) | (chat_values > int(N_PROMPTS * PERCENT_ACTIVE / 100))\n",
    "        print(f\"  {token_type}: {active_masks[token_type].sum():,} active features\")\n",
    "\n",
    "# Pre-process all data in single loop to avoid redundant calculations\n",
    "print(\"Pre-processing data...\")\n",
    "processed_data = {}\n",
    "all_base_values = []\n",
    "all_chat_values = []\n",
    "\n",
    "def format_explanation_efficient(claude_explanation):\n",
    "    \"\"\"Efficient text wrapping function - preserves original formatting logic\"\"\"\n",
    "    if not isinstance(claude_explanation, str) or pd.isna(claude_explanation):\n",
    "        return \"No explanation available\"\n",
    "    \n",
    "    if len(claude_explanation) <= 50:\n",
    "        return claude_explanation\n",
    "    \n",
    "    # Same text wrapping logic as original, but more efficient\n",
    "    words = claude_explanation.split()\n",
    "    lines = []\n",
    "    current_line = \"\"\n",
    "    \n",
    "    for word in words:\n",
    "        if len(current_line + word) <= 80:\n",
    "            current_line += word + \" \"\n",
    "        else:\n",
    "            if current_line:\n",
    "                lines.append(current_line.strip())\n",
    "            current_line = word + \" \"\n",
    "    \n",
    "    if current_line:\n",
    "        lines.append(current_line.strip())\n",
    "    \n",
    "    return \"<br>\".join(lines)\n",
    "\n",
    "# Process all token types in one pass\n",
    "no_explanation = set()\n",
    "for token_type in token_types:\n",
    "    if os.path.exists(active_file):\n",
    "        # Use pre-filtered feature IDs from CSV\n",
    "        all_feature_ids = np.arange(base_data['metadata']['num_features'])\n",
    "        mask = np.isin(all_feature_ids, list(active_feature_ids))\n",
    "\n",
    "        base_values = base_data[token_type][SELECTED_METRIC].numpy()[mask]\n",
    "        chat_values = chat_data[token_type][SELECTED_METRIC].numpy()[mask]\n",
    "        base_num_active = base_data[token_type]['num_active'].numpy()[mask]\n",
    "        chat_num_active = chat_data[token_type]['num_active'].numpy()[mask]\n",
    "        feature_ids = all_feature_ids[mask]\n",
    "    else:\n",
    "        # Fallback to mask calculation\n",
    "        active_mask = active_masks[token_type]\n",
    "        base_values = base_data[token_type][SELECTED_METRIC].numpy()[active_mask]\n",
    "        chat_values = chat_data[token_type][SELECTED_METRIC].numpy()[active_mask]\n",
    "        base_num_active = base_data[token_type]['num_active'].numpy()[active_mask]\n",
    "        chat_num_active = chat_data[token_type]['num_active'].numpy()[active_mask]\n",
    "        feature_ids = np.arange(len(active_mask))[active_mask]\n",
    "    \n",
    "    # Calculate differences vectorized\n",
    "    differences = chat_values - base_values\n",
    "    \n",
    "    # Pre-process hover text and explanations\n",
    "    hover_texts = []\n",
    "    neuronpedia_urls = []\n",
    "    \n",
    "    for fid, base_val, chat_val, diff, base_active, chat_active in zip(\n",
    "        feature_ids, base_values, chat_values, differences, base_num_active, chat_num_active\n",
    "    ):\n",
    "        # Get Claude explanation if available\n",
    "        if fid not in explanations_dict:\n",
    "            no_explanation.add(fid)\n",
    "        claude_explanation = explanations_dict.get(fid, \"No explanation available\")\n",
    "        \n",
    "        # Check if explanation is a string (handle NaN/float values)\n",
    "        if not isinstance(claude_explanation, str) or pd.isna(claude_explanation):\n",
    "            claude_explanation = \"No explanation available\"\n",
    "            no_explanation.add(fid)\n",
    "        \n",
    "        # Format explanation efficiently but preserve original wrapping behavior\n",
    "        formatted_explanation = format_explanation_efficient(claude_explanation)\n",
    "        \n",
    "        # Create Neuronpedia URL - choose correct format based on model type\n",
    "        if MODEL_TYPE == \"llama\":\n",
    "            neuronpedia_url = f\"{LLAMA_LINK_FORMAT}{fid}\"\n",
    "        else:  # gemma\n",
    "            neuronpedia_url = f\"{GEMMA_LINK_FORMAT}{fid}\"\n",
    "        neuronpedia_urls.append(neuronpedia_url)\n",
    "        \n",
    "        # Create hover text \n",
    "        hover_text = (\n",
    "            f\"<b>Feature {fid}</b><br>\" +\n",
    "            f\"Base: {base_val:.4f} ({base_active}/{N_PROMPTS} prompts)<br>\" +\n",
    "            f\"Instruct: {chat_val:.4f} ({chat_active}/{N_PROMPTS} prompts)<br>\" +\n",
    "            f\"Difference: {diff:.4f}<br><br>\" +\n",
    "            f\"<b>Description:</b><br>\" +\n",
    "            f\"{formatted_explanation}<extra></extra>\"\n",
    "        )\n",
    "        hover_texts.append(hover_text)\n",
    "    \n",
    "    # Store processed data\n",
    "    processed_data[token_type] = {\n",
    "        'base_values': base_values,\n",
    "        'chat_values': chat_values,\n",
    "        'feature_ids': feature_ids,\n",
    "        'hover_texts': hover_texts,\n",
    "        'neuronpedia_urls': neuronpedia_urls\n",
    "    }\n",
    "    \n",
    "    # Collect all values for min/max calculation (single pass)\n",
    "    all_base_values.extend(base_values)\n",
    "    all_chat_values.extend(chat_values)\n",
    "\n",
    "# Create the scatterplot\n",
    "fig = go.Figure()\n",
    "\n",
    "total_features = 0\n",
    "\n",
    "# Add scatter traces using pre-processed data\n",
    "for token_type in token_types:\n",
    "    data = processed_data[token_type]\n",
    "    \n",
    "    # Add scatter points for this token type using Scattergl for better performance\n",
    "    fig.add_trace(\n",
    "        go.Scattergl(\n",
    "            x=data['base_values'],\n",
    "            y=data['chat_values'],\n",
    "            mode='markers',\n",
    "            name=f'{token_type}',\n",
    "            marker=dict(\n",
    "                size=6,\n",
    "                color=colors[token_type],\n",
    "                symbol=symbols[token_type],\n",
    "                line=dict(width=0.3, color='black'),  # Thinner lines\n",
    "                opacity=0.7\n",
    "            ),\n",
    "            text=[f\"Feature {fid}\" for fid in data['feature_ids']],\n",
    "            customdata=data['neuronpedia_urls'],\n",
    "            hovertemplate=data['hover_texts'],\n",
    "            hoverlabel=dict(\n",
    "                bgcolor=colors[token_type],\n",
    "                bordercolor=\"black\",\n",
    "                font_size=12, \n",
    "                font_family=\"Arial\",\n",
    "                font_color=\"white\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    total_features += len(data['base_values'])\n",
    "\n",
    "# Add diagonal \"no change\" line using pre-calculated values (eliminates second loop)\n",
    "max_val = max(max(all_base_values), max(all_chat_values))\n",
    "min_val = min(min(all_base_values), min(all_chat_values))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[min_val, max_val],\n",
    "        y=[min_val, max_val],\n",
    "        mode='lines',\n",
    "        line=dict(color='gray', dash='dash', width=2),\n",
    "        name='No Change',\n",
    "        hovertemplate=\"No change line<extra></extra>\",\n",
    "        hoverlabel=dict(\n",
    "            bgcolor=\"gray\",\n",
    "            bordercolor=\"black\",\n",
    "            font_size=11,\n",
    "            font_family=\"Arial\",\n",
    "            font_color=\"white\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout with performance optimizations\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': f'Base → Instruct SAE Features: {METRIC_SUBTITLE[SELECTED_METRIC]}<br><sub>{MODEL_NAME_READABLE}, Residual Stream Post-Layer {SAE_LAYER}</sub>',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 16}\n",
    "    },\n",
    "    xaxis_title=f'Base: {METRIC_SUBTITLE[SELECTED_METRIC]}',\n",
    "    yaxis_title=f'Instruct: {METRIC_SUBTITLE[SELECTED_METRIC]}',\n",
    "    height=800,\n",
    "    width=900,\n",
    "    showlegend=True,\n",
    "    hovermode='closest',\n",
    "    legend=dict(\n",
    "        title=\"Activation Position\",\n",
    "        orientation=\"v\",\n",
    "        yanchor=\"top\",\n",
    "        y=1,\n",
    "        xanchor=\"left\",\n",
    "        x=1.02\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Add grid\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "\n",
    "# Save the interactive plot with JavaScript for click handling\n",
    "output_html = OUTPUT_DIR / f\"{SELECTED_METRIC}.html\"\n",
    "\n",
    "# Create custom HTML with click handler and performance optimizations\n",
    "html_content = fig.to_html(\n",
    "    include_plotlyjs='cdn',  # Use CDN for smaller file size\n",
    "    config={\n",
    "        'displayModeBar': True,\n",
    "        'showTips': False,\n",
    "        'scrollZoom': True,\n",
    "        'doubleClick': 'reset'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add JavaScript to handle clicks with performance optimizations\n",
    "click_script = \"\"\"\n",
    "<script>\n",
    "document.addEventListener('DOMContentLoaded', function() {\n",
    "    var plotDiv = document.getElementsByClassName('plotly-graph-div')[0];\n",
    "    \n",
    "    // Debounce click events to prevent rapid clicking\n",
    "    let clickTimeout;\n",
    "    plotDiv.on('plotly_click', function(data) {\n",
    "        clearTimeout(clickTimeout);\n",
    "        clickTimeout = setTimeout(function() {\n",
    "            var point = data.points[0];\n",
    "            if (point.customdata) {\n",
    "                window.open(point.customdata, '_blank');\n",
    "            }\n",
    "        }, 100);\n",
    "    });\n",
    "});\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "# Insert the script before the closing body tag\n",
    "html_with_script = html_content.replace('</body>', click_script + '</body>')\n",
    "\n",
    "with open(output_html, 'w') as f:\n",
    "    f.write(html_with_script)\n",
    "\n",
    "print(f\"\\nInteractive scatterplot saved to: {output_html}\")\n",
    "print(f\"File size: {output_html.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nScatterplot features:\")\n",
    "print(f\"- {total_features:,} total active features from all token types\")\n",
    "print(f\"- Different colors/symbols for each token type\")\n",
    "print(f\"- Hover shows feature ID, values, num_active, and Claude explanation\")\n",
    "print(f\"- Interactive legend to show/hide token types\")\n",
    "print(f\"- Gray diagonal line = no change reference\")\n",
    "print(f\"- Click any point to open its Neuronpedia page\")\n",
    "print(f\"- Optimized for performance with 7k+ data points\")\n",
    "print(f\"- Can easily change selected_metric above\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
