{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Diffing Analysis\n",
    "\n",
    "This notebook analyzes the differences between base and chat models by comparing feature activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model data from: /workspace/results/4_diffing/1_llama_trainer32x_layer15_base.pt\n",
      "Loading chat model data from: /workspace/results/4_diffing/1_llama_trainer32x_layer15_chat.pt\n",
      "Output directory: llama_trainer32x_layer15\n",
      "\n",
      "Base data keys: ['asst', 'endheader', 'newline', 'metadata']\n",
      "Chat data keys: ['asst', 'endheader', 'newline', 'metadata']\n",
      "Base metadata: {'source': 'llama_trainer32x_layer15_base', 'model_type': 'llama', 'model_ver': 'base', 'sae_layer': 15, 'sae_trainer': '32x', 'num_prompts': 1000, 'num_features': 131072, 'token_types': ['asst', 'endheader', 'newline']}\n",
      "Chat metadata: {'source': 'llama_trainer32x_layer15_chat', 'model_type': 'llama', 'model_ver': 'chat', 'sae_layer': 15, 'sae_trainer': '32x', 'num_prompts': 1000, 'num_features': 131072, 'token_types': ['asst', 'endheader', 'newline']}\n",
      "\n",
      "Base token types: ['asst', 'endheader', 'newline']\n",
      "Chat token types: ['asst', 'endheader', 'newline']\n",
      "Processing 3 token types: ['asst', 'endheader', 'newline']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "MODEL_TYPE = \"llama\"\n",
    "SAE_LAYER = 15\n",
    "SAE_TRAINER = \"32x\"\n",
    "TOKEN_OFFSETS = {\"asst\": -2, \"endheader\": -1, \"newline\": 0}\n",
    "\n",
    "# File paths\n",
    "BASE_FILE = f\"/workspace/results/4_diffing/1_{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}_base.pt\"\n",
    "CHAT_FILE = f\"/workspace/results/4_diffing/1_{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}_chat.pt\"\n",
    "\n",
    "# Output directory\n",
    "SOURCE = f\"{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}\"\n",
    "OUTPUT_DIR = Path(f\"./{SOURCE}\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Link\n",
    "LLAMA_LINK_FORMAT = f\"https://www.neuronpedia.org/llama3.1-8b/{SAE_LAYER}-llamascope-res-131k/\"\n",
    "\n",
    "print(f\"Loading base model data from: {BASE_FILE}\")\n",
    "print(f\"Loading chat model data from: {CHAT_FILE}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Load the PyTorch files\n",
    "base_data = torch.load(BASE_FILE)\n",
    "chat_data = torch.load(CHAT_FILE)\n",
    "\n",
    "print(f\"\\nBase data keys: {list(base_data.keys())}\")\n",
    "print(f\"Chat data keys: {list(chat_data.keys())}\")\n",
    "print(f\"Base metadata: {base_data['metadata']}\")\n",
    "print(f\"Chat metadata: {chat_data['metadata']}\")\n",
    "\n",
    "# Verify token types match\n",
    "base_tokens = [k for k in base_data.keys() if k != 'metadata']\n",
    "chat_tokens = [k for k in chat_data.keys() if k != 'metadata']\n",
    "print(f\"\\nBase token types: {base_tokens}\")\n",
    "print(f\"Chat token types: {chat_tokens}\")\n",
    "assert base_tokens == chat_tokens, \"Token types don't match between base and chat!\"\n",
    "\n",
    "token_types = base_tokens\n",
    "print(f\"Processing {len(token_types)} token types: {token_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create interactive scatterplot for one metric with all 3 token types\nimport plotly.graph_objects as go\nimport plotly.express as px\n\n# Load Claude explanations\nexplanations_path = \"/root/git/persona-subspace/sae_feature_analysis/results/4_diffing/llama_trainer32x_layer15/explanations_with_claude.csv\"\nexplanations_df = pd.read_csv(explanations_path)\nprint(f\"Loaded {len(explanations_df)} explanations\")\n\n# Create a dictionary for fast lookup of explanations by feature_id\nexplanations_dict = dict(zip(explanations_df['feature_id'], explanations_df['claude_desc']))\n\n# Choose one metric for detailed analysis\nselected_metric = 'sparsity'  # Change this to 'active_mean' or 'sparsity' if desired\n\nprint(f\"Creating interactive scatterplot for {selected_metric} metric with all token types...\")\n\n# Color mapping for token types\ncolors = {'asst': '#FF6B6B', 'endheader': '#4ECDC4', 'newline': '#45B7D1'}\nsymbols = {'asst': 'circle', 'endheader': 'square', 'newline': 'diamond'}\n\n# Create the scatterplot\nfig = go.Figure()\n\ntotal_features = 0\nfor token_type in token_types:\n    # Get all feature values for this token/metric combination\n    base_values = base_data[token_type][selected_metric].numpy()\n    chat_values = chat_data[token_type][selected_metric].numpy()\n    \n    # Filter out features that are inactive in both base and chat\n    active_mask = (base_values > 0) | (chat_values > 0)\n    filtered_base = base_values[active_mask]\n    filtered_chat = chat_values[active_mask]\n    \n    # Get feature IDs for active features\n    feature_ids = np.arange(len(base_values))[active_mask]\n    \n    # Calculate differences for coloring\n    differences = filtered_chat - filtered_base\n    \n    # Create hover text with feature details including Claude explanations\n    hover_text = []\n    neuronpedia_urls = []\n    for i, (fid, base_val, chat_val, diff) in enumerate(zip(feature_ids, filtered_base, filtered_chat, differences)):\n        # Get Claude explanation if available\n        claude_explanation = explanations_dict.get(fid, \"No explanation available\")\n        \n        # Check if explanation is a string (handle NaN/float values)\n        if not isinstance(claude_explanation, str) or pd.isna(claude_explanation):\n            claude_explanation = \"No explanation available\"\n        \n        # Format the explanation to wrap at reasonable length\n        if len(claude_explanation) > 80:\n            # Split into chunks of ~80 characters at word boundaries\n            words = claude_explanation.split()\n            lines = []\n            current_line = \"\"\n            for word in words:\n                if len(current_line + word) <= 80:\n                    current_line += word + \" \"\n                else:\n                    if current_line:\n                        lines.append(current_line.strip())\n                    current_line = word + \" \"\n            if current_line:\n                lines.append(current_line.strip())\n            formatted_explanation = \"<br>\".join(lines)\n        else:\n            formatted_explanation = claude_explanation\n        \n        # Create Neuronpedia URL for this feature\n        neuronpedia_url = f\"{LLAMA_LINK_FORMAT}{fid}\"\n        neuronpedia_urls.append(neuronpedia_url)\n        \n        hover_text.append(\n            f\"<b>Feature {fid}</b><br>\" +\n            f\"Base: {base_val:.6f}<br>\" +\n            f\"Chat: {chat_val:.6f}<br>\" +\n            f\"Difference: {diff:.6f}<br><br>\" +\n            f\"<b>Description:</b><br>\" +\n            f\"{formatted_explanation}<extra></extra>\"\n        )\n    \n    # Add scatter points for this token type\n    fig.add_trace(\n        go.Scatter(\n            x=filtered_base,\n            y=filtered_chat,\n            mode='markers',\n            name=f'{token_type}',\n            marker=dict(\n                size=6,\n                color=colors[token_type],\n                symbol=symbols[token_type],\n                line=dict(width=0.5, color='black'),\n                opacity=0.7\n            ),\n            text=[f\"Feature {fid}\" for fid in feature_ids],\n            customdata=neuronpedia_urls,\n            hovertemplate=hover_text\n        )\n    )\n    \n    total_features += len(filtered_base)\n    print(f\"  {token_type}: {len(filtered_base):,} active features\")\n\n# Add diagonal \"no change\" line\nall_base_values = []\nall_chat_values = []\nfor token_type in token_types:\n    base_values = base_data[token_type][selected_metric].numpy()\n    chat_values = chat_data[token_type][selected_metric].numpy()\n    active_mask = (base_values > 0) | (chat_values > 0)\n    all_base_values.extend(base_values[active_mask])\n    all_chat_values.extend(chat_values[active_mask])\n\nmax_val = max(max(all_base_values), max(all_chat_values))\nmin_val = min(min(all_base_values), min(all_chat_values))\n\nfig.add_trace(\n    go.Scatter(\n        x=[min_val, max_val],\n        y=[min_val, max_val],\n        mode='lines',\n        line=dict(color='gray', dash='dash', width=2),\n        name='No Change',\n        hovertemplate=\"No change line<extra></extra>\"\n    )\n)\n\n# Update layout\nfig.update_layout(\n    title={\n        'text': f'Base â†’ Instruct SAE Features: Activation Sparsity<br><sub>Llama 3.1 8B, Residual Stream Post-Layer 15</sub>',\n        'x': 0.5,\n        'xanchor': 'center',\n        'font': {'size': 16}\n    },\n    xaxis_title=f'Base: Activation Sparsity',\n    yaxis_title=f'Instruct: Activation Sparsity',\n    height=800,\n    width=900,\n    showlegend=True,\n    hovermode='closest',\n    legend=dict(\n        title=\"Activation Position\",\n        orientation=\"v\",\n        yanchor=\"top\",\n        y=1,\n        xanchor=\"left\",\n        x=1.02\n    ),\n    # Configure hover appearance\n    hoverlabel=dict(\n        bgcolor=\"white\",\n        bordercolor=\"black\",\n        font_size=12,\n        font_family=\"Arial\"\n    )\n)\n\n# Add grid\nfig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\nfig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n\n# Save the interactive plot with JavaScript for click handling\noutput_html = OUTPUT_DIR / f\"{selected_metric}.html\"\n\n# Create custom HTML with click handler\nhtml_content = fig.to_html(include_plotlyjs='cdn')\n\n# Add JavaScript to handle clicks\nclick_script = \"\"\"\n<script>\ndocument.addEventListener('DOMContentLoaded', function() {\n    var plotDiv = document.getElementsByClassName('plotly-graph-div')[0];\n    plotDiv.on('plotly_click', function(data) {\n        var point = data.points[0];\n        if (point.customdata) {\n            window.open(point.customdata, '_blank');\n        }\n    });\n});\n</script>\n\"\"\"\n\n# Insert the script before the closing body tag\nhtml_with_script = html_content.replace('</body>', click_script + '</body>')\n\nwith open(output_html, 'w') as f:\n    f.write(html_with_script)\n\nprint(f\"\\nInteractive scatterplot saved to: {output_html}\")\nprint(f\"File size: {output_html.stat().st_size / 1024:.1f} KB\")\n\n# Show the plot\nfig.show()\n\nprint(f\"\\nScatterplot features:\")\nprint(f\"- {total_features:,} total active features from all token types\")\nprint(f\"- Different colors/symbols for each token type\")\nprint(f\"- Hover shows feature ID, values, and Claude explanation\")\nprint(f\"- Interactive legend to show/hide token types\")\nprint(f\"- Gray diagonal line = no change reference\")\nprint(f\"- Click any point to open its Neuronpedia page\")\nprint(f\"- Can easily change selected_metric above\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}