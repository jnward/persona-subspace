{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis: Assistant vs Control Prompts\n",
    "\n",
    "This notebook analyzes which SAE features activate strongly on assistant prompts but not on control prompts. The model and layer are configurable - see the configuration cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import hf_hub_download\n",
    "from dictionary_learning.utils import load_dictionary\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL SELECTION - Change this to switch between models\n",
    "# =============================================================================\n",
    "MODEL_TYPE = \"qwen\"  # Options: \"qwen\" or \"llama\"\n",
    "TOKEN_TYPE = \"asst\"  # Options: \"asst\", \"newline\", \"endheader\" (endheader only for llama)\n",
    "SAE_LAYER = 11\n",
    "SAE_TRAINER = 1\n",
    "\n",
    "# =============================================================================\n",
    "# AUTO-CONFIGURED SETTINGS BASED ON MODEL TYPE\n",
    "# =============================================================================\n",
    "if MODEL_TYPE == \"qwen\":\n",
    "    MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "    SAE_RELEASE = \"andyrdt/saes-qwen2.5-7b-instruct\"\n",
    "    ASSISTANT_HEADER = \"<|im_start|>assistant\"\n",
    "    TOKEN_OFFSETS = {\"asst\": -1, \"newline\": 0}\n",
    "    SAE_BASE_PATH = \"/workspace/sae/qwen-2.5-7b-instruct/saes\"\n",
    "    \n",
    "elif MODEL_TYPE == \"llama\":\n",
    "    MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "    SAE_RELEASE = \"andyrdt/saes-llama-3.1-8b-instruct\"\n",
    "    ASSISTANT_HEADER = \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "    TOKEN_OFFSETS = {\"asst\": -2, \"endheader\": -1, \"newline\": 0}\n",
    "    SAE_BASE_PATH = \"/workspace/sae/llama-3.1-8b-instruct/saes\"\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f\"Unknown MODEL_TYPE: {MODEL_TYPE}. Use 'qwen' or 'llama'\")\n",
    "\n",
    "# Validate token type\n",
    "if TOKEN_TYPE not in TOKEN_OFFSETS:\n",
    "    raise ValueError(f\"TOKEN_TYPE '{TOKEN_TYPE}' not available for {MODEL_TYPE}. Available: {list(TOKEN_OFFSETS.keys())}\")\n",
    "\n",
    "# =============================================================================\n",
    "# DERIVED CONFIGURATIONS\n",
    "# =============================================================================\n",
    "SAE_CONFIG = {\n",
    "    \"release\": SAE_RELEASE,\n",
    "    \"layer\": SAE_LAYER,\n",
    "    \"trainer\": SAE_TRAINER\n",
    "}\n",
    "SAE_PATH = f\"{SAE_BASE_PATH}/resid_post_layer_{SAE_LAYER}/trainer_{SAE_TRAINER}\"\n",
    "LAYER_INDEX = SAE_LAYER\n",
    "TOKEN_OFFSET = TOKEN_OFFSETS[TOKEN_TYPE]\n",
    "\n",
    "# Data paths\n",
    "ASSISTANT_PROMPTS_PATH = \"assistant_prompts.jsonl\"\n",
    "CONTROL_PROMPTS_PATH = \"control_prompts.jsonl\"\n",
    "\n",
    "# Output directory with clear naming\n",
    "OUTPUT_DIR = f\"./{MODEL_TYPE}_trainer{SAE_TRAINER}_layer{SAE_LAYER}_{TOKEN_TYPE}\"\n",
    "\n",
    "# Processing parameters\n",
    "BATCH_SIZE = 8\n",
    "MAX_LENGTH = 512\n",
    "TOP_FEATURES = 100\n",
    "\n",
    "# =============================================================================\n",
    "# SUMMARY\n",
    "# =============================================================================\n",
    "print(f\"Configuration Summary:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  SAE Layer: {SAE_LAYER}, Trainer: {SAE_TRAINER}\")\n",
    "print(f\"  Token extraction: {TOKEN_TYPE} (offset: {TOKEN_OFFSET})\")\n",
    "print(f\"  Assistant header: {ASSISTANT_HEADER}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  SAE Release: {SAE_RELEASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 assistant prompts\n",
      "Loaded 12 control prompts\n",
      "\n",
      "Example assistant prompt: What's it like to be you?\n",
      "Example control prompt: What is the weather today?\n"
     ]
    }
   ],
   "source": [
    "def load_prompts(filepath: str) -> List[str]:\n",
    "    \"\"\"Load prompts from JSONL file.\"\"\"\n",
    "    prompts = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            prompts.append(data['content'])\n",
    "    return prompts\n",
    "\n",
    "# Load assistant and control prompts\n",
    "assistant_prompts = load_prompts(ASSISTANT_PROMPTS_PATH)\n",
    "control_prompts = load_prompts(CONTROL_PROMPTS_PATH)\n",
    "\n",
    "print(f\"Loaded {len(assistant_prompts)} assistant prompts\")\n",
    "print(f\"Loaded {len(control_prompts)} control prompts\")\n",
    "print(\"\\nExample assistant prompt:\", assistant_prompts[0])\n",
    "print(\"Example control prompt:\", control_prompts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "print(f\"Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "\n",
    "# Test chat template formatting\n",
    "test_messages = [{\"role\": \"user\", \"content\": \"What's it like to be you?\"}]\n",
    "formatted_test = tokenizer.apply_chat_template(test_messages, tokenize=False, add_generation_prompt=True)\n",
    "print(f\"\\nChat template test:\")\n",
    "print(f\"Original: What's it like to be you?\")\n",
    "print(f\"Formatted: {repr(formatted_test)}\")\n",
    "print(f\"Formatted (readable):\\n{formatted_test}\")\n",
    "\n",
    "# Test tokenization of assistant header to understand positioning\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"ASSISTANT HEADER TOKENIZATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "assistant_tokens = tokenizer.encode(ASSISTANT_HEADER, add_special_tokens=False)\n",
    "assistant_token_texts = [tokenizer.decode([token]) for token in assistant_tokens]\n",
    "\n",
    "print(f\"Assistant header: {ASSISTANT_HEADER}\")\n",
    "print(f\"Number of tokens: {len(assistant_tokens)}\")\n",
    "print(f\"Token IDs: {assistant_tokens}\")\n",
    "print(f\"Individual tokens: {assistant_token_texts}\")\n",
    "\n",
    "# Test with a full formatted prompt\n",
    "full_tokens = tokenizer.encode(formatted_test, add_special_tokens=False)\n",
    "full_token_texts = [tokenizer.decode([token]) for token in full_tokens]\n",
    "\n",
    "print(f\"\\nFull prompt tokens: {len(full_tokens)}\")\n",
    "print(\"All tokens with positions:\")\n",
    "for i, token_text in enumerate(full_token_texts):\n",
    "    print(f\"  {i:2d}: '{token_text}'\")\n",
    "\n",
    "# Find where assistant header appears in full prompt\n",
    "assistant_start_pos = None\n",
    "for i in range(len(full_tokens) - len(assistant_tokens) + 1):\n",
    "    if full_tokens[i:i+len(assistant_tokens)] == assistant_tokens:\n",
    "        assistant_start_pos = i\n",
    "        break\n",
    "\n",
    "if assistant_start_pos is not None:\n",
    "    assistant_end_pos = assistant_start_pos + len(assistant_tokens) - 1\n",
    "    print(f\"\\nAssistant header found at positions {assistant_start_pos} to {assistant_end_pos}\")\n",
    "    print(f\"Assistant header tokens: {full_token_texts[assistant_start_pos:assistant_end_pos+1]}\")\n",
    "    \n",
    "    # Show what the extraction function will actually extract\n",
    "    extraction_pos = assistant_start_pos + len(assistant_tokens) + TOKEN_OFFSET\n",
    "    print(f\"\\nExtraction calculation:\")\n",
    "    print(f\"  assistant_start_pos: {assistant_start_pos}\")\n",
    "    print(f\"  + len(assistant_tokens): {len(assistant_tokens)}\")  \n",
    "    print(f\"  + TOKEN_OFFSET ('{TOKEN_TYPE}'): {TOKEN_OFFSET}\")\n",
    "    print(f\"  = extraction_pos: {extraction_pos}\")\n",
    "    \n",
    "    if 0 <= extraction_pos < len(full_token_texts):\n",
    "        print(f\"✓ Token at extraction position {extraction_pos}: '{full_token_texts[extraction_pos]}'\")\n",
    "    else:\n",
    "        print(f\"❌ Extraction position {extraction_pos} is out of bounds (valid range: 0-{len(full_token_texts)-1})\")\n",
    "else:\n",
    "    print(\"❌ Assistant header not found in full prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a6c917793d4f529f8c07a77380dd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: Qwen2ForCausalLM\n",
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "device_map_value = device.index if device.type == 'cuda' and device.index is not None else str(device)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\": device_map_value}\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded: {model.__class__.__name__}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found SAE files at: /workspace/sae/qwen2.5-7b-instruct/saes/resid_post_layer_11/trainer_1\n",
      "SAE loaded with 131072 features\n",
      "SAE device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load SAE\n",
    "ae_file_path = os.path.join(SAE_PATH, \"ae.pt\")\n",
    "config_file_path = os.path.join(SAE_PATH, \"config.json\")\n",
    "\n",
    "if os.path.exists(ae_file_path) and os.path.exists(config_file_path):\n",
    "    print(f\"✓ Found SAE files at: {os.path.dirname(ae_file_path)}\")\n",
    "else:\n",
    "    print(f\"SAE not found locally, downloading from {SAE_RELEASE}...\")\n",
    "    os.makedirs(os.path.dirname(ae_file_path), exist_ok=True)\n",
    "    sae_path = f\"resid_post_layer_{SAE_LAYER}/trainer_{SAE_TRAINER}\"\n",
    "    local_dir = SAE_BASE_PATH\n",
    "    ae_file = hf_hub_download(repo_id=SAE_RELEASE, filename=f\"{sae_path}/ae.pt\", local_dir=local_dir)\n",
    "    config_file = hf_hub_download(repo_id=SAE_RELEASE, filename=f\"{sae_path}/config.json\", local_dir=local_dir)\n",
    "\n",
    "sae, _ = load_dictionary(SAE_PATH, device=device)\n",
    "sae.eval()\n",
    "\n",
    "print(f\"SAE loaded with {sae.dict_size} features\")\n",
    "print(f\"SAE device: {next(sae.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopForward(Exception):\n",
    "    \"\"\"Exception to stop forward pass after target layer.\"\"\"\n",
    "    pass\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_activations(prompts: List[str], layer_idx: int) -> torch.Tensor:\n",
    "    \"\"\"Extract activations from specified layer for given prompts.\"\"\"\n",
    "    all_activations = []\n",
    "    \n",
    "    # Get target layer\n",
    "    target_layer = model.model.layers[layer_idx]\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(prompts), BATCH_SIZE), desc=\"Processing batches\"):\n",
    "        batch_prompts = prompts[i:i+BATCH_SIZE]\n",
    "        \n",
    "        # Format prompts as chat messages\n",
    "        formatted_prompts = []\n",
    "        for prompt in batch_prompts:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            formatted_prompt = tokenizer.apply_chat_template(\n",
    "                messages, \n",
    "                tokenize=False, \n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "            formatted_prompts.append(formatted_prompt)\n",
    "        \n",
    "        # Tokenize batch\n",
    "        batch_inputs = tokenizer(\n",
    "            formatted_prompts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH\n",
    "        )\n",
    "        \n",
    "        # Move to device\n",
    "        batch_inputs = {k: v.to(device) for k, v in batch_inputs.items()}\n",
    "        \n",
    "        # Hook to capture activations\n",
    "        activations = None\n",
    "        \n",
    "        def hook_fn(module, input, output):\n",
    "            nonlocal activations\n",
    "            # Output is tuple, take first element (hidden states)\n",
    "            activations = output[0] if isinstance(output, tuple) else output\n",
    "            raise StopForward()\n",
    "        \n",
    "        # Register hook\n",
    "        handle = target_layer.register_forward_hook(hook_fn)\n",
    "        \n",
    "        try:\n",
    "            # Forward pass (will be stopped by hook)\n",
    "            _ = model(**batch_inputs)\n",
    "        except StopForward:\n",
    "            pass\n",
    "        finally:\n",
    "            handle.remove()\n",
    "        \n",
    "        # Extract assistant token positions\n",
    "        batch_activations = []\n",
    "        for j, formatted_prompt in enumerate(formatted_prompts):\n",
    "            # Find assistant header position\n",
    "            assistant_tokens = tokenizer.encode(ASSISTANT_HEADER, add_special_tokens=False)\n",
    "            input_ids = batch_inputs[\"input_ids\"][j]\n",
    "            \n",
    "            # Find where assistant section starts\n",
    "            assistant_pos = None\n",
    "            for k in range(len(input_ids) - len(assistant_tokens) + 1):\n",
    "                if torch.equal(input_ids[k:k+len(assistant_tokens)], torch.tensor(assistant_tokens).to(device)):\n",
    "                    assistant_pos = k + len(assistant_tokens) + TOKEN_OFFSET\n",
    "                    break\n",
    "            \n",
    "            if assistant_pos is None:\n",
    "                # Fallback to last non-padding token\n",
    "                attention_mask = batch_inputs[\"attention_mask\"][j]\n",
    "                assistant_pos = attention_mask.sum().item() - 1\n",
    "            \n",
    "            # Ensure position is within bounds\n",
    "            max_pos = attention_mask.sum().item() - 1\n",
    "            assistant_pos = min(assistant_pos, max_pos)\n",
    "            assistant_pos = max(assistant_pos, 0)\n",
    "            \n",
    "            # Extract activation at assistant position\n",
    "            assistant_activation = activations[j, assistant_pos, :]  # [hidden_dim]\n",
    "            batch_activations.append(assistant_activation.cpu())\n",
    "        \n",
    "        all_activations.extend(batch_activations)\n",
    "    \n",
    "    return torch.stack(all_activations, dim=0)\n",
    "\n",
    "print(\"Activation extraction functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Activations for Both Prompt Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting activations for assistant prompts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be01667e7a924b9b8ffd17b50d271033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant activations shape: torch.Size([12, 3584])\n",
      "\n",
      "Extracting activations for control prompts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2360b99ec454b1094f2b776b2cbe587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control activations shape: torch.Size([12, 3584])\n"
     ]
    }
   ],
   "source": [
    "# Extract activations for assistant prompts\n",
    "print(\"Extracting activations for assistant prompts...\")\n",
    "assistant_activations = extract_activations(assistant_prompts, LAYER_INDEX)\n",
    "print(f\"Assistant activations shape: {assistant_activations.shape}\")\n",
    "\n",
    "# Extract activations for control prompts\n",
    "print(\"\\nExtracting activations for control prompts...\")\n",
    "control_activations = extract_activations(control_prompts, LAYER_INDEX)\n",
    "print(f\"Control activations shape: {control_activations.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply SAE to Get Feature Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing SAE features for assistant prompts...\n",
      "Assistant features shape: torch.Size([12, 131072])\n",
      "\n",
      "Computing SAE features for control prompts...\n",
      "Control features shape: torch.Size([12, 131072])\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def get_sae_features(activations: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Apply SAE to get feature activations.\"\"\"\n",
    "    activations = activations.to(device)\n",
    "    \n",
    "    # Process in batches to avoid memory issues\n",
    "    feature_activations = []\n",
    "    \n",
    "    for i in range(0, activations.shape[0], BATCH_SIZE):\n",
    "        batch = activations[i:i+BATCH_SIZE]\n",
    "        features = sae.encode(batch)  # [batch, num_features]\n",
    "        feature_activations.append(features.cpu())\n",
    "    \n",
    "    return torch.cat(feature_activations, dim=0)\n",
    "\n",
    "# Get SAE feature activations\n",
    "print(\"Computing SAE features for assistant prompts...\")\n",
    "assistant_features = get_sae_features(assistant_activations)\n",
    "print(f\"Assistant features shape: {assistant_features.shape}\")\n",
    "\n",
    "print(\"\\nComputing SAE features for control prompts...\")\n",
    "control_features = get_sae_features(control_activations)\n",
    "print(f\"Control features shape: {control_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Feature Landscape Analysis\n",
    "\n",
    "This section provides a comprehensive view of how all SAE features differ between assistant and control prompts. This exploratory analysis helps understand the general patterns and identifies features with the largest overall differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive statistics computed for 131,072 SAE features\n",
      "Max difference: 4.5973\n",
      "Min difference: -3.4631\n",
      "Max Cohen's d: 5.6876\n",
      "Min Cohen's d: -3.5273\n",
      "Features with positive difference (favor assistant): 17\n",
      "Features with negative difference (favor control): 9\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Calculate comprehensive feature statistics for exploratory analysis\n",
    "assistant_mean = assistant_features.mean(dim=0)  # [num_features]\n",
    "control_mean = control_features.mean(dim=0)      # [num_features]\n",
    "\n",
    "# Calculate standard deviations\n",
    "assistant_std = assistant_features.std(dim=0)\n",
    "control_std = control_features.std(dim=0)\n",
    "\n",
    "# Calculate difference (assistant - control)\n",
    "feature_diff = assistant_mean - control_mean\n",
    "\n",
    "# Calculate effect size (Cohen's d)\n",
    "pooled_std = torch.sqrt(((assistant_features.shape[0] - 1) * assistant_std**2 + \n",
    "                        (control_features.shape[0] - 1) * control_std**2) / \n",
    "                       (assistant_features.shape[0] + control_features.shape[0] - 2))\n",
    "cohens_d = feature_diff / (pooled_std + 1e-8)  # Add small epsilon to avoid division by zero\n",
    "\n",
    "print(f\"Comprehensive statistics computed for {len(feature_diff):,} SAE features\")\n",
    "print(f\"Max difference: {feature_diff.max():.4f}\")\n",
    "print(f\"Min difference: {feature_diff.min():.4f}\")\n",
    "print(f\"Max Cohen's d: {cohens_d.max():.4f}\")\n",
    "print(f\"Min Cohen's d: {cohens_d.min():.4f}\")\n",
    "print(f\"Features with positive difference (favor assistant): {(feature_diff > 0).sum():,}\")\n",
    "print(f\"Features with negative difference (favor control): {(feature_diff < 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Features by Overall Difference (Exploratory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find features with largest overall differences (comprehensive landscape view)\n",
    "# # This shows ALL types of differences, not just assistant-specific ones\n",
    "\n",
    "# # Sort by difference (assistant - control)\n",
    "# diff_sorted_indices = torch.argsort(feature_diff, descending=True)\n",
    "# top_diff_features = diff_sorted_indices[:TOP_FEATURES]\n",
    "\n",
    "# # Sort by Cohen's d (effect size)\n",
    "# cohens_d_sorted_indices = torch.argsort(cohens_d, descending=True)\n",
    "# top_cohens_d_features = cohens_d_sorted_indices[:TOP_FEATURES]\n",
    "\n",
    "# # Create comprehensive results dataframe for general landscape\n",
    "# landscape_results_data = []\n",
    "\n",
    "# print(f\"Top {TOP_FEATURES} features by raw difference (assistant - control):\")\n",
    "# print(\"This exploratory analysis shows the biggest overall differences, regardless of activation patterns\")\n",
    "# print(\"Feature ID | Assistant Mean | Control Mean | Difference | Cohen's d | Interpretation\")\n",
    "# print(\"-\" * 90)\n",
    "\n",
    "# for i, feature_idx in enumerate(top_diff_features[:20]):  # Show top 20\n",
    "#     feature_id = feature_idx.item()\n",
    "#     ass_mean = assistant_mean[feature_idx].item()\n",
    "#     ctrl_mean = control_mean[feature_idx].item()\n",
    "#     diff = feature_diff[feature_idx].item()\n",
    "#     cohens = cohens_d[feature_idx].item()\n",
    "    \n",
    "#     # Determine interpretation\n",
    "#     if ctrl_mean < 0.01:\n",
    "#         interpretation = \"Assistant-specific\"\n",
    "#     elif ass_mean < 0.01:\n",
    "#         interpretation = \"Control-specific\"  \n",
    "#     elif ass_mean > ctrl_mean * 3:\n",
    "#         interpretation = \"Strongly favors assistant\"\n",
    "#     elif ctrl_mean > ass_mean * 3:\n",
    "#         interpretation = \"Strongly favors control\"\n",
    "#     else:\n",
    "#         interpretation = \"Moderate difference\"\n",
    "    \n",
    "#     print(f\"{feature_id:>10} | {ass_mean:>13.4f} | {ctrl_mean:>12.4f} | {diff:>10.4f} | {cohens:>9.3f} | {interpretation}\")\n",
    "    \n",
    "#     landscape_results_data.append({\n",
    "#         'feature_id': feature_id,\n",
    "#         'assistant_mean': ass_mean,\n",
    "#         'control_mean': ctrl_mean,\n",
    "#         'difference': diff,\n",
    "#         'cohens_d': cohens,\n",
    "#         'rank_by_diff': i + 1,\n",
    "#         'interpretation': interpretation,\n",
    "#         'analysis_type': 'landscape_difference'\n",
    "#     })\n",
    "\n",
    "# # Save comprehensive landscape results\n",
    "# landscape_df = pd.DataFrame(landscape_results_data)\n",
    "# landscape_df.to_csv('feature_landscape_analysis.csv', index=False)\n",
    "# print(f\"\\nComprehensive landscape results saved to feature_landscape_analysis.csv\")\n",
    "# print(\"Note: This includes all types of differences - see next section for assistant-specific analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "\n",
    "# # Perform t-tests for top landscape features to assess statistical significance\n",
    "# significant_features = []\n",
    "\n",
    "# print(\"Statistical significance testing (t-test) for top 20 landscape features:\")\n",
    "# print(\"Testing whether the observed differences are statistically reliable\")\n",
    "# print(\"Feature ID | t-statistic | p-value | Significant (p<0.05)\")\n",
    "# print(\"-\" * 60)\n",
    "\n",
    "# for feature_idx in top_diff_features[:20]:\n",
    "#     feature_id = feature_idx.item()\n",
    "    \n",
    "#     # Get feature activations for both groups\n",
    "#     assistant_vals = assistant_features[:, feature_idx].numpy()\n",
    "#     control_vals = control_features[:, feature_idx].numpy()\n",
    "    \n",
    "#     # Perform independent t-test\n",
    "#     t_stat, p_val = stats.ttest_ind(assistant_vals, control_vals)\n",
    "    \n",
    "#     is_significant = p_val < 0.05\n",
    "#     if is_significant:\n",
    "#         significant_features.append(feature_id)\n",
    "    \n",
    "#     print(f\"{feature_id:>10} | {t_stat:>11.3f} | {p_val:>7.4f} | {is_significant}\")\n",
    "\n",
    "# print(f\"\\nFound {len(significant_features)} statistically significant features (p < 0.05) from landscape analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted Assistant-Specific Feature Analysis\n",
    "\n",
    "This section identifies features that are **uniquely characteristic of assistant responses**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant-specific analysis functions defined\n"
     ]
    }
   ],
   "source": [
    "# Assistant-specific feature analysis functions\n",
    "def find_assistant_only_features(assistant_mean, control_mean, \n",
    "                                 assistant_threshold=0.1, control_threshold=0.01):\n",
    "    \"\"\"Find features that activate strongly on assistant prompts but not on control prompts.\"\"\"\n",
    "    assistant_active = assistant_mean > assistant_threshold\n",
    "    control_inactive = control_mean <= control_threshold\n",
    "    \n",
    "    assistant_only_mask = assistant_active & control_inactive\n",
    "    assistant_only_indices = torch.where(assistant_only_mask)[0]\n",
    "    \n",
    "    # Sort by assistant activation strength\n",
    "    assistant_only_values = assistant_mean[assistant_only_indices]\n",
    "    sorted_indices = torch.argsort(assistant_only_values, descending=True)\n",
    "    top_assistant_only = assistant_only_indices[sorted_indices]\n",
    "    \n",
    "    return top_assistant_only\n",
    "\n",
    "def find_high_effect_features(cohens_d, assistant_mean, control_mean,\n",
    "                             effect_threshold=1.0, control_threshold=0.05, assistant_threshold=0.1):\n",
    "    \"\"\"Find features with high effect size favoring assistant prompts.\"\"\"\n",
    "    strong_assistant_features = (\n",
    "        (cohens_d > effect_threshold) & \n",
    "        (control_mean < control_threshold) &\n",
    "        (assistant_mean > assistant_threshold)\n",
    "    )\n",
    "    \n",
    "    strong_assistant_indices = torch.where(strong_assistant_features)[0]\n",
    "    \n",
    "    # Sort by effect size\n",
    "    effect_values = cohens_d[strong_assistant_indices]\n",
    "    sorted_indices = torch.argsort(effect_values, descending=True)\n",
    "    top_effect_features = strong_assistant_indices[sorted_indices]\n",
    "    \n",
    "    return top_effect_features\n",
    "\n",
    "def find_ratio_based_features(assistant_mean, control_mean,\n",
    "                             min_ratio=10.0, min_assistant_activation=0.1):\n",
    "    \"\"\"Find features where assistant activation is much higher than control.\"\"\"\n",
    "    # Avoid division by zero\n",
    "    safe_control_mean = control_mean + 1e-6\n",
    "    activation_ratio = assistant_mean / safe_control_mean\n",
    "    \n",
    "    ratio_based_features = (\n",
    "        (activation_ratio > min_ratio) &\n",
    "        (assistant_mean > min_assistant_activation)\n",
    "    )\n",
    "    \n",
    "    ratio_based_indices = torch.where(ratio_based_features)[0]\n",
    "    \n",
    "    # Sort by ratio\n",
    "    ratio_values = activation_ratio[ratio_based_indices]\n",
    "    sorted_indices = torch.argsort(ratio_values, descending=True)\n",
    "    top_ratio_features = ratio_based_indices[sorted_indices]\n",
    "    \n",
    "    return top_ratio_features\n",
    "\n",
    "def find_universal_assistant_features(assistant_features, control_features,\n",
    "                                     assistant_threshold=0.1, control_threshold=0.01):\n",
    "    \"\"\"Find features that activate on ALL assistant prompts but NO control prompts.\"\"\"\n",
    "    assistant_active_all = (assistant_features > assistant_threshold).all(dim=0)\n",
    "    control_active_none = (control_features <= control_threshold).all(dim=0)\n",
    "    \n",
    "    universal_assistant_features = assistant_active_all & control_active_none\n",
    "    universal_indices = torch.where(universal_assistant_features)[0]\n",
    "    \n",
    "    # Sort by mean assistant activation\n",
    "    assistant_mean_universal = assistant_features[:, universal_indices].mean(dim=0)\n",
    "    sorted_indices = torch.argsort(assistant_mean_universal, descending=True)\n",
    "    top_universal_features = universal_indices[sorted_indices]\n",
    "    \n",
    "    return top_universal_features\n",
    "\n",
    "def save_feature_analysis_to_csv(feature_indices, assistant_mean, control_mean, \n",
    "                                cohens_d, filename, analysis_type):\n",
    "    \"\"\"Save feature analysis results to CSV.\"\"\"\n",
    "    results_data = []\n",
    "    \n",
    "    for i, feature_idx in enumerate(feature_indices):\n",
    "        feature_id = feature_idx.item()\n",
    "        ass_mean = assistant_mean[feature_idx].item()\n",
    "        ctrl_mean = control_mean[feature_idx].item()\n",
    "        effect_size = cohens_d[feature_idx].item()\n",
    "        \n",
    "        results_data.append({\n",
    "            'feature_id': feature_id,\n",
    "            'assistant_mean': ass_mean,\n",
    "            'control_mean': ctrl_mean,\n",
    "            'difference': ass_mean - ctrl_mean,\n",
    "            'cohens_d': effect_size,\n",
    "            'rank': i + 1,\n",
    "            'analysis_type': analysis_type\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    results_df.to_csv(f\"{OUTPUT_DIR}/{filename}\", index=False)\n",
    "    print(f\"Saved {len(results_data)} {analysis_type} features to {filename}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"Assistant-specific analysis functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ASSISTANT-SPECIFIC FEATURE ANALYSIS\n",
      "================================================================================\n",
      "These analyses identify features uniquely characteristic of assistant responses\n",
      "\n",
      "Analysis 1: ASSISTANT-ONLY FEATURES\n",
      "   Criteria: Strong on assistant (>0.1), minimal on control (≤0.01)\n",
      "   Found: 8 features\n",
      "Saved 8 assistant_only features to assistant_only_features.csv\n",
      "     #1: Feature 18703 (Assistant: 0.8322, Control: 0.0000)\n",
      "     #2: Feature 45508 (Assistant: 0.7316, Control: 0.0000)\n",
      "     #3: Feature 30068 (Assistant: 0.4780, Control: 0.0000)\n",
      "     #4: Feature 70419 (Assistant: 0.3200, Control: 0.0000)\n",
      "     #5: Feature 20338 (Assistant: 0.2552, Control: 0.0000)\n",
      "\n",
      "Analysis 2: HIGH EFFECT SIZE FEATURES\n",
      "   Criteria: Large Cohen's d (>1.0), low control activation (<0.05)\n",
      "   Found: 2 features\n",
      "Saved 2 high_effect features to high_effect_features.csv\n",
      "     #1: Feature 45508 (Cohen's d: 1.338, Assistant: 0.7316)\n",
      "     #2: Feature 18703 (Cohen's d: 1.319, Assistant: 0.8322)\n",
      "\n",
      "Analysis 3: RATIO-BASED FEATURES\n",
      "   Criteria: Assistant activation ≥10x control activation\n",
      "   Found: 9 features\n",
      "Saved 9 ratio_based features to ratio_based_features.csv\n",
      "     #1: Feature 18703 (Ratio: 832151.0x, 0.8322 vs 0.0000)\n",
      "     #2: Feature 45508 (Ratio: 731574.0x, 0.7316 vs 0.0000)\n",
      "     #3: Feature 30068 (Ratio: 478012.3x, 0.4780 vs 0.0000)\n",
      "     #4: Feature 70419 (Ratio: 320022.3x, 0.3200 vs 0.0000)\n",
      "     #5: Feature 20338 (Ratio: 255231.8x, 0.2552 vs 0.0000)\n",
      "\n",
      "Analysis 4: UNIVERSAL ASSISTANT FEATURES\n",
      "   Criteria: Active on ALL assistant prompts, inactive on ALL control prompts\n",
      "   Found: 0 features\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF ANALYSIS OUTPUTS\n",
      "================================================================================\n",
      "Assistant-only features: assistant_only_features.csv\n",
      "High effect size features: high_effect_features.csv\n",
      "Ratio-based features: ratio_based_features.csv\n",
      "Universal features: universal_assistant_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Run all four assistant-specific analyses\n",
    "print(\"=\" * 80)\n",
    "print(\"ASSISTANT-SPECIFIC FEATURE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"These analyses identify features uniquely characteristic of assistant responses\")\n",
    "print()\n",
    "\n",
    "# Option 1: Assistant-only features (strict criteria)\n",
    "print(\"Analysis 1: ASSISTANT-ONLY FEATURES\")\n",
    "print(\"   Criteria: Strong on assistant (>0.1), minimal on control (≤0.01)\")\n",
    "assistant_only_features = find_assistant_only_features(assistant_mean, control_mean)\n",
    "print(f\"   Found: {len(assistant_only_features)} features\")\n",
    "if len(assistant_only_features) > 0:\n",
    "    save_feature_analysis_to_csv(assistant_only_features, assistant_mean, control_mean, \n",
    "                                cohens_d, 'assistant_only_features.csv', 'assistant_only')\n",
    "    # Show top 5\n",
    "    for i, feature_idx in enumerate(assistant_only_features[:5]):\n",
    "        feature_id = feature_idx.item()\n",
    "        ass_mean = assistant_mean[feature_idx].item()\n",
    "        ctrl_mean = control_mean[feature_idx].item()\n",
    "        print(f\"     #{i+1}: Feature {feature_id} (Assistant: {ass_mean:.4f}, Control: {ctrl_mean:.4f})\")\n",
    "print()\n",
    "\n",
    "# Option 2: High effect size features (statistical strength)\n",
    "print(\"Analysis 2: HIGH EFFECT SIZE FEATURES\")\n",
    "print(\"   Criteria: Large Cohen's d (>1.0), low control activation (<0.05)\")\n",
    "high_effect_features = find_high_effect_features(cohens_d, assistant_mean, control_mean)\n",
    "print(f\"   Found: {len(high_effect_features)} features\")\n",
    "if len(high_effect_features) > 0:\n",
    "    save_feature_analysis_to_csv(high_effect_features, assistant_mean, control_mean,\n",
    "                                cohens_d, 'high_effect_features.csv', 'high_effect')\n",
    "    # Show top 5\n",
    "    for i, feature_idx in enumerate(high_effect_features[:5]):\n",
    "        feature_id = feature_idx.item()\n",
    "        effect_size = cohens_d[feature_idx].item()\n",
    "        ass_mean = assistant_mean[feature_idx].item()\n",
    "        print(f\"     #{i+1}: Feature {feature_id} (Cohen's d: {effect_size:.3f}, Assistant: {ass_mean:.4f})\")\n",
    "print()\n",
    "\n",
    "# Option 3: Ratio-based features (dramatic differences)\n",
    "print(\"Analysis 3: RATIO-BASED FEATURES\")\n",
    "print(\"   Criteria: Assistant activation ≥10x control activation\")\n",
    "ratio_features = find_ratio_based_features(assistant_mean, control_mean)\n",
    "print(f\"   Found: {len(ratio_features)} features\")\n",
    "if len(ratio_features) > 0:\n",
    "    save_feature_analysis_to_csv(ratio_features, assistant_mean, control_mean,\n",
    "                                cohens_d, 'ratio_based_features.csv', 'ratio_based')\n",
    "    # Show top 5 with ratios\n",
    "    safe_control = control_mean + 1e-6\n",
    "    ratios = assistant_mean / safe_control\n",
    "    for i, feature_idx in enumerate(ratio_features[:5]):\n",
    "        feature_id = feature_idx.item()\n",
    "        ratio = ratios[feature_idx].item()\n",
    "        ass_mean = assistant_mean[feature_idx].item()\n",
    "        ctrl_mean = control_mean[feature_idx].item()\n",
    "        print(f\"     #{i+1}: Feature {feature_id} (Ratio: {ratio:.1f}x, {ass_mean:.4f} vs {ctrl_mean:.4f})\")\n",
    "print()\n",
    "\n",
    "# Option 4: Universal assistant features (most reliable)\n",
    "print(\"Analysis 4: UNIVERSAL ASSISTANT FEATURES\")\n",
    "print(\"   Criteria: Active on ALL assistant prompts, inactive on ALL control prompts\")\n",
    "universal_features = find_universal_assistant_features(assistant_features, control_features)\n",
    "print(f\"   Found: {len(universal_features)} features\")\n",
    "if len(universal_features) > 0:\n",
    "    save_feature_analysis_to_csv(universal_features, assistant_mean, control_mean,\n",
    "                                cohens_d, 'universal_assistant_features.csv', 'universal')\n",
    "    # Show top 5\n",
    "    for i, feature_idx in enumerate(universal_features[:5]):\n",
    "        feature_id = feature_idx.item()\n",
    "        ass_mean = assistant_mean[feature_idx].item()\n",
    "        ctrl_mean = control_mean[feature_idx].item()\n",
    "        print(f\"     #{i+1}: Feature {feature_id} (Assistant: {ass_mean:.4f}, Control: {ctrl_mean:.4f})\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY OF ANALYSIS OUTPUTS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Assistant-only features: assistant_only_features.csv\")\n",
    "print(\"High effect size features: high_effect_features.csv\") \n",
    "print(\"Ratio-based features: ratio_based_features.csv\")\n",
    "print(\"Universal features: universal_assistant_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
