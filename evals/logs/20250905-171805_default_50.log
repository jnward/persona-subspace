=== 2025-09-05T17:18:05+00:00 === uv run 1_steering.py --pca_filepath /workspace/gemma-2-27b/roles_traits/pca/layer22_roles_pos23_traits_pos40-100.pt --prompts_file /root/git/persona-subspace/evals/susceptibility/default_50.jsonl --magnitudes -800.0 -400.0 400.0 800.0 1200.0 1600.0 2000.0 2400.0 2800.0 3200.0 --output_jsonl /root/git/persona-subspace/evals/susceptibility/gemma-2-27b/steered/default_50.jsonl --batch_size 16 --company Google --name Gemma --layer 22 --model google/gemma-2-27b-it --samples_per_prompt 10
2025-09-05 17:18:09,455 - INFO - Filtered 10000 work units to 9000 new units
2025-09-05 17:18:09,456 - INFO - Created 570 work batches from 9000 work units
============================================================
Optimized Hybrid Queue-Batch GPU Parallelized Steering
============================================================
Loading PCA results from /workspace/gemma-2-27b/roles_traits/pca/layer22_roles_pos23_traits_pos40-100.pt
Found PCA with 798 components
Loading prompts from /root/git/persona-subspace/evals/susceptibility/default_50.jsonl
Loaded 100 prompts
Using PC1 with combined prompts
Total work units: 10000 (10 magnitudes)
Batch size: 16
Processing 9000 work units in 570 batches
Found 8 GPUs available
Using GPUs: [0, 1, 2, 3, 4, 5, 6, 7]

Launched 8 worker processes
2025-09-05 17:18:15,896 - GPU-7 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:15,896 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:15,936 - GPU-4 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:15,936 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:15,937 - GPU-6 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:15,937 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:15,961 - GPU-5 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:15,961 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:15,983 - GPU-0 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:15,983 - INFO - Starting optimized work queue consumer
Overall progress:   0%|          | 0/9000 [00:00<?, ?work_units/s]2025-09-05 17:18:16,018 - GPU-3 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:16,018 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:16,026 - GPU-2 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:16,026 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:16,054 - GPU-1 - INFO - Starting optimized work queue consumer
2025-09-05 17:18:16,054 - INFO - Starting optimized work queue consumer
Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:00<00:08,  1.33it/s]Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:00<00:08,  1.34it/s]Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:00<00:09,  1.12it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:00<00:09,  1.10it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:00<00:08,  1.22it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:00<00:08,  1.24it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:00<00:08,  1.23it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:00<00:08,  1.23it/s]Loading checkpoint shards:  17%|█▋        | 2/12 [00:01<00:08,  1.20it/s]Loading checkpoint shards:  17%|█▋        | 2/12 [00:01<00:08,  1.17it/s]Loading checkpoint shards:  17%|█▋        | 2/12 [00:01<00:09,  1.05it/s]Loading checkpoint shards:  17%|█▋        | 2/12 [00:01<00:09,  1.05it/s]Loading checkpoint shards:  17%|█▋        | 2/12 [00:01<00:08,  1.22it/s]Loading checkpoint shards:  17%|█▋        | 2/12 [00:01<00:08,  1.18it/s]Loading checkpoint shards:  17%|█▋        | 2/12 [00:01<00:08,  1.22it/s]Loading checkpoint shards:  17%|█▋        | 2/12 [00:01<00:08,  1.18it/s]Loading checkpoint shards:  25%|██▌       | 3/12 [00:02<00:07,  1.16it/s]Loading checkpoint shards:  25%|██▌       | 3/12 [00:02<00:07,  1.15it/s]Loading checkpoint shards:  33%|███▎      | 4/12 [00:03<00:06,  1.19it/s]Loading checkpoint shards:  33%|███▎      | 4/12 [00:03<00:06,  1.18it/s]Loading checkpoint shards:  25%|██▌       | 3/12 [00:02<00:08,  1.02it/s]Loading checkpoint shards:  25%|██▌       | 3/12 [00:02<00:07,  1.13it/s]Loading checkpoint shards:  25%|██▌       | 3/12 [00:02<00:07,  1.14it/s]Loading checkpoint shards:  25%|██▌       | 3/12 [00:02<00:08,  1.09it/s]Loading checkpoint shards:  25%|██▌       | 3/12 [00:02<00:08,  1.00it/s]Loading checkpoint shards:  25%|██▌       | 3/12 [00:02<00:08,  1.12it/s]Loading checkpoint shards:  42%|████▏     | 5/12 [00:04<00:05,  1.21it/s]Loading checkpoint shards:  33%|███▎      | 4/12 [00:03<00:06,  1.18it/s]Loading checkpoint shards:  42%|████▏     | 5/12 [00:04<00:05,  1.19it/s]Loading checkpoint shards:  33%|███▎      | 4/12 [00:03<00:07,  1.09it/s]Loading checkpoint shards:  33%|███▎      | 4/12 [00:03<00:07,  1.02it/s]Loading checkpoint shards:  33%|███▎      | 4/12 [00:03<00:07,  1.08it/s]Loading checkpoint shards:  33%|███▎      | 4/12 [00:03<00:07,  1.06it/s]Loading checkpoint shards:  33%|███▎      | 4/12 [00:03<00:07,  1.05it/s]Loading checkpoint shards:  50%|█████     | 6/12 [00:04<00:04,  1.23it/s]Loading checkpoint shards:  42%|████▏     | 5/12 [00:04<00:05,  1.20it/s]Loading checkpoint shards:  50%|█████     | 6/12 [00:05<00:04,  1.21it/s]Loading checkpoint shards:  42%|████▏     | 5/12 [00:04<00:06,  1.15it/s]Loading checkpoint shards:  42%|████▏     | 5/12 [00:04<00:06,  1.11it/s]Loading checkpoint shards:  42%|████▏     | 5/12 [00:04<00:06,  1.03it/s]Loading checkpoint shards:  42%|████▏     | 5/12 [00:04<00:06,  1.03it/s]Loading checkpoint shards:  42%|████▏     | 5/12 [00:04<00:06,  1.04it/s]Loading checkpoint shards:  58%|█████▊    | 7/12 [00:05<00:04,  1.23it/s]Loading checkpoint shards:  58%|█████▊    | 7/12 [00:05<00:04,  1.21it/s]Loading checkpoint shards:  50%|█████     | 6/12 [00:05<00:05,  1.13it/s]Loading checkpoint shards:  50%|█████     | 6/12 [00:05<00:05,  1.17it/s]Loading checkpoint shards:  50%|█████     | 6/12 [00:05<00:05,  1.15it/s]Loading checkpoint shards:  50%|█████     | 6/12 [00:05<00:05,  1.06it/s]Loading checkpoint shards:  50%|█████     | 6/12 [00:05<00:05,  1.05it/s]Loading checkpoint shards:  50%|█████     | 6/12 [00:05<00:05,  1.06it/s]Loading checkpoint shards:  67%|██████▋   | 8/12 [00:06<00:03,  1.23it/s]Loading checkpoint shards:  67%|██████▋   | 8/12 [00:06<00:03,  1.21it/s]Loading checkpoint shards:  58%|█████▊    | 7/12 [00:05<00:04,  1.18it/s]Loading checkpoint shards:  58%|█████▊    | 7/12 [00:06<00:04,  1.14it/s]Loading checkpoint shards:  58%|█████▊    | 7/12 [00:06<00:04,  1.11it/s]Loading checkpoint shards:  58%|█████▊    | 7/12 [00:06<00:04,  1.09it/s]Loading checkpoint shards:  58%|█████▊    | 7/12 [00:06<00:04,  1.09it/s]Loading checkpoint shards:  58%|█████▊    | 7/12 [00:06<00:04,  1.08it/s]Loading checkpoint shards:  75%|███████▌  | 9/12 [00:07<00:02,  1.23it/s]Loading checkpoint shards:  75%|███████▌  | 9/12 [00:07<00:02,  1.21it/s]Loading checkpoint shards:  67%|██████▋   | 8/12 [00:06<00:03,  1.19it/s]Loading checkpoint shards:  67%|██████▋   | 8/12 [00:07<00:03,  1.10it/s]Loading checkpoint shards:  67%|██████▋   | 8/12 [00:07<00:03,  1.12it/s]Loading checkpoint shards:  67%|██████▋   | 8/12 [00:07<00:03,  1.11it/s]Loading checkpoint shards:  67%|██████▋   | 8/12 [00:07<00:03,  1.12it/s]Loading checkpoint shards:  67%|██████▋   | 8/12 [00:07<00:03,  1.12it/s]Loading checkpoint shards:  83%|████████▎ | 10/12 [00:08<00:01,  1.20it/s]Loading checkpoint shards:  83%|████████▎ | 10/12 [00:08<00:01,  1.19it/s]Loading checkpoint shards:  75%|███████▌  | 9/12 [00:07<00:02,  1.20it/s]Loading checkpoint shards:  75%|███████▌  | 9/12 [00:08<00:02,  1.11it/s]Loading checkpoint shards:  75%|███████▌  | 9/12 [00:08<00:02,  1.10it/s]Loading checkpoint shards:  75%|███████▌  | 9/12 [00:08<00:02,  1.12it/s]Loading checkpoint shards:  75%|███████▌  | 9/12 [00:08<00:02,  1.12it/s]Loading checkpoint shards:  75%|███████▌  | 9/12 [00:08<00:02,  1.12it/s]Loading checkpoint shards:  92%|█████████▏| 11/12 [00:09<00:00,  1.20it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:09<00:00,  1.63it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:09<00:00,  1.31it/s]
Loading checkpoint shards:  92%|█████████▏| 11/12 [00:09<00:00,  1.19it/s]Loading checkpoint shards:  83%|████████▎ | 10/12 [00:08<00:01,  1.19it/s]2025-09-05 17:18:33,215 - GPU-7 - INFO - Model loaded on cuda:7
2025-09-05 17:18:33,215 - INFO - Model loaded on cuda:7
Loading checkpoint shards: 100%|██████████| 12/12 [00:09<00:00,  1.61it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:09<00:00,  1.29it/s]
2025-09-05 17:18:33,324 - GPU-5 - INFO - Model loaded on cuda:5
2025-09-05 17:18:33,324 - INFO - Model loaded on cuda:5
Loading checkpoint shards:  83%|████████▎ | 10/12 [00:09<00:01,  1.09it/s]Loading checkpoint shards:  83%|████████▎ | 10/12 [00:09<00:01,  1.09it/s]Loading checkpoint shards:  83%|████████▎ | 10/12 [00:09<00:01,  1.12it/s]Loading checkpoint shards:  83%|████████▎ | 10/12 [00:09<00:01,  1.12it/s]Loading checkpoint shards:  83%|████████▎ | 10/12 [00:09<00:01,  1.12it/s]2025-09-05 17:18:33,844 - GPU-7 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:33,844 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:33,844 - GPU-7 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:33,844 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:33,934 - GPU-5 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:33,934 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:33,934 - GPU-5 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:33,934 - INFO - Processing batch 1 (16 work units)
Loading checkpoint shards:  92%|█████████▏| 11/12 [00:09<00:00,  1.21it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:09<00:00,  1.64it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:09<00:00,  1.28it/s]
2025-09-05 17:18:34,155 - GPU-4 - INFO - Model loaded on cuda:4
2025-09-05 17:18:34,155 - INFO - Model loaded on cuda:4
Loading checkpoint shards:  92%|█████████▏| 11/12 [00:10<00:00,  1.09it/s]Loading checkpoint shards:  92%|█████████▏| 11/12 [00:10<00:00,  1.09it/s]Loading checkpoint shards:  92%|█████████▏| 11/12 [00:09<00:00,  1.15it/s]Loading checkpoint shards:  92%|█████████▏| 11/12 [00:09<00:00,  1.15it/s]Loading checkpoint shards:  92%|█████████▏| 11/12 [00:09<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:10<00:00,  1.48it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:10<00:00,  1.18it/s]
Loading checkpoint shards: 100%|██████████| 12/12 [00:10<00:00,  1.49it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:10<00:00,  1.18it/s]
Loading checkpoint shards: 100%|██████████| 12/12 [00:09<00:00,  1.21it/s]
Loading checkpoint shards: 100%|██████████| 12/12 [00:09<00:00,  1.21it/s]
2025-09-05 17:18:34,676 - GPU-2 - INFO - Model loaded on cuda:2
2025-09-05 17:18:34,676 - INFO - Model loaded on cuda:2
Loading checkpoint shards: 100%|██████████| 12/12 [00:10<00:00,  1.56it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:10<00:00,  1.20it/s]
2025-09-05 17:18:34,689 - GPU-1 - INFO - Model loaded on cuda:1
2025-09-05 17:18:34,689 - INFO - Model loaded on cuda:1
2025-09-05 17:18:34,751 - GPU-6 - INFO - Model loaded on cuda:6
2025-09-05 17:18:34,751 - INFO - Model loaded on cuda:6
2025-09-05 17:18:34,751 - GPU-0 - INFO - Model loaded on cuda:0
2025-09-05 17:18:34,751 - INFO - Model loaded on cuda:0
2025-09-05 17:18:34,754 - GPU-3 - INFO - Model loaded on cuda:3
2025-09-05 17:18:34,754 - INFO - Model loaded on cuda:3
2025-09-05 17:18:34,771 - GPU-4 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:34,771 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:34,772 - GPU-4 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:34,772 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:35,258 - GPU-2 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:35,258 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:35,258 - GPU-2 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:35,258 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:35,261 - GPU-1 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:35,261 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:35,262 - GPU-1 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:35,262 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:35,324 - GPU-0 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:35,324 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:35,325 - GPU-0 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:35,325 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:35,330 - GPU-6 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:35,330 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:35,331 - GPU-6 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:35,331 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:35,334 - GPU-3 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:35,334 - INFO - Using PC1, steering vector shape: torch.Size([4608])
2025-09-05 17:18:35,334 - GPU-3 - INFO - Processing batch 1 (16 work units)
2025-09-05 17:18:35,334 - INFO - Processing batch 1 (16 work units)
Overall progress:   0%|          | 0/9000 [00:30<?, ?work_units/s]
2025-09-05 17:18:46,041 - INFO - Progress monitoring completed. Total processed: 0
2025-09-05 17:19:22,550 - GPU-3 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:22,550 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:22,551 - GPU-3 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:22,551 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:23,078 - GPU-1 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:23,078 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:23,078 - GPU-1 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:23,078 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:23,453 - GPU-5 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:23,453 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:23,453 - GPU-5 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:23,453 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:23,691 - GPU-4 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:23,691 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:23,691 - GPU-4 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:23,691 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:24,500 - GPU-2 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:24,500 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:24,500 - GPU-2 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:24,500 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:25,426 - GPU-6 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:25,426 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:25,427 - GPU-6 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:25,427 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:27,960 - GPU-2 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:19:27,960 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:19:28,359 - GPU-2 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:19:28,359 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:19:28,711 - GPU-0 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:28,711 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:28,711 - GPU-0 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:28,711 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:28,800 - GPU-1 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:19:28,800 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:19:28,865 - GPU-7 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:28,865 - INFO - Completed batch 1, total work units processed by this worker: 16
2025-09-05 17:19:28,866 - GPU-7 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:28,866 - INFO - Processing batch 2 (16 work units)
2025-09-05 17:19:29,221 - GPU-1 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:19:29,221 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:19:29,658 - GPU-6 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:19:29,658 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:19:29,748 - GPU-3 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:19:29,748 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:19:30,071 - GPU-6 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:19:30,071 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:19:30,182 - GPU-3 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:19:30,182 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:19:32,240 - GPU-0 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:19:32,240 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:19:32,660 - GPU-0 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:19:32,660 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:19:33,468 - GPU-1 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:19:33,468 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:19:33,468 - GPU-1 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:19:33,468 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:19:33,476 - GPU-6 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:19:33,476 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:19:33,476 - GPU-6 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:19:33,476 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:19:34,602 - GPU-2 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:19:34,602 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:19:34,602 - GPU-2 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:19:34,602 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:19:35,440 - GPU-3 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:19:35,440 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:19:35,440 - GPU-3 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:19:35,440 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:19:38,598 - GPU-1 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:19:38,598 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:19:38,741 - GPU-6 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:19:38,741 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:19:38,791 - GPU-0 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:19:38,791 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:19:38,791 - GPU-0 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:19:38,791 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:19:39,042 - GPU-1 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:19:39,042 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:19:39,195 - GPU-6 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:19:39,195 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:19:43,597 - GPU-1 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:19:43,597 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:19:43,597 - GPU-1 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:19:43,597 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:19:44,253 - GPU-6 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:19:44,253 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:19:44,254 - GPU-6 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:19:44,254 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:20:19,440 - GPU-5 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:20:19,440 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:20:20,322 - GPU-5 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:20:20,322 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:20:22,330 - GPU-4 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:20:22,330 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:20:23,157 - GPU-4 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:20:23,157 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:20:23,471 - GPU-7 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:20:23,471 - INFO - Completed batch 2, total work units processed by this worker: 32
2025-09-05 17:20:24,214 - GPU-7 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:20:24,214 - INFO - Processing batch 3 (16 work units)
2025-09-05 17:20:29,016 - GPU-2 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:20:29,016 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:20:29,739 - GPU-2 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:20:29,739 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:20:29,987 - GPU-3 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:20:29,987 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:20:30,713 - GPU-3 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:20:30,713 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:20:35,709 - GPU-0 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:20:35,709 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:20:36,457 - GPU-0 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:20:36,457 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:20:37,047 - GPU-3 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:20:37,047 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:20:37,047 - GPU-3 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:20:37,047 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:20:38,998 - GPU-6 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:20:38,998 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:20:39,708 - GPU-6 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:20:39,708 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:20:40,449 - GPU-1 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:20:40,449 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:20:40,451 - GPU-0 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:20:40,451 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:20:40,452 - GPU-0 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:20:40,452 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:20:41,202 - GPU-1 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:20:41,202 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:20:43,743 - GPU-6 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:20:43,743 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:20:43,743 - GPU-6 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:20:43,743 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:20:44,423 - GPU-0 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:20:44,423 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:20:45,219 - GPU-0 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:20:45,219 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:20:46,486 - GPU-1 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:20:46,486 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:20:46,486 - GPU-1 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:20:46,486 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:20:46,839 - GPU-6 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:20:46,839 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:20:47,638 - GPU-6 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:20:47,638 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:20:47,917 - GPU-0 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:20:47,917 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:20:47,918 - GPU-0 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:20:47,918 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:20:51,628 - GPU-5 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:20:51,628 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:20:51,628 - GPU-5 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:20:51,628 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:20:52,089 - GPU-1 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:20:52,089 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:20:52,510 - GPU-0 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:20:52,510 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:20:52,661 - GPU-6 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:20:52,661 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:20:52,661 - GPU-6 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:20:52,661 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:20:53,024 - GPU-1 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:20:53,024 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:20:53,292 - GPU-0 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:20:53,292 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:20:56,409 - GPU-7 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:20:56,409 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:20:56,409 - GPU-7 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:20:56,409 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:20:56,835 - GPU-4 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:20:56,835 - INFO - Completed batch 3, total work units processed by this worker: 48
2025-09-05 17:20:56,835 - GPU-4 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:20:56,835 - INFO - Processing batch 4 (16 work units)
2025-09-05 17:20:58,537 - GPU-6 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:20:58,537 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:20:59,009 - GPU-0 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:20:59,009 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:20:59,009 - GPU-0 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:20:59,009 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:20:59,205 - GPU-5 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:20:59,205 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:20:59,317 - GPU-6 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:20:59,317 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:21:00,105 - GPU-5 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:21:00,105 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:21:00,540 - GPU-1 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:21:00,540 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:21:00,540 - GPU-1 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:21:00,540 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:21:00,760 - GPU-7 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:21:00,760 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:21:01,541 - GPU-7 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:21:01,541 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:21:02,048 - GPU-2 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:21:02,048 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:21:02,049 - GPU-2 - INFO - Processing batch 6 (4 work units)
2025-09-05 17:21:02,049 - INFO - Processing batch 6 (4 work units)
2025-09-05 17:21:03,488 - GPU-4 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:21:03,488 - INFO - Completed batch 4, total work units processed by this worker: 64
2025-09-05 17:21:04,440 - GPU-4 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:21:04,440 - INFO - Processing batch 5 (16 work units)
2025-09-05 17:21:10,879 - GPU-3 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:21:10,879 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:21:11,714 - GPU-3 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:21:11,714 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:21:31,008 - GPU-6 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:21:31,008 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:21:31,008 - GPU-6 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:21:31,008 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:21:32,092 - GPU-1 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:21:32,092 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:21:32,440 - GPU-0 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:21:32,440 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:21:32,737 - GPU-7 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:21:32,737 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:21:32,737 - GPU-7 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:21:32,737 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:21:33,092 - GPU-1 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:21:33,092 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:21:33,276 - GPU-0 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:21:33,276 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:21:35,812 - GPU-5 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:21:35,812 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:21:35,812 - GPU-5 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:21:35,812 - INFO - Processing batch 6 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
2025-09-05 17:22:03,818 - GPU-4 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:22:03,818 - INFO - Completed batch 5, total work units processed by this worker: 80
2025-09-05 17:22:03,819 - GPU-4 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:22:03,819 - INFO - Processing batch 6 (16 work units)
2025-09-05 17:22:05,265 - GPU-3 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:22:05,265 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:22:05,265 - GPU-3 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:22:05,265 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:22:07,356 - GPU-4 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:22:07,356 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:22:09,114 - GPU-4 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:22:09,114 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:22:13,462 - GPU-4 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:22:13,462 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:22:13,463 - GPU-4 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:22:13,463 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:22:13,683 - GPU-3 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:22:13,683 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:22:15,080 - GPU-3 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:22:15,080 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:22:18,916 - GPU-4 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:22:18,916 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:22:20,150 - GPU-4 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:22:20,150 - INFO - Processing batch 9 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
2025-09-05 17:22:20,290 - GPU-2 - INFO - Completed batch 6, total work units processed by this worker: 84
2025-09-05 17:22:20,290 - INFO - Completed batch 6, total work units processed by this worker: 84
2025-09-05 17:22:21,756 - GPU-2 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:22:21,756 - INFO - Processing batch 7 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
2025-09-05 17:22:22,621 - GPU-3 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:22:22,621 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:22:22,621 - GPU-3 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:22:22,621 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:22:24,613 - GPU-4 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:22:24,613 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:22:24,614 - GPU-4 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:22:24,614 - INFO - Processing batch 10 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
2025-09-05 17:22:26,340 - GPU-6 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:22:26,340 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:22:26,778 - GPU-1 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:22:26,778 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:22:26,778 - GPU-1 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:22:26,778 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:22:27,720 - GPU-6 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:22:27,720 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:22:28,404 - GPU-4 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:22:28,404 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:22:29,109 - GPU-7 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:22:29,109 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:22:29,979 - GPU-4 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:22:29,979 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:22:30,541 - GPU-7 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:22:30,541 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:22:31,032 - GPU-3 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:22:31,032 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:22:31,166 - GPU-0 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:22:31,166 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:22:31,166 - GPU-0 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:22:31,166 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:22:32,334 - GPU-3 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:22:32,334 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:22:32,783 - GPU-5 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:22:32,783 - INFO - Completed batch 6, total work units processed by this worker: 96
2025-09-05 17:22:33,045 - GPU-1 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:22:33,045 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:22:34,198 - GPU-6 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:22:34,198 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:22:34,198 - GPU-6 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:22:34,198 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:22:34,295 - GPU-5 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:22:34,295 - INFO - Processing batch 7 (16 work units)
2025-09-05 17:22:34,441 - GPU-1 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:22:34,441 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:22:34,559 - GPU-4 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:22:34,559 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:22:34,559 - GPU-4 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:22:34,559 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:22:37,691 - GPU-3 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:22:37,691 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:22:37,691 - GPU-3 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:22:37,691 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:22:37,762 - GPU-7 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:22:37,762 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:22:37,763 - GPU-7 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:22:37,763 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:22:38,279 - GPU-0 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:22:38,279 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:22:39,441 - GPU-6 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:22:39,441 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:22:39,643 - GPU-0 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:22:39,643 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:22:39,825 - GPU-5 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:22:39,825 - INFO - Completed batch 7, total work units processed by this worker: 112
2025-09-05 17:22:39,826 - GPU-5 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:22:39,826 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:22:40,708 - GPU-6 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:22:40,708 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:22:41,014 - GPU-1 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:22:41,014 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:22:41,014 - GPU-1 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:22:41,014 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:22:41,148 - GPU-4 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:22:41,148 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:22:42,360 - GPU-4 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:22:42,360 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:22:42,927 - GPU-3 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:22:42,927 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:22:44,118 - GPU-3 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:22:44,118 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:22:44,854 - GPU-7 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:22:44,854 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:22:44,860 - GPU-0 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:22:44,860 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:22:44,861 - GPU-0 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:22:44,861 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:22:45,312 - GPU-5 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:22:45,312 - INFO - Completed batch 8, total work units processed by this worker: 128
2025-09-05 17:22:45,733 - GPU-6 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:22:45,733 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:22:45,733 - GPU-6 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:22:45,733 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:22:46,413 - GPU-4 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:22:46,413 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:22:46,413 - GPU-4 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:22:46,413 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:22:46,415 - GPU-7 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:22:46,415 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:22:46,707 - GPU-5 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:22:46,707 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:22:49,037 - GPU-1 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:22:49,037 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:22:49,998 - GPU-5 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:22:49,998 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:22:49,998 - GPU-5 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:22:49,998 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:22:50,273 - GPU-1 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:22:50,273 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:22:51,243 - GPU-4 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:22:51,243 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:22:51,379 - GPU-6 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:22:51,379 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:22:51,988 - GPU-0 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:22:51,988 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:22:52,534 - GPU-4 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:22:52,534 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:22:52,859 - GPU-6 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:22:52,859 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:22:53,556 - GPU-0 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:22:53,556 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:22:53,961 - GPU-1 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:22:53,961 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:22:53,962 - GPU-1 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:22:53,962 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:22:54,573 - GPU-7 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:22:54,573 - INFO - Completed batch 9, total work units processed by this worker: 144
2025-09-05 17:22:54,573 - GPU-7 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:22:54,573 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:22:55,628 - GPU-5 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:22:55,628 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:22:56,471 - GPU-4 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:22:56,471 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:22:56,471 - GPU-4 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:22:56,471 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:22:56,957 - GPU-5 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:22:56,957 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:22:58,074 - GPU-0 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:22:58,074 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:22:58,074 - GPU-0 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:22:58,074 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:23:00,507 - GPU-1 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:23:00,507 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:23:00,771 - GPU-4 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:23:00,771 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:23:01,609 - GPU-6 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:23:01,609 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:23:01,609 - GPU-6 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:23:01,609 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:23:01,872 - GPU-1 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:23:01,872 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:23:02,112 - GPU-4 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:23:02,112 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:23:02,135 - GPU-7 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:23:02,135 - INFO - Completed batch 10, total work units processed by this worker: 160
2025-09-05 17:23:02,190 - GPU-5 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:23:02,190 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:23:02,190 - GPU-5 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:23:02,190 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:23:03,526 - GPU-7 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:23:03,526 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:23:06,341 - GPU-5 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:23:06,341 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:23:06,386 - GPU-6 - INFO - Completed batch 18, total work units processed by this worker: 288
2025-09-05 17:23:06,386 - INFO - Completed batch 18, total work units processed by this worker: 288
2025-09-05 17:23:06,629 - GPU-0 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:23:06,629 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:23:07,781 - GPU-5 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:23:07,781 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:23:07,893 - GPU-6 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:23:07,893 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:23:08,033 - GPU-0 - INFO - Processing batch 17 (4 work units)
2025-09-05 17:23:08,033 - INFO - Processing batch 17 (4 work units)
2025-09-05 17:23:08,929 - GPU-1 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:23:08,929 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:23:08,929 - GPU-1 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:23:08,929 - INFO - Processing batch 18 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
2025-09-05 17:23:11,053 - GPU-5 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:23:11,053 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:23:11,053 - GPU-5 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:23:11,053 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:23:12,285 - GPU-6 - INFO - Completed batch 19, total work units processed by this worker: 304
2025-09-05 17:23:12,285 - INFO - Completed batch 19, total work units processed by this worker: 304
2025-09-05 17:23:12,285 - GPU-6 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:23:12,285 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:23:15,425 - GPU-5 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:23:15,425 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:23:16,293 - GPU-3 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:23:16,293 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:23:16,294 - GPU-3 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:23:16,294 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:23:16,752 - GPU-5 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:23:16,752 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:23:17,459 - GPU-6 - INFO - Completed batch 20, total work units processed by this worker: 320
2025-09-05 17:23:17,459 - INFO - Completed batch 20, total work units processed by this worker: 320
2025-09-05 17:23:18,063 - GPU-1 - INFO - Completed batch 18, total work units processed by this worker: 288
2025-09-05 17:23:18,063 - INFO - Completed batch 18, total work units processed by this worker: 288
2025-09-05 17:23:18,935 - GPU-6 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:23:18,935 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:23:19,417 - GPU-1 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:23:19,417 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:23:21,588 - GPU-3 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:23:21,588 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:23:21,855 - GPU-5 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:23:21,855 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:23:21,856 - GPU-5 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:23:21,856 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:23:23,574 - GPU-3 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:23:23,574 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:23:24,838 - GPU-1 - INFO - Completed batch 19, total work units processed by this worker: 304
2025-09-05 17:23:24,838 - INFO - Completed batch 19, total work units processed by this worker: 304
2025-09-05 17:23:24,838 - GPU-1 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:23:24,838 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:23:25,157 - GPU-6 - INFO - Completed batch 21, total work units processed by this worker: 336
2025-09-05 17:23:25,157 - INFO - Completed batch 21, total work units processed by this worker: 336
2025-09-05 17:23:25,158 - GPU-6 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:23:25,158 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:23:27,057 - GPU-5 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:23:27,057 - INFO - Completed batch 16, total work units processed by this worker: 256
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
2025-09-05 17:23:28,451 - GPU-5 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:23:28,451 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:23:29,188 - GPU-3 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:23:29,188 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:23:29,189 - GPU-3 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:23:29,189 - INFO - Processing batch 16 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
2025-09-05 17:23:30,353 - GPU-6 - INFO - Completed batch 22, total work units processed by this worker: 352
2025-09-05 17:23:30,353 - INFO - Completed batch 22, total work units processed by this worker: 352
2025-09-05 17:23:30,577 - GPU-1 - INFO - Completed batch 20, total work units processed by this worker: 320
2025-09-05 17:23:30,577 - INFO - Completed batch 20, total work units processed by this worker: 320
2025-09-05 17:23:31,926 - GPU-6 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:23:31,926 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:23:31,986 - GPU-1 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:23:31,986 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:23:33,530 - GPU-3 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:23:33,530 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:23:33,679 - GPU-5 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:23:33,679 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:23:33,679 - GPU-5 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:23:33,679 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:23:34,690 - GPU-4 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:23:34,690 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:23:34,690 - GPU-4 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:23:34,690 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:23:34,800 - GPU-3 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:23:34,800 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:23:36,634 - GPU-6 - INFO - Completed batch 23, total work units processed by this worker: 368
2025-09-05 17:23:36,634 - INFO - Completed batch 23, total work units processed by this worker: 368
2025-09-05 17:23:36,634 - GPU-6 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:23:36,634 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:23:37,465 - GPU-1 - INFO - Completed batch 21, total work units processed by this worker: 336
2025-09-05 17:23:37,465 - INFO - Completed batch 21, total work units processed by this worker: 336
2025-09-05 17:23:37,465 - GPU-1 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:23:37,465 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:23:37,853 - GPU-5 - INFO - Completed batch 18, total work units processed by this worker: 288
2025-09-05 17:23:37,853 - INFO - Completed batch 18, total work units processed by this worker: 288
2025-09-05 17:23:37,953 - GPU-7 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:23:37,953 - INFO - Completed batch 11, total work units processed by this worker: 176
2025-09-05 17:23:37,954 - GPU-7 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:23:37,954 - INFO - Processing batch 12 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:23:38,519 - GPU-4 - INFO - Completed batch 18, total work units processed by this worker: 288
2025-09-05 17:23:38,519 - INFO - Completed batch 18, total work units processed by this worker: 288
2025-09-05 17:23:39,358 - GPU-5 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:23:39,358 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:23:39,624 - GPU-3 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:23:39,624 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:23:39,624 - GPU-3 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:23:39,624 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:23:40,333 - GPU-4 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:23:40,333 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:23:41,236 - GPU-6 - INFO - Completed batch 24, total work units processed by this worker: 384
2025-09-05 17:23:41,236 - INFO - Completed batch 24, total work units processed by this worker: 384
2025-09-05 17:23:42,464 - GPU-6 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:23:42,464 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:23:43,325 - GPU-2 - INFO - Completed batch 7, total work units processed by this worker: 100
2025-09-05 17:23:43,325 - INFO - Completed batch 7, total work units processed by this worker: 100
2025-09-05 17:23:43,325 - GPU-2 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:23:43,325 - INFO - Processing batch 8 (16 work units)
2025-09-05 17:23:44,907 - GPU-7 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:23:44,907 - INFO - Completed batch 12, total work units processed by this worker: 192
2025-09-05 17:23:45,631 - GPU-4 - INFO - Completed batch 19, total work units processed by this worker: 304
2025-09-05 17:23:45,631 - INFO - Completed batch 19, total work units processed by this worker: 304
2025-09-05 17:23:45,632 - GPU-4 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:23:45,632 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:23:46,321 - GPU-1 - INFO - Completed batch 22, total work units processed by this worker: 352
2025-09-05 17:23:46,321 - INFO - Completed batch 22, total work units processed by this worker: 352
2025-09-05 17:23:46,433 - GPU-3 - INFO - Completed batch 18, total work units processed by this worker: 288
2025-09-05 17:23:46,433 - INFO - Completed batch 18, total work units processed by this worker: 288
2025-09-05 17:23:46,804 - GPU-7 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:23:46,804 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:23:47,008 - GPU-5 - INFO - Completed batch 19, total work units processed by this worker: 304
2025-09-05 17:23:47,008 - INFO - Completed batch 19, total work units processed by this worker: 304
2025-09-05 17:23:47,008 - GPU-5 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:23:47,008 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:23:47,595 - GPU-1 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:23:47,595 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:23:47,828 - GPU-3 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:23:47,828 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:23:48,357 - GPU-6 - INFO - Completed batch 25, total work units processed by this worker: 400
2025-09-05 17:23:48,357 - INFO - Completed batch 25, total work units processed by this worker: 400
2025-09-05 17:23:48,357 - GPU-6 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:23:48,357 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:23:50,772 - GPU-4 - INFO - Completed batch 20, total work units processed by this worker: 320
2025-09-05 17:23:50,772 - INFO - Completed batch 20, total work units processed by this worker: 320
2025-09-05 17:23:52,054 - GPU-4 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:23:52,054 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:23:52,712 - GPU-1 - INFO - Completed batch 23, total work units processed by this worker: 368
2025-09-05 17:23:52,712 - INFO - Completed batch 23, total work units processed by this worker: 368
2025-09-05 17:23:52,713 - GPU-1 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:23:52,713 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:23:53,356 - GPU-3 - INFO - Completed batch 19, total work units processed by this worker: 304
2025-09-05 17:23:53,356 - INFO - Completed batch 19, total work units processed by this worker: 304
2025-09-05 17:23:53,356 - GPU-3 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:23:53,356 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:23:53,402 - GPU-5 - INFO - Completed batch 20, total work units processed by this worker: 320
2025-09-05 17:23:53,402 - INFO - Completed batch 20, total work units processed by this worker: 320
2025-09-05 17:23:53,657 - GPU-7 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:23:53,657 - INFO - Completed batch 13, total work units processed by this worker: 208
2025-09-05 17:23:53,657 - GPU-7 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:23:53,657 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:23:54,250 - GPU-6 - INFO - Completed batch 26, total work units processed by this worker: 416
2025-09-05 17:23:54,250 - INFO - Completed batch 26, total work units processed by this worker: 416
2025-09-05 17:23:54,793 - GPU-5 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:23:54,793 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:23:55,604 - GPU-6 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:23:55,604 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:23:57,428 - GPU-4 - INFO - Completed batch 21, total work units processed by this worker: 336
2025-09-05 17:23:57,428 - INFO - Completed batch 21, total work units processed by this worker: 336
2025-09-05 17:23:57,428 - GPU-4 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:23:57,428 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:23:59,047 - GPU-3 - INFO - Completed batch 20, total work units processed by this worker: 320
2025-09-05 17:23:59,047 - INFO - Completed batch 20, total work units processed by this worker: 320
2025-09-05 17:24:00,396 - GPU-3 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:24:00,396 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:24:00,852 - GPU-5 - INFO - Completed batch 21, total work units processed by this worker: 336
2025-09-05 17:24:00,852 - INFO - Completed batch 21, total work units processed by this worker: 336
2025-09-05 17:24:00,852 - GPU-5 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:24:00,852 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:24:00,856 - GPU-6 - INFO - Completed batch 27, total work units processed by this worker: 432
2025-09-05 17:24:00,856 - INFO - Completed batch 27, total work units processed by this worker: 432
2025-09-05 17:24:00,857 - GPU-6 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:24:00,857 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:24:00,987 - GPU-4 - INFO - Completed batch 22, total work units processed by this worker: 352
2025-09-05 17:24:00,987 - INFO - Completed batch 22, total work units processed by this worker: 352
2025-09-05 17:24:01,441 - GPU-7 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:24:01,441 - INFO - Completed batch 14, total work units processed by this worker: 224
2025-09-05 17:24:02,568 - GPU-4 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:24:02,568 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:24:02,927 - GPU-7 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:24:02,927 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:24:04,198 - GPU-3 - INFO - Completed batch 21, total work units processed by this worker: 336
2025-09-05 17:24:04,198 - INFO - Completed batch 21, total work units processed by this worker: 336
2025-09-05 17:24:04,198 - GPU-3 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:24:04,198 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:24:04,760 - GPU-5 - INFO - Completed batch 22, total work units processed by this worker: 352
2025-09-05 17:24:04,760 - INFO - Completed batch 22, total work units processed by this worker: 352
2025-09-05 17:24:05,392 - GPU-6 - INFO - Completed batch 28, total work units processed by this worker: 448
2025-09-05 17:24:05,392 - INFO - Completed batch 28, total work units processed by this worker: 448
2025-09-05 17:24:06,047 - GPU-5 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:24:06,047 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:24:06,706 - GPU-6 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:24:06,706 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:24:07,858 - GPU-7 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:24:07,858 - INFO - Completed batch 15, total work units processed by this worker: 240
2025-09-05 17:24:07,859 - GPU-7 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:24:07,859 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:24:09,372 - GPU-4 - INFO - Completed batch 23, total work units processed by this worker: 368
2025-09-05 17:24:09,372 - INFO - Completed batch 23, total work units processed by this worker: 368
2025-09-05 17:24:09,372 - GPU-4 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:24:09,372 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:24:11,862 - GPU-3 - INFO - Completed batch 22, total work units processed by this worker: 352
2025-09-05 17:24:11,862 - INFO - Completed batch 22, total work units processed by this worker: 352
2025-09-05 17:24:12,590 - GPU-6 - INFO - Completed batch 29, total work units processed by this worker: 464
2025-09-05 17:24:12,590 - INFO - Completed batch 29, total work units processed by this worker: 464
2025-09-05 17:24:12,590 - GPU-6 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:24:12,590 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:24:12,624 - GPU-5 - INFO - Completed batch 23, total work units processed by this worker: 368
2025-09-05 17:24:12,624 - INFO - Completed batch 23, total work units processed by this worker: 368
2025-09-05 17:24:12,625 - GPU-5 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:24:12,625 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:24:13,234 - GPU-3 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:24:13,234 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:24:14,137 - GPU-7 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:24:14,137 - INFO - Completed batch 16, total work units processed by this worker: 256
2025-09-05 17:24:15,085 - GPU-4 - INFO - Completed batch 24, total work units processed by this worker: 384
2025-09-05 17:24:15,085 - INFO - Completed batch 24, total work units processed by this worker: 384
2025-09-05 17:24:15,666 - GPU-7 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:24:15,666 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:24:16,436 - GPU-4 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:24:16,436 - INFO - Processing batch 25 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
2025-09-05 17:24:18,894 - GPU-3 - INFO - Completed batch 23, total work units processed by this worker: 368
2025-09-05 17:24:18,894 - INFO - Completed batch 23, total work units processed by this worker: 368
2025-09-05 17:24:18,895 - GPU-3 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:24:18,895 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:24:19,289 - GPU-6 - INFO - Completed batch 30, total work units processed by this worker: 480
2025-09-05 17:24:19,289 - INFO - Completed batch 30, total work units processed by this worker: 480
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:24:20,238 - GPU-5 - INFO - Completed batch 24, total work units processed by this worker: 384
2025-09-05 17:24:20,238 - INFO - Completed batch 24, total work units processed by this worker: 384
2025-09-05 17:24:20,587 - GPU-6 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:24:20,587 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:24:21,113 - GPU-7 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:24:21,113 - INFO - Completed batch 17, total work units processed by this worker: 272
2025-09-05 17:24:21,113 - GPU-7 - INFO - Processing batch 18 (4 work units)
2025-09-05 17:24:21,113 - INFO - Processing batch 18 (4 work units)
2025-09-05 17:24:21,543 - GPU-5 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:24:21,543 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:24:23,916 - GPU-0 - INFO - Completed batch 17, total work units processed by this worker: 260
2025-09-05 17:24:23,916 - INFO - Completed batch 17, total work units processed by this worker: 260
2025-09-05 17:24:23,916 - GPU-0 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:24:23,916 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:24:24,119 - GPU-3 - INFO - Completed batch 24, total work units processed by this worker: 384
2025-09-05 17:24:24,119 - INFO - Completed batch 24, total work units processed by this worker: 384
2025-09-05 17:24:24,383 - GPU-1 - INFO - Completed batch 24, total work units processed by this worker: 384
2025-09-05 17:24:24,383 - INFO - Completed batch 24, total work units processed by this worker: 384
2025-09-05 17:24:25,429 - GPU-3 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:24:25,429 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:24:26,065 - GPU-1 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:24:26,065 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:24:26,250 - GPU-6 - INFO - Completed batch 31, total work units processed by this worker: 496
2025-09-05 17:24:26,250 - INFO - Completed batch 31, total work units processed by this worker: 496
2025-09-05 17:24:26,250 - GPU-6 - INFO - Processing batch 32 (16 work units)
2025-09-05 17:24:26,250 - INFO - Processing batch 32 (16 work units)
2025-09-05 17:24:27,063 - GPU-5 - INFO - Completed batch 25, total work units processed by this worker: 400
2025-09-05 17:24:27,063 - INFO - Completed batch 25, total work units processed by this worker: 400
2025-09-05 17:24:27,063 - GPU-5 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:24:27,063 - INFO - Processing batch 26 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:24:30,958 - GPU-1 - INFO - Completed batch 25, total work units processed by this worker: 400
2025-09-05 17:24:30,958 - INFO - Completed batch 25, total work units processed by this worker: 400
2025-09-05 17:24:30,958 - GPU-1 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:24:30,958 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:24:31,605 - GPU-6 - INFO - Completed batch 32, total work units processed by this worker: 512
2025-09-05 17:24:31,605 - INFO - Completed batch 32, total work units processed by this worker: 512
2025-09-05 17:24:32,067 - GPU-3 - INFO - Completed batch 25, total work units processed by this worker: 400
2025-09-05 17:24:32,067 - INFO - Completed batch 25, total work units processed by this worker: 400
2025-09-05 17:24:32,068 - GPU-3 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:24:32,068 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:24:32,844 - GPU-6 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:24:32,844 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:24:34,898 - GPU-5 - INFO - Completed batch 26, total work units processed by this worker: 416
2025-09-05 17:24:34,898 - INFO - Completed batch 26, total work units processed by this worker: 416
2025-09-05 17:24:36,220 - GPU-5 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:24:36,220 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:24:36,662 - GPU-1 - INFO - Completed batch 26, total work units processed by this worker: 416
2025-09-05 17:24:36,662 - INFO - Completed batch 26, total work units processed by this worker: 416
2025-09-05 17:24:37,921 - GPU-1 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:24:37,921 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:24:39,453 - GPU-2 - INFO - Completed batch 8, total work units processed by this worker: 116
2025-09-05 17:24:39,453 - INFO - Completed batch 8, total work units processed by this worker: 116
2025-09-05 17:24:39,569 - GPU-3 - INFO - Completed batch 26, total work units processed by this worker: 416
2025-09-05 17:24:39,569 - INFO - Completed batch 26, total work units processed by this worker: 416
2025-09-05 17:24:40,182 - GPU-6 - INFO - Completed batch 33, total work units processed by this worker: 528
2025-09-05 17:24:40,182 - INFO - Completed batch 33, total work units processed by this worker: 528
2025-09-05 17:24:40,182 - GPU-6 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:24:40,182 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:24:40,911 - GPU-3 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:24:40,911 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:24:42,096 - GPU-5 - INFO - Completed batch 27, total work units processed by this worker: 432
2025-09-05 17:24:42,096 - INFO - Completed batch 27, total work units processed by this worker: 432
2025-09-05 17:24:42,096 - GPU-5 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:24:42,096 - INFO - Processing batch 28 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
2025-09-05 17:24:42,458 - GPU-2 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:24:42,458 - INFO - Processing batch 9 (16 work units)
2025-09-05 17:24:43,406 - GPU-1 - INFO - Completed batch 27, total work units processed by this worker: 432
2025-09-05 17:24:43,406 - INFO - Completed batch 27, total work units processed by this worker: 432
2025-09-05 17:24:43,407 - GPU-1 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:24:43,407 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:24:44,341 - GPU-3 - INFO - Completed batch 27, total work units processed by this worker: 432
2025-09-05 17:24:44,341 - INFO - Completed batch 27, total work units processed by this worker: 432
2025-09-05 17:24:44,341 - GPU-3 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:24:44,341 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:24:45,467 - GPU-6 - INFO - Completed batch 34, total work units processed by this worker: 544
2025-09-05 17:24:45,467 - INFO - Completed batch 34, total work units processed by this worker: 544
2025-09-05 17:24:46,769 - GPU-6 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:24:46,769 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:24:46,966 - GPU-5 - INFO - Completed batch 28, total work units processed by this worker: 448
2025-09-05 17:24:46,966 - INFO - Completed batch 28, total work units processed by this worker: 448
2025-09-05 17:24:46,984 - GPU-2 - INFO - Completed batch 9, total work units processed by this worker: 132
2025-09-05 17:24:46,984 - INFO - Completed batch 9, total work units processed by this worker: 132
2025-09-05 17:24:46,984 - GPU-2 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:24:46,984 - INFO - Processing batch 10 (16 work units)
2025-09-05 17:24:47,546 - GPU-1 - INFO - Completed batch 28, total work units processed by this worker: 448
2025-09-05 17:24:47,546 - INFO - Completed batch 28, total work units processed by this worker: 448
2025-09-05 17:24:48,168 - GPU-3 - INFO - Completed batch 28, total work units processed by this worker: 448
2025-09-05 17:24:48,168 - INFO - Completed batch 28, total work units processed by this worker: 448
2025-09-05 17:24:48,306 - GPU-5 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:24:48,306 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:24:48,838 - GPU-1 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:24:48,838 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:24:49,437 - GPU-3 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:24:49,437 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:24:50,623 - GPU-4 - INFO - Completed batch 25, total work units processed by this worker: 400
2025-09-05 17:24:50,623 - INFO - Completed batch 25, total work units processed by this worker: 400
2025-09-05 17:24:50,624 - GPU-4 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:24:50,624 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:24:53,764 - GPU-6 - INFO - Completed batch 35, total work units processed by this worker: 560
2025-09-05 17:24:53,764 - INFO - Completed batch 35, total work units processed by this worker: 560
2025-09-05 17:24:53,764 - GPU-6 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:24:53,764 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:24:54,679 - GPU-2 - INFO - Completed batch 10, total work units processed by this worker: 148
2025-09-05 17:24:54,679 - INFO - Completed batch 10, total work units processed by this worker: 148
2025-09-05 17:24:54,960 - GPU-5 - INFO - Completed batch 29, total work units processed by this worker: 464
2025-09-05 17:24:54,960 - INFO - Completed batch 29, total work units processed by this worker: 464
2025-09-05 17:24:54,960 - GPU-5 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:24:54,960 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:24:55,108 - GPU-1 - INFO - Completed batch 29, total work units processed by this worker: 464
2025-09-05 17:24:55,108 - INFO - Completed batch 29, total work units processed by this worker: 464
2025-09-05 17:24:55,108 - GPU-1 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:24:55,108 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:24:57,060 - GPU-2 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:24:57,060 - INFO - Processing batch 11 (16 work units)
2025-09-05 17:24:57,295 - GPU-4 - INFO - Completed batch 26, total work units processed by this worker: 416
2025-09-05 17:24:57,295 - INFO - Completed batch 26, total work units processed by this worker: 416
2025-09-05 17:24:57,529 - GPU-3 - INFO - Completed batch 29, total work units processed by this worker: 464
2025-09-05 17:24:57,529 - INFO - Completed batch 29, total work units processed by this worker: 464
2025-09-05 17:24:57,530 - GPU-3 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:24:57,530 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:24:59,003 - GPU-4 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:24:59,003 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:24:59,850 - GPU-6 - INFO - Completed batch 36, total work units processed by this worker: 576
2025-09-05 17:24:59,850 - INFO - Completed batch 36, total work units processed by this worker: 576
2025-09-05 17:25:00,687 - GPU-5 - INFO - Completed batch 30, total work units processed by this worker: 480
2025-09-05 17:25:00,687 - INFO - Completed batch 30, total work units processed by this worker: 480
2025-09-05 17:25:00,830 - GPU-1 - INFO - Completed batch 30, total work units processed by this worker: 480
2025-09-05 17:25:00,830 - INFO - Completed batch 30, total work units processed by this worker: 480
2025-09-05 17:25:01,216 - GPU-6 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:25:01,216 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:25:02,034 - GPU-5 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:25:02,034 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:25:02,132 - GPU-1 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:25:02,132 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:25:02,894 - GPU-2 - INFO - Completed batch 11, total work units processed by this worker: 164
2025-09-05 17:25:02,894 - INFO - Completed batch 11, total work units processed by this worker: 164
2025-09-05 17:25:02,894 - GPU-2 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:25:02,894 - INFO - Processing batch 12 (16 work units)
2025-09-05 17:25:05,598 - GPU-4 - INFO - Completed batch 27, total work units processed by this worker: 432
2025-09-05 17:25:05,598 - INFO - Completed batch 27, total work units processed by this worker: 432
2025-09-05 17:25:05,598 - GPU-4 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:25:05,598 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:25:06,287 - GPU-3 - INFO - Completed batch 30, total work units processed by this worker: 480
2025-09-05 17:25:06,287 - INFO - Completed batch 30, total work units processed by this worker: 480
2025-09-05 17:25:07,341 - GPU-6 - INFO - Completed batch 37, total work units processed by this worker: 592
2025-09-05 17:25:07,341 - INFO - Completed batch 37, total work units processed by this worker: 592
2025-09-05 17:25:07,341 - GPU-6 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:25:07,341 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:25:07,653 - GPU-3 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:25:07,653 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:25:08,791 - GPU-5 - INFO - Completed batch 31, total work units processed by this worker: 496
2025-09-05 17:25:08,791 - INFO - Completed batch 31, total work units processed by this worker: 496
2025-09-05 17:25:08,791 - GPU-5 - INFO - Processing batch 32 (16 work units)
2025-09-05 17:25:08,791 - INFO - Processing batch 32 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:25:10,562 - GPU-4 - INFO - Completed batch 28, total work units processed by this worker: 448
2025-09-05 17:25:10,562 - INFO - Completed batch 28, total work units processed by this worker: 448
2025-09-05 17:25:10,781 - GPU-1 - INFO - Completed batch 31, total work units processed by this worker: 496
2025-09-05 17:25:10,781 - INFO - Completed batch 31, total work units processed by this worker: 496
2025-09-05 17:25:10,781 - GPU-1 - INFO - Processing batch 32 (16 work units)
2025-09-05 17:25:10,781 - INFO - Processing batch 32 (16 work units)
2025-09-05 17:25:11,902 - GPU-4 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:25:11,902 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:25:13,040 - GPU-3 - INFO - Completed batch 31, total work units processed by this worker: 496
2025-09-05 17:25:13,040 - INFO - Completed batch 31, total work units processed by this worker: 496
2025-09-05 17:25:13,040 - GPU-3 - INFO - Processing batch 32 (16 work units)
2025-09-05 17:25:13,040 - INFO - Processing batch 32 (16 work units)
2025-09-05 17:25:13,161 - GPU-6 - INFO - Completed batch 38, total work units processed by this worker: 608
2025-09-05 17:25:13,161 - INFO - Completed batch 38, total work units processed by this worker: 608
2025-09-05 17:25:14,193 - GPU-0 - INFO - Completed batch 18, total work units processed by this worker: 276
2025-09-05 17:25:14,193 - INFO - Completed batch 18, total work units processed by this worker: 276
2025-09-05 17:25:14,468 - GPU-6 - INFO - Processing batch 39 (16 work units)
2025-09-05 17:25:14,468 - INFO - Processing batch 39 (16 work units)
2025-09-05 17:25:14,852 - GPU-5 - INFO - Completed batch 32, total work units processed by this worker: 512
2025-09-05 17:25:14,852 - INFO - Completed batch 32, total work units processed by this worker: 512
2025-09-05 17:25:16,397 - GPU-5 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:25:16,397 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:25:16,733 - GPU-4 - INFO - Completed batch 29, total work units processed by this worker: 464
2025-09-05 17:25:16,733 - INFO - Completed batch 29, total work units processed by this worker: 464
2025-09-05 17:25:16,733 - GPU-4 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:25:16,733 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:25:17,171 - GPU-0 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:25:17,171 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:25:17,797 - GPU-3 - INFO - Completed batch 32, total work units processed by this worker: 512
2025-09-05 17:25:17,797 - INFO - Completed batch 32, total work units processed by this worker: 512
2025-09-05 17:25:17,851 - GPU-1 - INFO - Completed batch 32, total work units processed by this worker: 512
2025-09-05 17:25:17,851 - INFO - Completed batch 32, total work units processed by this worker: 512
2025-09-05 17:25:18,637 - GPU-6 - INFO - Completed batch 39, total work units processed by this worker: 624
2025-09-05 17:25:18,637 - INFO - Completed batch 39, total work units processed by this worker: 624
2025-09-05 17:25:18,637 - GPU-6 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:25:18,637 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:25:19,079 - GPU-3 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:25:19,079 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:25:19,303 - GPU-1 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:25:19,303 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:25:23,485 - GPU-4 - INFO - Completed batch 30, total work units processed by this worker: 480
2025-09-05 17:25:23,485 - INFO - Completed batch 30, total work units processed by this worker: 480
2025-09-05 17:25:23,673 - GPU-5 - INFO - Completed batch 33, total work units processed by this worker: 528
2025-09-05 17:25:23,673 - INFO - Completed batch 33, total work units processed by this worker: 528
2025-09-05 17:25:23,673 - GPU-5 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:25:23,673 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:25:23,796 - GPU-1 - INFO - Completed batch 33, total work units processed by this worker: 528
2025-09-05 17:25:23,796 - INFO - Completed batch 33, total work units processed by this worker: 528
2025-09-05 17:25:23,797 - GPU-1 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:25:23,797 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:25:24,893 - GPU-4 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:25:24,893 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:25:24,955 - GPU-3 - INFO - Completed batch 33, total work units processed by this worker: 528
2025-09-05 17:25:24,955 - INFO - Completed batch 33, total work units processed by this worker: 528
2025-09-05 17:25:24,955 - GPU-3 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:25:24,955 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:25:25,835 - GPU-6 - INFO - Completed batch 40, total work units processed by this worker: 640
2025-09-05 17:25:25,835 - INFO - Completed batch 40, total work units processed by this worker: 640
2025-09-05 17:25:27,080 - GPU-6 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:25:27,080 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:25:29,760 - GPU-3 - INFO - Completed batch 34, total work units processed by this worker: 544
2025-09-05 17:25:29,760 - INFO - Completed batch 34, total work units processed by this worker: 544
2025-09-05 17:25:29,930 - GPU-5 - INFO - Completed batch 34, total work units processed by this worker: 544
2025-09-05 17:25:29,930 - INFO - Completed batch 34, total work units processed by this worker: 544
2025-09-05 17:25:30,068 - GPU-1 - INFO - Completed batch 34, total work units processed by this worker: 544
2025-09-05 17:25:30,068 - INFO - Completed batch 34, total work units processed by this worker: 544
2025-09-05 17:25:31,337 - GPU-3 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:25:31,337 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:25:31,372 - GPU-1 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:25:31,372 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:25:31,397 - GPU-5 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:25:31,397 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:25:32,001 - GPU-6 - INFO - Completed batch 41, total work units processed by this worker: 656
2025-09-05 17:25:32,001 - INFO - Completed batch 41, total work units processed by this worker: 656
2025-09-05 17:25:32,001 - GPU-6 - INFO - Processing batch 42 (16 work units)
2025-09-05 17:25:32,001 - INFO - Processing batch 42 (16 work units)
2025-09-05 17:25:32,497 - GPU-4 - INFO - Completed batch 31, total work units processed by this worker: 496
2025-09-05 17:25:32,497 - INFO - Completed batch 31, total work units processed by this worker: 496
2025-09-05 17:25:32,497 - GPU-4 - INFO - Processing batch 32 (4 work units)
2025-09-05 17:25:32,497 - INFO - Processing batch 32 (4 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:25:37,675 - GPU-5 - INFO - Completed batch 35, total work units processed by this worker: 560
2025-09-05 17:25:37,675 - INFO - Completed batch 35, total work units processed by this worker: 560
2025-09-05 17:25:37,675 - GPU-5 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:25:37,675 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:25:37,871 - GPU-7 - INFO - Completed batch 18, total work units processed by this worker: 276
2025-09-05 17:25:37,871 - INFO - Completed batch 18, total work units processed by this worker: 276
2025-09-05 17:25:37,960 - GPU-6 - INFO - Completed batch 42, total work units processed by this worker: 672
2025-09-05 17:25:37,960 - INFO - Completed batch 42, total work units processed by this worker: 672
2025-09-05 17:25:39,498 - GPU-6 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:25:39,498 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:25:40,179 - GPU-7 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:25:40,179 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:25:44,730 - GPU-5 - INFO - Completed batch 36, total work units processed by this worker: 576
2025-09-05 17:25:44,730 - INFO - Completed batch 36, total work units processed by this worker: 576
2025-09-05 17:25:45,630 - GPU-6 - INFO - Completed batch 43, total work units processed by this worker: 688
2025-09-05 17:25:45,630 - INFO - Completed batch 43, total work units processed by this worker: 688
2025-09-05 17:25:45,630 - GPU-6 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:25:45,630 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:25:46,028 - GPU-5 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:25:46,028 - INFO - Processing batch 37 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:25:52,428 - GPU-6 - INFO - Completed batch 44, total work units processed by this worker: 704
2025-09-05 17:25:52,428 - INFO - Completed batch 44, total work units processed by this worker: 704
2025-09-05 17:25:52,481 - GPU-5 - INFO - Completed batch 37, total work units processed by this worker: 592
2025-09-05 17:25:52,481 - INFO - Completed batch 37, total work units processed by this worker: 592
2025-09-05 17:25:52,482 - GPU-5 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:25:52,482 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:25:53,707 - GPU-6 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:25:53,707 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:25:56,256 - GPU-2 - INFO - Completed batch 12, total work units processed by this worker: 180
2025-09-05 17:25:56,256 - INFO - Completed batch 12, total work units processed by this worker: 180
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg355_1)
2025-09-05 17:25:58,148 - GPU-5 - INFO - Completed batch 38, total work units processed by this worker: 608
2025-09-05 17:25:58,148 - INFO - Completed batch 38, total work units processed by this worker: 608
2025-09-05 17:25:59,159 - GPU-6 - INFO - Completed batch 45, total work units processed by this worker: 720
2025-09-05 17:25:59,159 - INFO - Completed batch 45, total work units processed by this worker: 720
2025-09-05 17:25:59,160 - GPU-6 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:25:59,160 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:25:59,391 - GPU-2 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:25:59,391 - INFO - Processing batch 13 (16 work units)
2025-09-05 17:25:59,429 - GPU-5 - INFO - Processing batch 39 (16 work units)
2025-09-05 17:25:59,429 - INFO - Processing batch 39 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:26:04,188 - GPU-3 - INFO - Completed batch 35, total work units processed by this worker: 560
2025-09-05 17:26:04,188 - INFO - Completed batch 35, total work units processed by this worker: 560
2025-09-05 17:26:04,188 - GPU-3 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:26:04,188 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:26:04,744 - GPU-2 - INFO - Completed batch 13, total work units processed by this worker: 196
2025-09-05 17:26:04,744 - INFO - Completed batch 13, total work units processed by this worker: 196
2025-09-05 17:26:04,745 - GPU-2 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:26:04,745 - INFO - Processing batch 14 (16 work units)
2025-09-05 17:26:05,394 - GPU-1 - INFO - Completed batch 35, total work units processed by this worker: 560
2025-09-05 17:26:05,394 - INFO - Completed batch 35, total work units processed by this worker: 560
2025-09-05 17:26:05,395 - GPU-1 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:26:05,395 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:26:05,858 - GPU-5 - INFO - Completed batch 39, total work units processed by this worker: 624
2025-09-05 17:26:05,858 - INFO - Completed batch 39, total work units processed by this worker: 624
2025-09-05 17:26:05,858 - GPU-5 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:26:05,858 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:26:06,628 - GPU-6 - INFO - Completed batch 46, total work units processed by this worker: 736
2025-09-05 17:26:06,628 - INFO - Completed batch 46, total work units processed by this worker: 736
2025-09-05 17:26:07,862 - GPU-6 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:26:07,862 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:26:08,983 - GPU-0 - INFO - Completed batch 19, total work units processed by this worker: 292
2025-09-05 17:26:08,983 - INFO - Completed batch 19, total work units processed by this worker: 292
2025-09-05 17:26:08,983 - GPU-0 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:26:08,983 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:26:10,005 - GPU-1 - INFO - Completed batch 36, total work units processed by this worker: 576
2025-09-05 17:26:10,005 - INFO - Completed batch 36, total work units processed by this worker: 576
2025-09-05 17:26:10,900 - GPU-2 - INFO - Completed batch 14, total work units processed by this worker: 212
2025-09-05 17:26:10,900 - INFO - Completed batch 14, total work units processed by this worker: 212
2025-09-05 17:26:11,973 - GPU-1 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:26:11,973 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:26:12,483 - GPU-3 - INFO - Completed batch 36, total work units processed by this worker: 576
2025-09-05 17:26:12,483 - INFO - Completed batch 36, total work units processed by this worker: 576
2025-09-05 17:26:13,132 - GPU-5 - INFO - Completed batch 40, total work units processed by this worker: 640
2025-09-05 17:26:13,132 - INFO - Completed batch 40, total work units processed by this worker: 640
2025-09-05 17:26:13,237 - GPU-2 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:26:13,237 - INFO - Processing batch 15 (16 work units)
2025-09-05 17:26:13,385 - GPU-6 - INFO - Completed batch 47, total work units processed by this worker: 752
2025-09-05 17:26:13,385 - INFO - Completed batch 47, total work units processed by this worker: 752
2025-09-05 17:26:13,386 - GPU-6 - INFO - Processing batch 48 (16 work units)
2025-09-05 17:26:13,386 - INFO - Processing batch 48 (16 work units)
2025-09-05 17:26:14,516 - GPU-3 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:26:14,516 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:26:14,639 - GPU-5 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:26:14,639 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:26:18,518 - GPU-2 - INFO - Completed batch 15, total work units processed by this worker: 228
2025-09-05 17:26:18,518 - INFO - Completed batch 15, total work units processed by this worker: 228
2025-09-05 17:26:18,519 - GPU-2 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:26:18,519 - INFO - Processing batch 16 (16 work units)
2025-09-05 17:26:18,951 - GPU-1 - INFO - Completed batch 37, total work units processed by this worker: 592
2025-09-05 17:26:18,951 - INFO - Completed batch 37, total work units processed by this worker: 592
2025-09-05 17:26:18,951 - GPU-1 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:26:18,951 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:26:19,831 - GPU-3 - INFO - Completed batch 37, total work units processed by this worker: 592
2025-09-05 17:26:19,831 - INFO - Completed batch 37, total work units processed by this worker: 592
2025-09-05 17:26:19,831 - GPU-3 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:26:19,831 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:26:19,915 - GPU-6 - INFO - Completed batch 48, total work units processed by this worker: 768
2025-09-05 17:26:19,915 - INFO - Completed batch 48, total work units processed by this worker: 768
2025-09-05 17:26:21,222 - GPU-6 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:26:21,222 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:26:21,387 - GPU-5 - INFO - Completed batch 41, total work units processed by this worker: 656
2025-09-05 17:26:21,387 - INFO - Completed batch 41, total work units processed by this worker: 656
2025-09-05 17:26:21,387 - GPU-5 - INFO - Processing batch 42 (16 work units)
2025-09-05 17:26:21,387 - INFO - Processing batch 42 (16 work units)
2025-09-05 17:26:25,429 - GPU-1 - INFO - Completed batch 38, total work units processed by this worker: 608
2025-09-05 17:26:25,429 - INFO - Completed batch 38, total work units processed by this worker: 608
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:26:26,215 - GPU-3 - INFO - Completed batch 38, total work units processed by this worker: 608
2025-09-05 17:26:26,215 - INFO - Completed batch 38, total work units processed by this worker: 608
2025-09-05 17:26:26,235 - GPU-2 - INFO - Completed batch 16, total work units processed by this worker: 244
2025-09-05 17:26:26,235 - INFO - Completed batch 16, total work units processed by this worker: 244
2025-09-05 17:26:27,039 - GPU-1 - INFO - Processing batch 39 (16 work units)
2025-09-05 17:26:27,039 - INFO - Processing batch 39 (16 work units)
2025-09-05 17:26:27,831 - GPU-3 - INFO - Processing batch 39 (16 work units)
2025-09-05 17:26:27,831 - INFO - Processing batch 39 (16 work units)
2025-09-05 17:26:28,237 - GPU-5 - INFO - Completed batch 42, total work units processed by this worker: 672
2025-09-05 17:26:28,237 - INFO - Completed batch 42, total work units processed by this worker: 672
2025-09-05 17:26:28,539 - GPU-2 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:26:28,539 - INFO - Processing batch 17 (16 work units)
2025-09-05 17:26:28,568 - GPU-6 - INFO - Completed batch 49, total work units processed by this worker: 784
2025-09-05 17:26:28,568 - INFO - Completed batch 49, total work units processed by this worker: 784
2025-09-05 17:26:28,568 - GPU-6 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:26:28,568 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:26:29,510 - GPU-5 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:26:29,510 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:26:33,016 - GPU-1 - INFO - Completed batch 39, total work units processed by this worker: 624
2025-09-05 17:26:33,016 - INFO - Completed batch 39, total work units processed by this worker: 624
2025-09-05 17:26:33,016 - GPU-1 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:26:33,016 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:26:33,680 - GPU-7 - INFO - Completed batch 19, total work units processed by this worker: 292
2025-09-05 17:26:33,680 - INFO - Completed batch 19, total work units processed by this worker: 292
2025-09-05 17:26:33,681 - GPU-7 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:26:33,681 - INFO - Processing batch 20 (16 work units)
W0905 17:26:33.788000 29043 torch/_dynamo/convert_frame.py:964] [0/8] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:33.788000 29043 torch/_dynamo/convert_frame.py:964] [0/8]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:33.788000 29043 torch/_dynamo/convert_frame.py:964] [0/8]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:33.788000 29043 torch/_dynamo/convert_frame.py:964] [0/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:33.788000 29043 torch/_dynamo/convert_frame.py:964] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:33,791 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:33,791 - INFO - Falling back to sequential processing
W0905 17:26:33.864000 29043 torch/_dynamo/convert_frame.py:964] [0/9] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:33.864000 29043 torch/_dynamo/convert_frame.py:964] [0/9]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:33.864000 29043 torch/_dynamo/convert_frame.py:964] [0/9]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:33.864000 29043 torch/_dynamo/convert_frame.py:964] [0/9] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:33.864000 29043 torch/_dynamo/convert_frame.py:964] [0/9] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:33,865 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=56, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=57, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - WARNING - Skipping empty response for id=58, magnitude=1200.0
2025-09-05 17:26:33,866 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:33,866 - INFO - No valid responses to write for this batch
2025-09-05 17:26:33,876 - GPU-7 - INFO - Completed batch 20, total work units processed by this worker: 308
2025-09-05 17:26:33,876 - INFO - Completed batch 20, total work units processed by this worker: 308
2025-09-05 17:26:34,288 - GPU-6 - INFO - Completed batch 50, total work units processed by this worker: 800
2025-09-05 17:26:34,288 - INFO - Completed batch 50, total work units processed by this worker: 800
2025-09-05 17:26:35,333 - GPU-2 - INFO - Completed batch 17, total work units processed by this worker: 260
2025-09-05 17:26:35,333 - INFO - Completed batch 17, total work units processed by this worker: 260
2025-09-05 17:26:35,334 - GPU-2 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:26:35,334 - INFO - Processing batch 18 (16 work units)
2025-09-05 17:26:35,369 - GPU-3 - INFO - Completed batch 39, total work units processed by this worker: 624
2025-09-05 17:26:35,369 - INFO - Completed batch 39, total work units processed by this worker: 624
2025-09-05 17:26:35,369 - GPU-3 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:26:35,369 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:26:35,531 - GPU-6 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:26:35,531 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:26:36,514 - GPU-5 - INFO - Completed batch 43, total work units processed by this worker: 688
2025-09-05 17:26:36,514 - INFO - Completed batch 43, total work units processed by this worker: 688
2025-09-05 17:26:36,515 - GPU-5 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:26:36,515 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:26:36,755 - GPU-7 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:26:36,755 - INFO - Processing batch 21 (16 work units)
W0905 17:26:36.852000 29043 torch/_dynamo/convert_frame.py:964] [0/10] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:36.852000 29043 torch/_dynamo/convert_frame.py:964] [0/10]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:36.852000 29043 torch/_dynamo/convert_frame.py:964] [0/10]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:36.852000 29043 torch/_dynamo/convert_frame.py:964] [0/10] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:36.852000 29043 torch/_dynamo/convert_frame.py:964] [0/10] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:36,854 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:36,854 - INFO - Falling back to sequential processing
W0905 17:26:36.924000 29043 torch/_dynamo/convert_frame.py:964] [0/11] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:36.924000 29043 torch/_dynamo/convert_frame.py:964] [0/11]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:36.924000 29043 torch/_dynamo/convert_frame.py:964] [0/11]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:36.924000 29043 torch/_dynamo/convert_frame.py:964] [0/11] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:36.924000 29043 torch/_dynamo/convert_frame.py:964] [0/11] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:36,925 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=65, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=65, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=66, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:36,926 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:36,926 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:36,926 - INFO - No valid responses to write for this batch
2025-09-05 17:26:36,936 - GPU-7 - INFO - Completed batch 21, total work units processed by this worker: 324
2025-09-05 17:26:36,936 - INFO - Completed batch 21, total work units processed by this worker: 324
2025-09-05 17:26:36,937 - GPU-7 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:26:36,937 - INFO - Processing batch 22 (16 work units)
W0905 17:26:37.035000 29043 torch/_dynamo/convert_frame.py:964] [0/12] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:37.035000 29043 torch/_dynamo/convert_frame.py:964] [0/12]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:37.035000 29043 torch/_dynamo/convert_frame.py:964] [0/12]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:37.035000 29043 torch/_dynamo/convert_frame.py:964] [0/12] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:37.035000 29043 torch/_dynamo/convert_frame.py:964] [0/12] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:37,037 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:37,037 - INFO - Falling back to sequential processing
W0905 17:26:37.096000 29043 torch/_dynamo/convert_frame.py:964] [0/13] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:37.096000 29043 torch/_dynamo/convert_frame.py:964] [0/13]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:37.096000 29043 torch/_dynamo/convert_frame.py:964] [0/13]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:37.096000 29043 torch/_dynamo/convert_frame.py:964] [0/13] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:37.096000 29043 torch/_dynamo/convert_frame.py:964] [0/13] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:37,098 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=67, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=68, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:37,098 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:37,098 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:37,098 - INFO - No valid responses to write for this batch
2025-09-05 17:26:37,109 - GPU-7 - INFO - Completed batch 22, total work units processed by this worker: 340
2025-09-05 17:26:37,109 - INFO - Completed batch 22, total work units processed by this worker: 340
2025-09-05 17:26:39,238 - GPU-1 - INFO - Completed batch 40, total work units processed by this worker: 640
2025-09-05 17:26:39,238 - INFO - Completed batch 40, total work units processed by this worker: 640
2025-09-05 17:26:39,266 - GPU-7 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:26:39,266 - INFO - Processing batch 23 (16 work units)
W0905 17:26:39.367000 29043 torch/_dynamo/convert_frame.py:964] [0/14] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:39.367000 29043 torch/_dynamo/convert_frame.py:964] [0/14]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:39.367000 29043 torch/_dynamo/convert_frame.py:964] [0/14]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:39.367000 29043 torch/_dynamo/convert_frame.py:964] [0/14] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:39.367000 29043 torch/_dynamo/convert_frame.py:964] [0/14] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:39,369 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:39,369 - INFO - Falling back to sequential processing
W0905 17:26:39.428000 29043 torch/_dynamo/convert_frame.py:964] [0/15] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:39.428000 29043 torch/_dynamo/convert_frame.py:964] [0/15]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:39.428000 29043 torch/_dynamo/convert_frame.py:964] [0/15]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:39.428000 29043 torch/_dynamo/convert_frame.py:964] [0/15] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:39.428000 29043 torch/_dynamo/convert_frame.py:964] [0/15] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:39,430 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:39,430 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - WARNING - Skipping empty response for id=69, magnitude=1200.0
2025-09-05 17:26:39,430 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,430 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - WARNING - Skipping empty response for id=70, magnitude=1200.0
2025-09-05 17:26:39,431 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,431 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,431 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:39,431 - INFO - No valid responses to write for this batch
2025-09-05 17:26:39,441 - GPU-7 - INFO - Completed batch 23, total work units processed by this worker: 356
2025-09-05 17:26:39,441 - INFO - Completed batch 23, total work units processed by this worker: 356
2025-09-05 17:26:39,442 - GPU-7 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:26:39,442 - INFO - Processing batch 24 (16 work units)
W0905 17:26:39.536000 29043 torch/_dynamo/convert_frame.py:964] [0/16] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:39.536000 29043 torch/_dynamo/convert_frame.py:964] [0/16]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:39.536000 29043 torch/_dynamo/convert_frame.py:964] [0/16]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:39.536000 29043 torch/_dynamo/convert_frame.py:964] [0/16] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:39.536000 29043 torch/_dynamo/convert_frame.py:964] [0/16] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:39,538 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:39,538 - INFO - Falling back to sequential processing
W0905 17:26:39.597000 29043 torch/_dynamo/convert_frame.py:964] [0/17] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:39.597000 29043 torch/_dynamo/convert_frame.py:964] [0/17]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:39.597000 29043 torch/_dynamo/convert_frame.py:964] [0/17]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:39.597000 29043 torch/_dynamo/convert_frame.py:964] [0/17] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:39.597000 29043 torch/_dynamo/convert_frame.py:964] [0/17] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:39,599 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=71, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - WARNING - Skipping empty response for id=72, magnitude=1200.0
2025-09-05 17:26:39,599 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:39,599 - INFO - No valid responses to write for this batch
2025-09-05 17:26:39,609 - GPU-7 - INFO - Completed batch 24, total work units processed by this worker: 372
2025-09-05 17:26:39,609 - INFO - Completed batch 24, total work units processed by this worker: 372
2025-09-05 17:26:40,891 - GPU-1 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:26:40,891 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:26:41,693 - GPU-7 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:26:41,693 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:26:41,751 - GPU-5 - INFO - Completed batch 44, total work units processed by this worker: 704
2025-09-05 17:26:41,751 - INFO - Completed batch 44, total work units processed by this worker: 704
W0905 17:26:41.803000 29043 torch/_dynamo/convert_frame.py:964] [0/18] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:41.803000 29043 torch/_dynamo/convert_frame.py:964] [0/18]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:41.803000 29043 torch/_dynamo/convert_frame.py:964] [0/18]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:41.803000 29043 torch/_dynamo/convert_frame.py:964] [0/18] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:41.803000 29043 torch/_dynamo/convert_frame.py:964] [0/18] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:41,805 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:41,805 - INFO - Falling back to sequential processing
W0905 17:26:41.859000 29043 torch/_dynamo/convert_frame.py:964] [0/19] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:41.859000 29043 torch/_dynamo/convert_frame.py:964] [0/19]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:41.859000 29043 torch/_dynamo/convert_frame.py:964] [0/19]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:41.859000 29043 torch/_dynamo/convert_frame.py:964] [0/19] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:41.859000 29043 torch/_dynamo/convert_frame.py:964] [0/19] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:41,861 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:41,861 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=1200.0
2025-09-05 17:26:41,861 - WARNING - Skipping empty response for id=74, magnitude=1200.0
2025-09-05 17:26:41,861 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=1200.0
2025-09-05 17:26:41,861 - WARNING - Skipping empty response for id=74, magnitude=1200.0
2025-09-05 17:26:41,861 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=1200.0
2025-09-05 17:26:41,861 - WARNING - Skipping empty response for id=74, magnitude=1200.0
2025-09-05 17:26:41,861 - GPU-7 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - GPU-7 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - GPU-7 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - GPU-7 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - GPU-7 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - GPU-7 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,861 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,862 - GPU-7 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,862 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,862 - GPU-7 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,862 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,862 - GPU-7 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,862 - WARNING - Skipping empty response for id=75, magnitude=1200.0
2025-09-05 17:26:41,862 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:41,862 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:41,862 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:41,862 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:41,862 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:41,862 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:41,862 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:41,862 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:41,862 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:41,862 - INFO - No valid responses to write for this batch
2025-09-05 17:26:41,872 - GPU-7 - INFO - Completed batch 25, total work units processed by this worker: 388
2025-09-05 17:26:41,872 - INFO - Completed batch 25, total work units processed by this worker: 388
2025-09-05 17:26:41,873 - GPU-7 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:26:41,873 - INFO - Processing batch 26 (16 work units)
W0905 17:26:41.967000 29043 torch/_dynamo/convert_frame.py:964] [0/20] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:41.967000 29043 torch/_dynamo/convert_frame.py:964] [0/20]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:41.967000 29043 torch/_dynamo/convert_frame.py:964] [0/20]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:41.967000 29043 torch/_dynamo/convert_frame.py:964] [0/20] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:41.967000 29043 torch/_dynamo/convert_frame.py:964] [0/20] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:41,969 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:41,969 - INFO - Falling back to sequential processing
W0905 17:26:42.023000 29043 torch/_dynamo/convert_frame.py:964] [0/21] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:42.023000 29043 torch/_dynamo/convert_frame.py:964] [0/21]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:42.023000 29043 torch/_dynamo/convert_frame.py:964] [0/21]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:42.023000 29043 torch/_dynamo/convert_frame.py:964] [0/21] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:42.023000 29043 torch/_dynamo/convert_frame.py:964] [0/21] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:42,025 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:42,025 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:42,025 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=76, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=77, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=78, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=78, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - WARNING - Skipping empty response for id=78, magnitude=1200.0
2025-09-05 17:26:42,026 - WARNING - Skipping empty response for id=78, magnitude=1200.0
2025-09-05 17:26:42,026 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:42,026 - INFO - No valid responses to write for this batch
2025-09-05 17:26:42,036 - GPU-7 - INFO - Completed batch 26, total work units processed by this worker: 404
2025-09-05 17:26:42,036 - INFO - Completed batch 26, total work units processed by this worker: 404
2025-09-05 17:26:42,101 - GPU-3 - INFO - Completed batch 40, total work units processed by this worker: 640
2025-09-05 17:26:42,101 - INFO - Completed batch 40, total work units processed by this worker: 640
2025-09-05 17:26:42,918 - GPU-6 - INFO - Completed batch 51, total work units processed by this worker: 816
2025-09-05 17:26:42,918 - INFO - Completed batch 51, total work units processed by this worker: 816
2025-09-05 17:26:42,918 - GPU-6 - INFO - Processing batch 52 (16 work units)
2025-09-05 17:26:42,918 - INFO - Processing batch 52 (16 work units)
2025-09-05 17:26:43,439 - GPU-5 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:26:43,439 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:26:43,793 - GPU-3 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:26:43,793 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:26:44,254 - GPU-7 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:26:44,254 - INFO - Processing batch 27 (16 work units)
W0905 17:26:44.356000 29043 torch/_dynamo/convert_frame.py:964] [0/22] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:44.356000 29043 torch/_dynamo/convert_frame.py:964] [0/22]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:44.356000 29043 torch/_dynamo/convert_frame.py:964] [0/22]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:44.356000 29043 torch/_dynamo/convert_frame.py:964] [0/22] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:44.356000 29043 torch/_dynamo/convert_frame.py:964] [0/22] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:44,358 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:44,358 - INFO - Falling back to sequential processing
W0905 17:26:44.413000 29043 torch/_dynamo/convert_frame.py:964] [0/23] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:44.413000 29043 torch/_dynamo/convert_frame.py:964] [0/23]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:44.413000 29043 torch/_dynamo/convert_frame.py:964] [0/23]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:44.413000 29043 torch/_dynamo/convert_frame.py:964] [0/23] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:44.413000 29043 torch/_dynamo/convert_frame.py:964] [0/23] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:44,415 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:44,415 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=1200.0
2025-09-05 17:26:44,415 - WARNING - Skipping empty response for id=83, magnitude=1200.0
2025-09-05 17:26:44,415 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=1200.0
2025-09-05 17:26:44,415 - WARNING - Skipping empty response for id=83, magnitude=1200.0
2025-09-05 17:26:44,415 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=1200.0
2025-09-05 17:26:44,415 - WARNING - Skipping empty response for id=83, magnitude=1200.0
2025-09-05 17:26:44,415 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=1200.0
2025-09-05 17:26:44,415 - WARNING - Skipping empty response for id=83, magnitude=1200.0
2025-09-05 17:26:44,415 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,415 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,415 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,415 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,415 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,415 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,415 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,415 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,415 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,415 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,416 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,416 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,416 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,416 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,416 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,416 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,416 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,416 - WARNING - Skipping empty response for id=84, magnitude=1200.0
2025-09-05 17:26:44,416 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,416 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,416 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,416 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,416 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,416 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,416 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:44,416 - INFO - No valid responses to write for this batch
2025-09-05 17:26:44,426 - GPU-7 - INFO - Completed batch 27, total work units processed by this worker: 420
2025-09-05 17:26:44,426 - INFO - Completed batch 27, total work units processed by this worker: 420
2025-09-05 17:26:44,427 - GPU-7 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:26:44,427 - INFO - Processing batch 28 (16 work units)
W0905 17:26:44.525000 29043 torch/_dynamo/convert_frame.py:964] [0/24] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:44.525000 29043 torch/_dynamo/convert_frame.py:964] [0/24]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:44.525000 29043 torch/_dynamo/convert_frame.py:964] [0/24]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:44.525000 29043 torch/_dynamo/convert_frame.py:964] [0/24] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:44.525000 29043 torch/_dynamo/convert_frame.py:964] [0/24] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:44,527 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:44,527 - INFO - Falling back to sequential processing
W0905 17:26:44.582000 29043 torch/_dynamo/convert_frame.py:964] [0/25] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:44.582000 29043 torch/_dynamo/convert_frame.py:964] [0/25]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:44.582000 29043 torch/_dynamo/convert_frame.py:964] [0/25]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:44.582000 29043 torch/_dynamo/convert_frame.py:964] [0/25] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:44.582000 29043 torch/_dynamo/convert_frame.py:964] [0/25] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:44,583 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=85, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=86, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:44,584 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:44,584 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:44,584 - INFO - No valid responses to write for this batch
2025-09-05 17:26:44,595 - GPU-7 - INFO - Completed batch 28, total work units processed by this worker: 436
2025-09-05 17:26:44,595 - INFO - Completed batch 28, total work units processed by this worker: 436
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:26:46,713 - GPU-7 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:26:46,713 - INFO - Processing batch 29 (16 work units)
W0905 17:26:46.815000 29043 torch/_dynamo/convert_frame.py:964] [0/26] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:46.815000 29043 torch/_dynamo/convert_frame.py:964] [0/26]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:46.815000 29043 torch/_dynamo/convert_frame.py:964] [0/26]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:46.815000 29043 torch/_dynamo/convert_frame.py:964] [0/26] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:46.815000 29043 torch/_dynamo/convert_frame.py:964] [0/26] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:46,817 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:46,817 - INFO - Falling back to sequential processing
W0905 17:26:46.876000 29043 torch/_dynamo/convert_frame.py:964] [0/27] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:46.876000 29043 torch/_dynamo/convert_frame.py:964] [0/27]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:46.876000 29043 torch/_dynamo/convert_frame.py:964] [0/27]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:46.876000 29043 torch/_dynamo/convert_frame.py:964] [0/27] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:46.876000 29043 torch/_dynamo/convert_frame.py:964] [0/27] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:46,878 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=87, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:46,879 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:46,879 - INFO - No valid responses to write for this batch
2025-09-05 17:26:46,890 - GPU-7 - INFO - Completed batch 29, total work units processed by this worker: 452
2025-09-05 17:26:46,890 - INFO - Completed batch 29, total work units processed by this worker: 452
2025-09-05 17:26:46,890 - GPU-7 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:26:46,890 - INFO - Processing batch 30 (16 work units)
W0905 17:26:46.991000 29043 torch/_dynamo/convert_frame.py:964] [0/28] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:46.991000 29043 torch/_dynamo/convert_frame.py:964] [0/28]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:46.991000 29043 torch/_dynamo/convert_frame.py:964] [0/28]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:46.991000 29043 torch/_dynamo/convert_frame.py:964] [0/28] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:46.991000 29043 torch/_dynamo/convert_frame.py:964] [0/28] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:46,993 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:46,993 - INFO - Falling back to sequential processing
2025-09-05 17:26:47,032 - GPU-1 - INFO - Completed batch 41, total work units processed by this worker: 656
2025-09-05 17:26:47,032 - INFO - Completed batch 41, total work units processed by this worker: 656
2025-09-05 17:26:47,032 - GPU-1 - INFO - Processing batch 42 (16 work units)
2025-09-05 17:26:47,032 - INFO - Processing batch 42 (16 work units)
W0905 17:26:47.048000 29043 torch/_dynamo/convert_frame.py:964] [0/29] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:47.048000 29043 torch/_dynamo/convert_frame.py:964] [0/29]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:47.048000 29043 torch/_dynamo/convert_frame.py:964] [0/29]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:47.048000 29043 torch/_dynamo/convert_frame.py:964] [0/29] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:47.048000 29043 torch/_dynamo/convert_frame.py:964] [0/29] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:47,050 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=88, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=89, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - WARNING - Skipping empty response for id=90, magnitude=1200.0
2025-09-05 17:26:47,050 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:47,050 - INFO - No valid responses to write for this batch
2025-09-05 17:26:47,063 - GPU-7 - INFO - Completed batch 30, total work units processed by this worker: 468
2025-09-05 17:26:47,063 - INFO - Completed batch 30, total work units processed by this worker: 468
2025-09-05 17:26:48,370 - GPU-3 - INFO - Completed batch 41, total work units processed by this worker: 656
2025-09-05 17:26:48,370 - INFO - Completed batch 41, total work units processed by this worker: 656
2025-09-05 17:26:48,370 - GPU-3 - INFO - Processing batch 42 (16 work units)
2025-09-05 17:26:48,370 - INFO - Processing batch 42 (16 work units)
2025-09-05 17:26:48,788 - GPU-4 - INFO - Completed batch 32, total work units processed by this worker: 500
2025-09-05 17:26:48,788 - INFO - Completed batch 32, total work units processed by this worker: 500
2025-09-05 17:26:48,935 - GPU-6 - INFO - Completed batch 52, total work units processed by this worker: 832
2025-09-05 17:26:48,935 - INFO - Completed batch 52, total work units processed by this worker: 832
2025-09-05 17:26:49,090 - GPU-5 - INFO - Completed batch 45, total work units processed by this worker: 720
2025-09-05 17:26:49,090 - INFO - Completed batch 45, total work units processed by this worker: 720
2025-09-05 17:26:49,091 - GPU-5 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:26:49,091 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:26:49,185 - GPU-7 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:26:49,185 - INFO - Processing batch 31 (16 work units)
W0905 17:26:49.294000 29043 torch/_dynamo/convert_frame.py:964] [0/30] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:49.294000 29043 torch/_dynamo/convert_frame.py:964] [0/30]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:49.294000 29043 torch/_dynamo/convert_frame.py:964] [0/30]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:49.294000 29043 torch/_dynamo/convert_frame.py:964] [0/30] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:49.294000 29043 torch/_dynamo/convert_frame.py:964] [0/30] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:49,296 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:49,296 - INFO - Falling back to sequential processing
W0905 17:26:49.352000 29043 torch/_dynamo/convert_frame.py:964] [0/31] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:49.352000 29043 torch/_dynamo/convert_frame.py:964] [0/31]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:49.352000 29043 torch/_dynamo/convert_frame.py:964] [0/31]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:49.352000 29043 torch/_dynamo/convert_frame.py:964] [0/31] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:49.352000 29043 torch/_dynamo/convert_frame.py:964] [0/31] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:49,354 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:49,354 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,354 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,354 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,354 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=96, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,355 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:49,355 - INFO - No valid responses to write for this batch
2025-09-05 17:26:49,366 - GPU-7 - INFO - Completed batch 31, total work units processed by this worker: 484
2025-09-05 17:26:49,366 - INFO - Completed batch 31, total work units processed by this worker: 484
2025-09-05 17:26:49,366 - GPU-7 - INFO - Processing batch 32 (16 work units)
2025-09-05 17:26:49,366 - INFO - Processing batch 32 (16 work units)
W0905 17:26:49.469000 29043 torch/_dynamo/convert_frame.py:964] [0/32] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:49.469000 29043 torch/_dynamo/convert_frame.py:964] [0/32]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:49.469000 29043 torch/_dynamo/convert_frame.py:964] [0/32]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:49.469000 29043 torch/_dynamo/convert_frame.py:964] [0/32] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:49.469000 29043 torch/_dynamo/convert_frame.py:964] [0/32] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:49,471 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:49,471 - INFO - Falling back to sequential processing
W0905 17:26:49.534000 29043 torch/_dynamo/convert_frame.py:964] [0/33] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:49.534000 29043 torch/_dynamo/convert_frame.py:964] [0/33]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:49.534000 29043 torch/_dynamo/convert_frame.py:964] [0/33]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:49.534000 29043 torch/_dynamo/convert_frame.py:964] [0/33] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:49.534000 29043 torch/_dynamo/convert_frame.py:964] [0/33] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:49,536 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:49,536 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,536 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,536 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,536 - WARNING - Skipping empty response for id=97, magnitude=1200.0
2025-09-05 17:26:49,536 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,536 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,536 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,536 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,536 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,536 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=98, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=99, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=99, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=99, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=99, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1200.0
2025-09-05 17:26:49,537 - WARNING - Skipping empty response for id=99, magnitude=1200.0
2025-09-05 17:26:49,537 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:49,537 - INFO - No valid responses to write for this batch
2025-09-05 17:26:49,548 - GPU-7 - INFO - Completed batch 32, total work units processed by this worker: 500
2025-09-05 17:26:49,548 - INFO - Completed batch 32, total work units processed by this worker: 500
2025-09-05 17:26:50,241 - GPU-6 - INFO - Processing batch 53 (4 work units)
2025-09-05 17:26:50,241 - INFO - Processing batch 53 (4 work units)
2025-09-05 17:26:51,213 - GPU-4 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:26:51,213 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:26:51,724 - GPU-7 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:26:51,724 - INFO - Processing batch 33 (16 work units)
W0905 17:26:51.814000 29043 torch/_dynamo/convert_frame.py:964] [0/34] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:51.814000 29043 torch/_dynamo/convert_frame.py:964] [0/34]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:51.814000 29043 torch/_dynamo/convert_frame.py:964] [0/34]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:51.814000 29043 torch/_dynamo/convert_frame.py:964] [0/34] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:51.814000 29043 torch/_dynamo/convert_frame.py:964] [0/34] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:51,816 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:51,816 - INFO - Falling back to sequential processing
W0905 17:26:51.872000 29043 torch/_dynamo/convert_frame.py:964] [0/35] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:51.872000 29043 torch/_dynamo/convert_frame.py:964] [0/35]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:51.872000 29043 torch/_dynamo/convert_frame.py:964] [0/35]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:51.872000 29043 torch/_dynamo/convert_frame.py:964] [0/35] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:51.872000 29043 torch/_dynamo/convert_frame.py:964] [0/35] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:51,874 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:51,874 - GPU-7 - WARNING - Skipping empty response for id=1, magnitude=1600.0
2025-09-05 17:26:51,874 - WARNING - Skipping empty response for id=1, magnitude=1600.0
2025-09-05 17:26:51,874 - GPU-7 - WARNING - Skipping empty response for id=1, magnitude=1600.0
2025-09-05 17:26:51,874 - WARNING - Skipping empty response for id=1, magnitude=1600.0
2025-09-05 17:26:51,874 - GPU-7 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,874 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,874 - GPU-7 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,874 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,874 - GPU-7 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,874 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,874 - GPU-7 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,874 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - WARNING - Skipping empty response for id=2, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:51,875 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:51,875 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:51,875 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:51,875 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:51,875 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:51,875 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:51,875 - INFO - No valid responses to write for this batch
2025-09-05 17:26:51,886 - GPU-7 - INFO - Completed batch 33, total work units processed by this worker: 516
2025-09-05 17:26:51,886 - INFO - Completed batch 33, total work units processed by this worker: 516
2025-09-05 17:26:51,886 - GPU-7 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:26:51,886 - INFO - Processing batch 34 (16 work units)
W0905 17:26:51.980000 29043 torch/_dynamo/convert_frame.py:964] [0/36] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:51.980000 29043 torch/_dynamo/convert_frame.py:964] [0/36]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:51.980000 29043 torch/_dynamo/convert_frame.py:964] [0/36]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:51.980000 29043 torch/_dynamo/convert_frame.py:964] [0/36] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:51.980000 29043 torch/_dynamo/convert_frame.py:964] [0/36] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:51,982 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:51,982 - INFO - Falling back to sequential processing
W0905 17:26:52.037000 29043 torch/_dynamo/convert_frame.py:964] [0/37] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:52.037000 29043 torch/_dynamo/convert_frame.py:964] [0/37]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:52.037000 29043 torch/_dynamo/convert_frame.py:964] [0/37]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:52.037000 29043 torch/_dynamo/convert_frame.py:964] [0/37] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:52.037000 29043 torch/_dynamo/convert_frame.py:964] [0/37] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:52,038 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=3, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=4, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:52,039 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:52,039 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:52,039 - INFO - No valid responses to write for this batch
2025-09-05 17:26:52,049 - GPU-7 - INFO - Completed batch 34, total work units processed by this worker: 532
2025-09-05 17:26:52,049 - INFO - Completed batch 34, total work units processed by this worker: 532
2025-09-05 17:26:54,115 - GPU-1 - INFO - Completed batch 42, total work units processed by this worker: 672
2025-09-05 17:26:54,115 - INFO - Completed batch 42, total work units processed by this worker: 672
2025-09-05 17:26:54,142 - GPU-7 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:26:54,142 - INFO - Processing batch 35 (16 work units)
W0905 17:26:54.243000 29043 torch/_dynamo/convert_frame.py:964] [0/38] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:54.243000 29043 torch/_dynamo/convert_frame.py:964] [0/38]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:54.243000 29043 torch/_dynamo/convert_frame.py:964] [0/38]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:54.243000 29043 torch/_dynamo/convert_frame.py:964] [0/38] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:54.243000 29043 torch/_dynamo/convert_frame.py:964] [0/38] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:54,245 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:54,245 - INFO - Falling back to sequential processing
W0905 17:26:54.301000 29043 torch/_dynamo/convert_frame.py:964] [0/39] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:54.301000 29043 torch/_dynamo/convert_frame.py:964] [0/39]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:54.301000 29043 torch/_dynamo/convert_frame.py:964] [0/39]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:54.301000 29043 torch/_dynamo/convert_frame.py:964] [0/39] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:54.301000 29043 torch/_dynamo/convert_frame.py:964] [0/39] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:54,302 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=5, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=6, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,303 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,303 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:54,303 - INFO - No valid responses to write for this batch
2025-09-05 17:26:54,314 - GPU-7 - INFO - Completed batch 35, total work units processed by this worker: 548
2025-09-05 17:26:54,314 - INFO - Completed batch 35, total work units processed by this worker: 548
2025-09-05 17:26:54,314 - GPU-7 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:26:54,314 - INFO - Processing batch 36 (16 work units)
W0905 17:26:54.412000 29043 torch/_dynamo/convert_frame.py:964] [0/40] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:54.412000 29043 torch/_dynamo/convert_frame.py:964] [0/40]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:54.412000 29043 torch/_dynamo/convert_frame.py:964] [0/40]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:54.412000 29043 torch/_dynamo/convert_frame.py:964] [0/40] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:54.412000 29043 torch/_dynamo/convert_frame.py:964] [0/40] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:54,414 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:54,414 - INFO - Falling back to sequential processing
W0905 17:26:54.469000 29043 torch/_dynamo/convert_frame.py:964] [0/41] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:54.469000 29043 torch/_dynamo/convert_frame.py:964] [0/41]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:54.469000 29043 torch/_dynamo/convert_frame.py:964] [0/41]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:54.469000 29043 torch/_dynamo/convert_frame.py:964] [0/41] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:54.469000 29043 torch/_dynamo/convert_frame.py:964] [0/41] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:54,471 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=7, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - WARNING - Skipping empty response for id=8, magnitude=1600.0
2025-09-05 17:26:54,471 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:54,471 - INFO - No valid responses to write for this batch
2025-09-05 17:26:54,482 - GPU-7 - INFO - Completed batch 36, total work units processed by this worker: 564
2025-09-05 17:26:54,482 - INFO - Completed batch 36, total work units processed by this worker: 564
2025-09-05 17:26:55,019 - GPU-5 - INFO - Completed batch 46, total work units processed by this worker: 736
2025-09-05 17:26:55,019 - INFO - Completed batch 46, total work units processed by this worker: 736
2025-09-05 17:26:55,191 - GPU-3 - INFO - Completed batch 42, total work units processed by this worker: 672
2025-09-05 17:26:55,191 - INFO - Completed batch 42, total work units processed by this worker: 672
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:26:55,589 - GPU-1 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:26:55,589 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:26:56,611 - GPU-5 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:26:56,611 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:26:56,800 - GPU-3 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:26:56,800 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:26:56,805 - GPU-7 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:26:56,805 - INFO - Processing batch 37 (16 work units)
W0905 17:26:56.908000 29043 torch/_dynamo/convert_frame.py:964] [0/42] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:56.908000 29043 torch/_dynamo/convert_frame.py:964] [0/42]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:56.908000 29043 torch/_dynamo/convert_frame.py:964] [0/42]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:56.908000 29043 torch/_dynamo/convert_frame.py:964] [0/42] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:56.908000 29043 torch/_dynamo/convert_frame.py:964] [0/42] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:56,910 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:56,910 - INFO - Falling back to sequential processing
W0905 17:26:56.965000 29043 torch/_dynamo/convert_frame.py:964] [0/43] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:56.965000 29043 torch/_dynamo/convert_frame.py:964] [0/43]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:56.965000 29043 torch/_dynamo/convert_frame.py:964] [0/43]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:56.965000 29043 torch/_dynamo/convert_frame.py:964] [0/43] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:56.965000 29043 torch/_dynamo/convert_frame.py:964] [0/43] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:56,967 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=14, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,967 - WARNING - Skipping empty response for id=15, magnitude=1600.0
2025-09-05 17:26:56,968 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:56,968 - INFO - No valid responses to write for this batch
2025-09-05 17:26:56,978 - GPU-7 - INFO - Completed batch 37, total work units processed by this worker: 580
2025-09-05 17:26:56,978 - INFO - Completed batch 37, total work units processed by this worker: 580
2025-09-05 17:26:56,979 - GPU-7 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:26:56,979 - INFO - Processing batch 38 (16 work units)
W0905 17:26:57.077000 29043 torch/_dynamo/convert_frame.py:964] [0/44] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:57.077000 29043 torch/_dynamo/convert_frame.py:964] [0/44]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:57.077000 29043 torch/_dynamo/convert_frame.py:964] [0/44]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:57.077000 29043 torch/_dynamo/convert_frame.py:964] [0/44] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:57.077000 29043 torch/_dynamo/convert_frame.py:964] [0/44] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:57,078 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:57,079 - INFO - Falling back to sequential processing
W0905 17:26:57.133000 29043 torch/_dynamo/convert_frame.py:964] [0/45] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:57.133000 29043 torch/_dynamo/convert_frame.py:964] [0/45]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:57.133000 29043 torch/_dynamo/convert_frame.py:964] [0/45]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:57.133000 29043 torch/_dynamo/convert_frame.py:964] [0/45] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:57.133000 29043 torch/_dynamo/convert_frame.py:964] [0/45] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:57,135 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=16, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,135 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,136 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,136 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:57,136 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:57,136 - INFO - No valid responses to write for this batch
2025-09-05 17:26:57,146 - GPU-7 - INFO - Completed batch 38, total work units processed by this worker: 596
2025-09-05 17:26:57,146 - INFO - Completed batch 38, total work units processed by this worker: 596
2025-09-05 17:26:59,274 - GPU-7 - INFO - Processing batch 39 (16 work units)
2025-09-05 17:26:59,274 - INFO - Processing batch 39 (16 work units)
W0905 17:26:59.371000 29043 torch/_dynamo/convert_frame.py:964] [0/46] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:59.371000 29043 torch/_dynamo/convert_frame.py:964] [0/46]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:59.371000 29043 torch/_dynamo/convert_frame.py:964] [0/46]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:59.371000 29043 torch/_dynamo/convert_frame.py:964] [0/46] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:59.371000 29043 torch/_dynamo/convert_frame.py:964] [0/46] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:59,373 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:59,373 - INFO - Falling back to sequential processing
W0905 17:26:59.428000 29043 torch/_dynamo/convert_frame.py:964] [0/47] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:59.428000 29043 torch/_dynamo/convert_frame.py:964] [0/47]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:59.428000 29043 torch/_dynamo/convert_frame.py:964] [0/47]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:59.428000 29043 torch/_dynamo/convert_frame.py:964] [0/47] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:59.428000 29043 torch/_dynamo/convert_frame.py:964] [0/47] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:59,430 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:59,430 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:59,430 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=17, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=18, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,431 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,431 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:59,431 - INFO - No valid responses to write for this batch
2025-09-05 17:26:59,442 - GPU-7 - INFO - Completed batch 39, total work units processed by this worker: 612
2025-09-05 17:26:59,442 - INFO - Completed batch 39, total work units processed by this worker: 612
2025-09-05 17:26:59,442 - GPU-7 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:26:59,442 - INFO - Processing batch 40 (16 work units)
W0905 17:26:59.536000 29043 torch/_dynamo/convert_frame.py:964] [0/48] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:59.536000 29043 torch/_dynamo/convert_frame.py:964] [0/48]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:59.536000 29043 torch/_dynamo/convert_frame.py:964] [0/48]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:59.536000 29043 torch/_dynamo/convert_frame.py:964] [0/48] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:59.536000 29043 torch/_dynamo/convert_frame.py:964] [0/48] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:59,538 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:59,538 - INFO - Falling back to sequential processing
W0905 17:26:59.593000 29043 torch/_dynamo/convert_frame.py:964] [0/49] torch._dynamo hit config.recompile_limit (8)
W0905 17:26:59.593000 29043 torch/_dynamo/convert_frame.py:964] [0/49]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:26:59.593000 29043 torch/_dynamo/convert_frame.py:964] [0/49]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:26:59.593000 29043 torch/_dynamo/convert_frame.py:964] [0/49] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:26:59.593000 29043 torch/_dynamo/convert_frame.py:964] [0/49] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:26:59,595 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=19, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=20, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:26:59,595 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:26:59,595 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:26:59,595 - INFO - No valid responses to write for this batch
2025-09-05 17:26:59,606 - GPU-7 - INFO - Completed batch 40, total work units processed by this worker: 628
2025-09-05 17:26:59,606 - INFO - Completed batch 40, total work units processed by this worker: 628
2025-09-05 17:27:01,685 - GPU-7 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:27:01,685 - INFO - Processing batch 41 (16 work units)
W0905 17:27:01.784000 29043 torch/_dynamo/convert_frame.py:964] [0/50] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:01.784000 29043 torch/_dynamo/convert_frame.py:964] [0/50]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:01.784000 29043 torch/_dynamo/convert_frame.py:964] [0/50]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:01.784000 29043 torch/_dynamo/convert_frame.py:964] [0/50] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:01.784000 29043 torch/_dynamo/convert_frame.py:964] [0/50] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:01,786 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:01,786 - INFO - Falling back to sequential processing
W0905 17:27:01.841000 29043 torch/_dynamo/convert_frame.py:964] [0/51] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:01.841000 29043 torch/_dynamo/convert_frame.py:964] [0/51]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:01.841000 29043 torch/_dynamo/convert_frame.py:964] [0/51]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:01.841000 29043 torch/_dynamo/convert_frame.py:964] [0/51] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:01.841000 29043 torch/_dynamo/convert_frame.py:964] [0/51] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:01,843 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:01,843 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,843 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,843 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,843 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,843 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,843 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,843 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,843 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=21, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=22, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:01,844 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:01,844 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:01,844 - INFO - No valid responses to write for this batch
2025-09-05 17:27:01,855 - GPU-7 - INFO - Completed batch 41, total work units processed by this worker: 644
2025-09-05 17:27:01,855 - INFO - Completed batch 41, total work units processed by this worker: 644
2025-09-05 17:27:01,855 - GPU-7 - INFO - Processing batch 42 (16 work units)
2025-09-05 17:27:01,855 - INFO - Processing batch 42 (16 work units)
W0905 17:27:01.947000 29043 torch/_dynamo/convert_frame.py:964] [0/52] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:01.947000 29043 torch/_dynamo/convert_frame.py:964] [0/52]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:01.947000 29043 torch/_dynamo/convert_frame.py:964] [0/52]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:01.947000 29043 torch/_dynamo/convert_frame.py:964] [0/52] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:01.947000 29043 torch/_dynamo/convert_frame.py:964] [0/52] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:01,949 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:01,949 - INFO - Falling back to sequential processing
W0905 17:27:02.003000 29043 torch/_dynamo/convert_frame.py:964] [0/53] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:02.003000 29043 torch/_dynamo/convert_frame.py:964] [0/53]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:02.003000 29043 torch/_dynamo/convert_frame.py:964] [0/53]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:02.003000 29043 torch/_dynamo/convert_frame.py:964] [0/53] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:02.003000 29043 torch/_dynamo/convert_frame.py:964] [0/53] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:02,005 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:02,005 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,005 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,006 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,006 - WARNING - Skipping empty response for id=23, magnitude=1600.0
2025-09-05 17:27:02,006 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - WARNING - Skipping empty response for id=24, magnitude=1600.0
2025-09-05 17:27:02,006 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:02,006 - INFO - No valid responses to write for this batch
2025-09-05 17:27:02,016 - GPU-7 - INFO - Completed batch 42, total work units processed by this worker: 660
2025-09-05 17:27:02,016 - INFO - Completed batch 42, total work units processed by this worker: 660
2025-09-05 17:27:02,803 - GPU-1 - INFO - Completed batch 43, total work units processed by this worker: 688
2025-09-05 17:27:02,803 - INFO - Completed batch 43, total work units processed by this worker: 688
2025-09-05 17:27:02,803 - GPU-1 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:27:02,803 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:27:03,194 - GPU-5 - INFO - Completed batch 47, total work units processed by this worker: 752
2025-09-05 17:27:03,194 - INFO - Completed batch 47, total work units processed by this worker: 752
2025-09-05 17:27:03,195 - GPU-5 - INFO - Processing batch 48 (16 work units)
2025-09-05 17:27:03,195 - INFO - Processing batch 48 (16 work units)
2025-09-05 17:27:03,707 - GPU-0 - INFO - Completed batch 20, total work units processed by this worker: 308
2025-09-05 17:27:03,707 - INFO - Completed batch 20, total work units processed by this worker: 308
2025-09-05 17:27:04,105 - GPU-3 - INFO - Completed batch 43, total work units processed by this worker: 688
2025-09-05 17:27:04,105 - INFO - Completed batch 43, total work units processed by this worker: 688
2025-09-05 17:27:04,106 - GPU-3 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:27:04,106 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:27:04,138 - GPU-7 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:27:04,138 - INFO - Processing batch 43 (16 work units)
W0905 17:27:04.233000 29043 torch/_dynamo/convert_frame.py:964] [0/54] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:04.233000 29043 torch/_dynamo/convert_frame.py:964] [0/54]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:04.233000 29043 torch/_dynamo/convert_frame.py:964] [0/54]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:04.233000 29043 torch/_dynamo/convert_frame.py:964] [0/54] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:04.233000 29043 torch/_dynamo/convert_frame.py:964] [0/54] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:04,235 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:04,235 - INFO - Falling back to sequential processing
W0905 17:27:04.295000 29043 torch/_dynamo/convert_frame.py:964] [0/55] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:04.295000 29043 torch/_dynamo/convert_frame.py:964] [0/55]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:04.295000 29043 torch/_dynamo/convert_frame.py:964] [0/55]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:04.295000 29043 torch/_dynamo/convert_frame.py:964] [0/55] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:04.295000 29043 torch/_dynamo/convert_frame.py:964] [0/55] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:04,297 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=30, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - WARNING - Skipping empty response for id=31, magnitude=1600.0
2025-09-05 17:27:04,297 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:04,297 - INFO - No valid responses to write for this batch
2025-09-05 17:27:04,308 - GPU-7 - INFO - Completed batch 43, total work units processed by this worker: 676
2025-09-05 17:27:04,308 - INFO - Completed batch 43, total work units processed by this worker: 676
2025-09-05 17:27:04,309 - GPU-7 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:27:04,309 - INFO - Processing batch 44 (16 work units)
W0905 17:27:04.401000 29043 torch/_dynamo/convert_frame.py:964] [0/56] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:04.401000 29043 torch/_dynamo/convert_frame.py:964] [0/56]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:04.401000 29043 torch/_dynamo/convert_frame.py:964] [0/56]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:04.401000 29043 torch/_dynamo/convert_frame.py:964] [0/56] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:04.401000 29043 torch/_dynamo/convert_frame.py:964] [0/56] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:04,403 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:04,403 - INFO - Falling back to sequential processing
W0905 17:27:04.457000 29043 torch/_dynamo/convert_frame.py:964] [0/57] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:04.457000 29043 torch/_dynamo/convert_frame.py:964] [0/57]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:04.457000 29043 torch/_dynamo/convert_frame.py:964] [0/57]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:04.457000 29043 torch/_dynamo/convert_frame.py:964] [0/57] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:04.457000 29043 torch/_dynamo/convert_frame.py:964] [0/57] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:04,459 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:04,459 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,459 - WARNING - Skipping empty response for id=32, magnitude=1600.0
2025-09-05 17:27:04,460 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:04,460 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:04,460 - INFO - No valid responses to write for this batch
2025-09-05 17:27:04,470 - GPU-7 - INFO - Completed batch 44, total work units processed by this worker: 692
2025-09-05 17:27:04,470 - INFO - Completed batch 44, total work units processed by this worker: 692
2025-09-05 17:27:06,580 - GPU-7 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:27:06,580 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:27:06,665 - GPU-0 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:27:06,665 - INFO - Processing batch 21 (16 work units)
W0905 17:27:06.681000 29043 torch/_dynamo/convert_frame.py:964] [0/58] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:06.681000 29043 torch/_dynamo/convert_frame.py:964] [0/58]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:06.681000 29043 torch/_dynamo/convert_frame.py:964] [0/58]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:06.681000 29043 torch/_dynamo/convert_frame.py:964] [0/58] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:06.681000 29043 torch/_dynamo/convert_frame.py:964] [0/58] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:06,683 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:06,683 - INFO - Falling back to sequential processing
W0905 17:27:06.738000 29043 torch/_dynamo/convert_frame.py:964] [0/59] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:06.738000 29043 torch/_dynamo/convert_frame.py:964] [0/59]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:06.738000 29043 torch/_dynamo/convert_frame.py:964] [0/59]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:06.738000 29043 torch/_dynamo/convert_frame.py:964] [0/59] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:06.738000 29043 torch/_dynamo/convert_frame.py:964] [0/59] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:06,740 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=33, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=34, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=35, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=35, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=35, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=35, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=1600.0
2025-09-05 17:27:06,740 - WARNING - Skipping empty response for id=35, magnitude=1600.0
2025-09-05 17:27:06,740 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:06,740 - INFO - No valid responses to write for this batch
2025-09-05 17:27:06,751 - GPU-7 - INFO - Completed batch 45, total work units processed by this worker: 708
2025-09-05 17:27:06,751 - INFO - Completed batch 45, total work units processed by this worker: 708
2025-09-05 17:27:06,751 - GPU-7 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:27:06,751 - INFO - Processing batch 46 (16 work units)
W0905 17:27:06.846000 29043 torch/_dynamo/convert_frame.py:964] [0/60] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:06.846000 29043 torch/_dynamo/convert_frame.py:964] [0/60]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:06.846000 29043 torch/_dynamo/convert_frame.py:964] [0/60]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:06.846000 29043 torch/_dynamo/convert_frame.py:964] [0/60] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:06.846000 29043 torch/_dynamo/convert_frame.py:964] [0/60] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:06,848 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:06,848 - INFO - Falling back to sequential processing
W0905 17:27:06.903000 29043 torch/_dynamo/convert_frame.py:964] [0/61] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:06.903000 29043 torch/_dynamo/convert_frame.py:964] [0/61]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:06.903000 29043 torch/_dynamo/convert_frame.py:964] [0/61]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:06.903000 29043 torch/_dynamo/convert_frame.py:964] [0/61] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:06.903000 29043 torch/_dynamo/convert_frame.py:964] [0/61] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:06,904 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=37, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=38, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:06,905 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:06,905 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:06,905 - INFO - No valid responses to write for this batch
2025-09-05 17:27:06,916 - GPU-7 - INFO - Completed batch 46, total work units processed by this worker: 724
2025-09-05 17:27:06,916 - INFO - Completed batch 46, total work units processed by this worker: 724
2025-09-05 17:27:08,979 - GPU-7 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:27:08,979 - INFO - Processing batch 47 (16 work units)
W0905 17:27:09.080000 29043 torch/_dynamo/convert_frame.py:964] [0/62] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:09.080000 29043 torch/_dynamo/convert_frame.py:964] [0/62]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:09.080000 29043 torch/_dynamo/convert_frame.py:964] [0/62]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:09.080000 29043 torch/_dynamo/convert_frame.py:964] [0/62] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:09.080000 29043 torch/_dynamo/convert_frame.py:964] [0/62] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:09,082 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:09,082 - INFO - Falling back to sequential processing
W0905 17:27:09.137000 29043 torch/_dynamo/convert_frame.py:964] [0/63] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:09.137000 29043 torch/_dynamo/convert_frame.py:964] [0/63]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:09.137000 29043 torch/_dynamo/convert_frame.py:964] [0/63]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:09.137000 29043 torch/_dynamo/convert_frame.py:964] [0/63] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:09.137000 29043 torch/_dynamo/convert_frame.py:964] [0/63] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:09,139 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=39, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,139 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:09,139 - INFO - No valid responses to write for this batch
2025-09-05 17:27:09,150 - GPU-7 - INFO - Completed batch 47, total work units processed by this worker: 740
2025-09-05 17:27:09,150 - INFO - Completed batch 47, total work units processed by this worker: 740
2025-09-05 17:27:09,151 - GPU-7 - INFO - Processing batch 48 (16 work units)
2025-09-05 17:27:09,151 - INFO - Processing batch 48 (16 work units)
W0905 17:27:09.250000 29043 torch/_dynamo/convert_frame.py:964] [0/64] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:09.250000 29043 torch/_dynamo/convert_frame.py:964] [0/64]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:09.250000 29043 torch/_dynamo/convert_frame.py:964] [0/64]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:09.250000 29043 torch/_dynamo/convert_frame.py:964] [0/64] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:09.250000 29043 torch/_dynamo/convert_frame.py:964] [0/64] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:09,251 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:09,251 - INFO - Falling back to sequential processing
2025-09-05 17:27:09,300 - GPU-5 - INFO - Completed batch 48, total work units processed by this worker: 768
2025-09-05 17:27:09,300 - INFO - Completed batch 48, total work units processed by this worker: 768
W0905 17:27:09.306000 29043 torch/_dynamo/convert_frame.py:964] [0/65] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:09.306000 29043 torch/_dynamo/convert_frame.py:964] [0/65]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:09.306000 29043 torch/_dynamo/convert_frame.py:964] [0/65]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:09.306000 29043 torch/_dynamo/convert_frame.py:964] [0/65] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:09.306000 29043 torch/_dynamo/convert_frame.py:964] [0/65] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:09,308 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=40, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=41, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - WARNING - Skipping empty response for id=42, magnitude=1600.0
2025-09-05 17:27:09,308 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:09,308 - INFO - No valid responses to write for this batch
2025-09-05 17:27:09,319 - GPU-7 - INFO - Completed batch 48, total work units processed by this worker: 756
2025-09-05 17:27:09,319 - INFO - Completed batch 48, total work units processed by this worker: 756
2025-09-05 17:27:09,785 - GPU-1 - INFO - Completed batch 44, total work units processed by this worker: 704
2025-09-05 17:27:09,785 - INFO - Completed batch 44, total work units processed by this worker: 704
2025-09-05 17:27:10,399 - GPU-3 - INFO - Completed batch 44, total work units processed by this worker: 704
2025-09-05 17:27:10,399 - INFO - Completed batch 44, total work units processed by this worker: 704
2025-09-05 17:27:10,936 - GPU-5 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:27:10,936 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:27:11,293 - GPU-1 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:27:11,293 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:27:11,668 - GPU-7 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:27:11,668 - INFO - Processing batch 49 (16 work units)
W0905 17:27:11.764000 29043 torch/_dynamo/convert_frame.py:964] [0/66] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:11.764000 29043 torch/_dynamo/convert_frame.py:964] [0/66]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:11.764000 29043 torch/_dynamo/convert_frame.py:964] [0/66]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:11.764000 29043 torch/_dynamo/convert_frame.py:964] [0/66] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:11.764000 29043 torch/_dynamo/convert_frame.py:964] [0/66] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:11,766 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:11,766 - INFO - Falling back to sequential processing
W0905 17:27:11.820000 29043 torch/_dynamo/convert_frame.py:964] [0/67] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:11.820000 29043 torch/_dynamo/convert_frame.py:964] [0/67]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:11.820000 29043 torch/_dynamo/convert_frame.py:964] [0/67]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:11.820000 29043 torch/_dynamo/convert_frame.py:964] [0/67] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:11.820000 29043 torch/_dynamo/convert_frame.py:964] [0/67] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:11,822 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=46, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - WARNING - Skipping empty response for id=47, magnitude=1600.0
2025-09-05 17:27:11,823 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:11,823 - INFO - No valid responses to write for this batch
2025-09-05 17:27:11,834 - GPU-7 - INFO - Completed batch 49, total work units processed by this worker: 772
2025-09-05 17:27:11,834 - INFO - Completed batch 49, total work units processed by this worker: 772
2025-09-05 17:27:11,834 - GPU-7 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:27:11,834 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:27:11,867 - GPU-3 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:27:11,867 - INFO - Processing batch 45 (16 work units)
W0905 17:27:11.932000 29043 torch/_dynamo/convert_frame.py:964] [0/68] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:11.932000 29043 torch/_dynamo/convert_frame.py:964] [0/68]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:11.932000 29043 torch/_dynamo/convert_frame.py:964] [0/68]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:11.932000 29043 torch/_dynamo/convert_frame.py:964] [0/68] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:11.932000 29043 torch/_dynamo/convert_frame.py:964] [0/68] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:11,934 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:11,934 - INFO - Falling back to sequential processing
W0905 17:27:11.989000 29043 torch/_dynamo/convert_frame.py:964] [0/69] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:11.989000 29043 torch/_dynamo/convert_frame.py:964] [0/69]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:11.989000 29043 torch/_dynamo/convert_frame.py:964] [0/69]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:11.989000 29043 torch/_dynamo/convert_frame.py:964] [0/69] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:11.989000 29043 torch/_dynamo/convert_frame.py:964] [0/69] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:11,991 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=48, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - WARNING - Skipping empty response for id=49, magnitude=1600.0
2025-09-05 17:27:11,991 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:11,991 - INFO - No valid responses to write for this batch
2025-09-05 17:27:12,002 - GPU-7 - INFO - Completed batch 50, total work units processed by this worker: 788
2025-09-05 17:27:12,002 - INFO - Completed batch 50, total work units processed by this worker: 788
2025-09-05 17:27:13,520 - GPU-0 - INFO - Completed batch 21, total work units processed by this worker: 324
2025-09-05 17:27:13,520 - INFO - Completed batch 21, total work units processed by this worker: 324
2025-09-05 17:27:13,521 - GPU-0 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:27:13,521 - INFO - Processing batch 22 (16 work units)
W0905 17:27:13.621000 29036 torch/_dynamo/convert_frame.py:964] [0/8] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:13.621000 29036 torch/_dynamo/convert_frame.py:964] [0/8]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:13.621000 29036 torch/_dynamo/convert_frame.py:964] [0/8]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:13.621000 29036 torch/_dynamo/convert_frame.py:964] [0/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:13.621000 29036 torch/_dynamo/convert_frame.py:964] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:13,623 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:13,623 - INFO - Falling back to sequential processing
W0905 17:27:13.698000 29036 torch/_dynamo/convert_frame.py:964] [0/9] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:13.698000 29036 torch/_dynamo/convert_frame.py:964] [0/9]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:13.698000 29036 torch/_dynamo/convert_frame.py:964] [0/9]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:13.698000 29036 torch/_dynamo/convert_frame.py:964] [0/9] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:13.698000 29036 torch/_dynamo/convert_frame.py:964] [0/9] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:13,699 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=51, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=51, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=51, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=51, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=52, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:13,700 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:13,700 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:13,700 - INFO - No valid responses to write for this batch
2025-09-05 17:27:13,710 - GPU-0 - INFO - Completed batch 22, total work units processed by this worker: 340
2025-09-05 17:27:13,710 - INFO - Completed batch 22, total work units processed by this worker: 340
2025-09-05 17:27:14,192 - GPU-7 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:27:14,192 - INFO - Processing batch 51 (16 work units)
W0905 17:27:14.300000 29043 torch/_dynamo/convert_frame.py:964] [0/70] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:14.300000 29043 torch/_dynamo/convert_frame.py:964] [0/70]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:14.300000 29043 torch/_dynamo/convert_frame.py:964] [0/70]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:14.300000 29043 torch/_dynamo/convert_frame.py:964] [0/70] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:14.300000 29043 torch/_dynamo/convert_frame.py:964] [0/70] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:14,302 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:14,302 - INFO - Falling back to sequential processing
W0905 17:27:14.357000 29043 torch/_dynamo/convert_frame.py:964] [0/71] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:14.357000 29043 torch/_dynamo/convert_frame.py:964] [0/71]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:14.357000 29043 torch/_dynamo/convert_frame.py:964] [0/71]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:14.357000 29043 torch/_dynamo/convert_frame.py:964] [0/71] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:14.357000 29043 torch/_dynamo/convert_frame.py:964] [0/71] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:14,359 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=53, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=54, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,359 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,359 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:14,359 - INFO - No valid responses to write for this batch
2025-09-05 17:27:14,370 - GPU-7 - INFO - Completed batch 51, total work units processed by this worker: 804
2025-09-05 17:27:14,370 - INFO - Completed batch 51, total work units processed by this worker: 804
2025-09-05 17:27:14,370 - GPU-7 - INFO - Processing batch 52 (16 work units)
2025-09-05 17:27:14,370 - INFO - Processing batch 52 (16 work units)
W0905 17:27:14.475000 29043 torch/_dynamo/convert_frame.py:964] [0/72] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:14.475000 29043 torch/_dynamo/convert_frame.py:964] [0/72]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:14.475000 29043 torch/_dynamo/convert_frame.py:964] [0/72]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:14.475000 29043 torch/_dynamo/convert_frame.py:964] [0/72] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:14.475000 29043 torch/_dynamo/convert_frame.py:964] [0/72] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:14,477 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:14,477 - INFO - Falling back to sequential processing
W0905 17:27:14.532000 29043 torch/_dynamo/convert_frame.py:964] [0/73] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:14.532000 29043 torch/_dynamo/convert_frame.py:964] [0/73]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:14.532000 29043 torch/_dynamo/convert_frame.py:964] [0/73]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:14.532000 29043 torch/_dynamo/convert_frame.py:964] [0/73] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:14.532000 29043 torch/_dynamo/convert_frame.py:964] [0/73] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:14,534 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:14,534 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,534 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,534 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,534 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,534 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,534 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=55, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:14,535 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:14,535 - INFO - No valid responses to write for this batch
2025-09-05 17:27:14,547 - GPU-7 - INFO - Completed batch 52, total work units processed by this worker: 820
2025-09-05 17:27:14,547 - INFO - Completed batch 52, total work units processed by this worker: 820
2025-09-05 17:27:15,907 - GPU-0 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:27:15,907 - INFO - Processing batch 23 (16 work units)
W0905 17:27:16.029000 29036 torch/_dynamo/convert_frame.py:964] [0/10] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:16.029000 29036 torch/_dynamo/convert_frame.py:964] [0/10]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:16.029000 29036 torch/_dynamo/convert_frame.py:964] [0/10]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:16.029000 29036 torch/_dynamo/convert_frame.py:964] [0/10] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:16.029000 29036 torch/_dynamo/convert_frame.py:964] [0/10] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:16,031 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:16,031 - INFO - Falling back to sequential processing
W0905 17:27:16.088000 29036 torch/_dynamo/convert_frame.py:964] [0/11] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:16.088000 29036 torch/_dynamo/convert_frame.py:964] [0/11]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:16.088000 29036 torch/_dynamo/convert_frame.py:964] [0/11]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:16.088000 29036 torch/_dynamo/convert_frame.py:964] [0/11] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:16.088000 29036 torch/_dynamo/convert_frame.py:964] [0/11] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:16,090 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:16,090 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:16,090 - WARNING - Skipping empty response for id=56, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=57, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,091 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:16,091 - INFO - No valid responses to write for this batch
2025-09-05 17:27:16,101 - GPU-0 - INFO - Completed batch 23, total work units processed by this worker: 356
2025-09-05 17:27:16,101 - INFO - Completed batch 23, total work units processed by this worker: 356
2025-09-05 17:27:16,101 - GPU-0 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:27:16,101 - INFO - Processing batch 24 (16 work units)
W0905 17:27:16.203000 29036 torch/_dynamo/convert_frame.py:964] [0/12] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:16.203000 29036 torch/_dynamo/convert_frame.py:964] [0/12]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:16.203000 29036 torch/_dynamo/convert_frame.py:964] [0/12]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:16.203000 29036 torch/_dynamo/convert_frame.py:964] [0/12] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:16.203000 29036 torch/_dynamo/convert_frame.py:964] [0/12] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:16,205 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:16,205 - INFO - Falling back to sequential processing
W0905 17:27:16.257000 29036 torch/_dynamo/convert_frame.py:964] [0/13] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:16.257000 29036 torch/_dynamo/convert_frame.py:964] [0/13]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:16.257000 29036 torch/_dynamo/convert_frame.py:964] [0/13]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:16.257000 29036 torch/_dynamo/convert_frame.py:964] [0/13] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:16.257000 29036 torch/_dynamo/convert_frame.py:964] [0/13] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:16,259 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=58, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=59, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,259 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,259 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:16,259 - INFO - No valid responses to write for this batch
2025-09-05 17:27:16,269 - GPU-0 - INFO - Completed batch 24, total work units processed by this worker: 372
2025-09-05 17:27:16,269 - INFO - Completed batch 24, total work units processed by this worker: 372
2025-09-05 17:27:16,652 - GPU-7 - INFO - Processing batch 53 (16 work units)
2025-09-05 17:27:16,652 - INFO - Processing batch 53 (16 work units)
W0905 17:27:16.752000 29043 torch/_dynamo/convert_frame.py:964] [0/74] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:16.752000 29043 torch/_dynamo/convert_frame.py:964] [0/74]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:16.752000 29043 torch/_dynamo/convert_frame.py:964] [0/74]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:16.752000 29043 torch/_dynamo/convert_frame.py:964] [0/74] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:16.752000 29043 torch/_dynamo/convert_frame.py:964] [0/74] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:16,754 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:16,754 - INFO - Falling back to sequential processing
W0905 17:27:16.809000 29043 torch/_dynamo/convert_frame.py:964] [0/75] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:16.809000 29043 torch/_dynamo/convert_frame.py:964] [0/75]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:16.809000 29043 torch/_dynamo/convert_frame.py:964] [0/75]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:16.809000 29043 torch/_dynamo/convert_frame.py:964] [0/75] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:16.809000 29043 torch/_dynamo/convert_frame.py:964] [0/75] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:16,811 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:16,811 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,811 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,811 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,811 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,811 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,811 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=60, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=61, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,812 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,812 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:16,812 - INFO - No valid responses to write for this batch
2025-09-05 17:27:16,823 - GPU-7 - INFO - Completed batch 53, total work units processed by this worker: 836
2025-09-05 17:27:16,823 - INFO - Completed batch 53, total work units processed by this worker: 836
2025-09-05 17:27:16,823 - GPU-7 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:27:16,823 - INFO - Processing batch 54 (16 work units)
W0905 17:27:16.920000 29043 torch/_dynamo/convert_frame.py:964] [0/76] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:16.920000 29043 torch/_dynamo/convert_frame.py:964] [0/76]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:16.920000 29043 torch/_dynamo/convert_frame.py:964] [0/76]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:16.920000 29043 torch/_dynamo/convert_frame.py:964] [0/76] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:16.920000 29043 torch/_dynamo/convert_frame.py:964] [0/76] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:16,922 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:16,922 - INFO - Falling back to sequential processing
W0905 17:27:16.976000 29043 torch/_dynamo/convert_frame.py:964] [0/77] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:16.976000 29043 torch/_dynamo/convert_frame.py:964] [0/77]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:16.976000 29043 torch/_dynamo/convert_frame.py:964] [0/77]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:16.976000 29043 torch/_dynamo/convert_frame.py:964] [0/77] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:16.976000 29043 torch/_dynamo/convert_frame.py:964] [0/77] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:16,978 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:16,978 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - WARNING - Skipping empty response for id=62, magnitude=1600.0
2025-09-05 17:27:16,978 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,978 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - WARNING - Skipping empty response for id=63, magnitude=1600.0
2025-09-05 17:27:16,979 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:16,979 - INFO - No valid responses to write for this batch
2025-09-05 17:27:16,991 - GPU-7 - INFO - Completed batch 54, total work units processed by this worker: 852
2025-09-05 17:27:16,991 - INFO - Completed batch 54, total work units processed by this worker: 852
2025-09-05 17:27:18,418 - GPU-0 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:27:18,418 - INFO - Processing batch 25 (16 work units)
W0905 17:27:18.529000 29036 torch/_dynamo/convert_frame.py:964] [0/14] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:18.529000 29036 torch/_dynamo/convert_frame.py:964] [0/14]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:18.529000 29036 torch/_dynamo/convert_frame.py:964] [0/14]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:18.529000 29036 torch/_dynamo/convert_frame.py:964] [0/14] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:18.529000 29036 torch/_dynamo/convert_frame.py:964] [0/14] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:18,531 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:18,531 - INFO - Falling back to sequential processing
2025-09-05 17:27:18,543 - GPU-5 - INFO - Completed batch 49, total work units processed by this worker: 784
2025-09-05 17:27:18,543 - INFO - Completed batch 49, total work units processed by this worker: 784
2025-09-05 17:27:18,544 - GPU-5 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:27:18,544 - INFO - Processing batch 50 (16 work units)
W0905 17:27:18.584000 29036 torch/_dynamo/convert_frame.py:964] [0/15] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:18.584000 29036 torch/_dynamo/convert_frame.py:964] [0/15]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:18.584000 29036 torch/_dynamo/convert_frame.py:964] [0/15]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:18.584000 29036 torch/_dynamo/convert_frame.py:964] [0/15] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:18.584000 29036 torch/_dynamo/convert_frame.py:964] [0/15] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:18,586 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=64, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - WARNING - Skipping empty response for id=65, magnitude=1600.0
2025-09-05 17:27:18,586 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:18,586 - INFO - No valid responses to write for this batch
2025-09-05 17:27:18,597 - GPU-0 - INFO - Completed batch 25, total work units processed by this worker: 388
2025-09-05 17:27:18,597 - INFO - Completed batch 25, total work units processed by this worker: 388
2025-09-05 17:27:18,597 - GPU-0 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:27:18,597 - INFO - Processing batch 26 (16 work units)
W0905 17:27:18.696000 29036 torch/_dynamo/convert_frame.py:964] [0/16] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:18.696000 29036 torch/_dynamo/convert_frame.py:964] [0/16]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:18.696000 29036 torch/_dynamo/convert_frame.py:964] [0/16]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:18.696000 29036 torch/_dynamo/convert_frame.py:964] [0/16] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:18.696000 29036 torch/_dynamo/convert_frame.py:964] [0/16] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:18,698 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:18,698 - INFO - Falling back to sequential processing
W0905 17:27:18.764000 29036 torch/_dynamo/convert_frame.py:964] [0/17] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:18.764000 29036 torch/_dynamo/convert_frame.py:964] [0/17]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:18.764000 29036 torch/_dynamo/convert_frame.py:964] [0/17]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:18.764000 29036 torch/_dynamo/convert_frame.py:964] [0/17] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:18.764000 29036 torch/_dynamo/convert_frame.py:964] [0/17] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:18,766 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=67, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=67, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=67, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=67, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=68, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=69, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=69, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=1600.0
2025-09-05 17:27:18,766 - WARNING - Skipping empty response for id=69, magnitude=1600.0
2025-09-05 17:27:18,766 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:18,766 - INFO - No valid responses to write for this batch
2025-09-05 17:27:18,777 - GPU-0 - INFO - Completed batch 26, total work units processed by this worker: 404
2025-09-05 17:27:18,777 - INFO - Completed batch 26, total work units processed by this worker: 404
2025-09-05 17:27:19,005 - GPU-3 - INFO - Completed batch 45, total work units processed by this worker: 720
2025-09-05 17:27:19,005 - INFO - Completed batch 45, total work units processed by this worker: 720
2025-09-05 17:27:19,006 - GPU-3 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:27:19,006 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:27:19,079 - GPU-7 - INFO - Processing batch 55 (16 work units)
2025-09-05 17:27:19,079 - INFO - Processing batch 55 (16 work units)
W0905 17:27:19.177000 29043 torch/_dynamo/convert_frame.py:964] [0/78] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:19.177000 29043 torch/_dynamo/convert_frame.py:964] [0/78]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:19.177000 29043 torch/_dynamo/convert_frame.py:964] [0/78]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:19.177000 29043 torch/_dynamo/convert_frame.py:964] [0/78] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:19.177000 29043 torch/_dynamo/convert_frame.py:964] [0/78] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:19,179 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:19,179 - INFO - Falling back to sequential processing
W0905 17:27:19.234000 29043 torch/_dynamo/convert_frame.py:964] [0/79] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:19.234000 29043 torch/_dynamo/convert_frame.py:964] [0/79]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:19.234000 29043 torch/_dynamo/convert_frame.py:964] [0/79]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:19.234000 29043 torch/_dynamo/convert_frame.py:964] [0/79] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:19.234000 29043 torch/_dynamo/convert_frame.py:964] [0/79] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:19,236 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=71, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,236 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:19,236 - INFO - No valid responses to write for this batch
2025-09-05 17:27:19,247 - GPU-7 - INFO - Completed batch 55, total work units processed by this worker: 868
2025-09-05 17:27:19,247 - INFO - Completed batch 55, total work units processed by this worker: 868
2025-09-05 17:27:19,247 - GPU-7 - INFO - Processing batch 56 (16 work units)
2025-09-05 17:27:19,247 - INFO - Processing batch 56 (16 work units)
W0905 17:27:19.339000 29043 torch/_dynamo/convert_frame.py:964] [0/80] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:19.339000 29043 torch/_dynamo/convert_frame.py:964] [0/80]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:19.339000 29043 torch/_dynamo/convert_frame.py:964] [0/80]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:19.339000 29043 torch/_dynamo/convert_frame.py:964] [0/80] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:19.339000 29043 torch/_dynamo/convert_frame.py:964] [0/80] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:19,341 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:19,341 - INFO - Falling back to sequential processing
W0905 17:27:19.396000 29043 torch/_dynamo/convert_frame.py:964] [0/81] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:19.396000 29043 torch/_dynamo/convert_frame.py:964] [0/81]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:19.396000 29043 torch/_dynamo/convert_frame.py:964] [0/81]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:19.396000 29043 torch/_dynamo/convert_frame.py:964] [0/81] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:19.396000 29043 torch/_dynamo/convert_frame.py:964] [0/81] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:19,397 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=72, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=73, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - WARNING - Skipping empty response for id=74, magnitude=1600.0
2025-09-05 17:27:19,398 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:19,398 - INFO - No valid responses to write for this batch
2025-09-05 17:27:19,409 - GPU-7 - INFO - Completed batch 56, total work units processed by this worker: 884
2025-09-05 17:27:19,409 - INFO - Completed batch 56, total work units processed by this worker: 884
2025-09-05 17:27:19,960 - GPU-1 - INFO - Completed batch 45, total work units processed by this worker: 720
2025-09-05 17:27:19,960 - INFO - Completed batch 45, total work units processed by this worker: 720
2025-09-05 17:27:19,961 - GPU-1 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:27:19,961 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:27:21,089 - GPU-0 - INFO - Processing batch 27 (16 work units)
2025-09-05 17:27:21,089 - INFO - Processing batch 27 (16 work units)
W0905 17:27:21.190000 29036 torch/_dynamo/convert_frame.py:964] [0/18] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:21.190000 29036 torch/_dynamo/convert_frame.py:964] [0/18]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:21.190000 29036 torch/_dynamo/convert_frame.py:964] [0/18]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:21.190000 29036 torch/_dynamo/convert_frame.py:964] [0/18] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:21.190000 29036 torch/_dynamo/convert_frame.py:964] [0/18] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:21,192 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:21,192 - INFO - Falling back to sequential processing
W0905 17:27:21.249000 29036 torch/_dynamo/convert_frame.py:964] [0/19] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:21.249000 29036 torch/_dynamo/convert_frame.py:964] [0/19]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:21.249000 29036 torch/_dynamo/convert_frame.py:964] [0/19]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:21.249000 29036 torch/_dynamo/convert_frame.py:964] [0/19] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:21.249000 29036 torch/_dynamo/convert_frame.py:964] [0/19] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:21,251 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:21,251 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=1600.0
2025-09-05 17:27:21,251 - WARNING - Skipping empty response for id=76, magnitude=1600.0
2025-09-05 17:27:21,251 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=1600.0
2025-09-05 17:27:21,251 - WARNING - Skipping empty response for id=76, magnitude=1600.0
2025-09-05 17:27:21,251 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=1600.0
2025-09-05 17:27:21,251 - WARNING - Skipping empty response for id=76, magnitude=1600.0
2025-09-05 17:27:21,251 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=1600.0
2025-09-05 17:27:21,251 - WARNING - Skipping empty response for id=76, magnitude=1600.0
2025-09-05 17:27:21,251 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=1600.0
2025-09-05 17:27:21,251 - WARNING - Skipping empty response for id=76, magnitude=1600.0
2025-09-05 17:27:21,251 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,251 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,251 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,251 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,251 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,251 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,251 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,251 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,251 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,251 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,252 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,252 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,252 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,252 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,252 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,252 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,252 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,252 - WARNING - Skipping empty response for id=77, magnitude=1600.0
2025-09-05 17:27:21,252 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,252 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,252 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,252 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,252 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:21,252 - INFO - No valid responses to write for this batch
2025-09-05 17:27:21,262 - GPU-0 - INFO - Completed batch 27, total work units processed by this worker: 420
2025-09-05 17:27:21,262 - INFO - Completed batch 27, total work units processed by this worker: 420
2025-09-05 17:27:21,262 - GPU-0 - INFO - Processing batch 28 (16 work units)
2025-09-05 17:27:21,262 - INFO - Processing batch 28 (16 work units)
W0905 17:27:21.354000 29036 torch/_dynamo/convert_frame.py:964] [0/20] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:21.354000 29036 torch/_dynamo/convert_frame.py:964] [0/20]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:21.354000 29036 torch/_dynamo/convert_frame.py:964] [0/20]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:21.354000 29036 torch/_dynamo/convert_frame.py:964] [0/20] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:21.354000 29036 torch/_dynamo/convert_frame.py:964] [0/20] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:21,356 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:21,356 - INFO - Falling back to sequential processing
W0905 17:27:21.409000 29036 torch/_dynamo/convert_frame.py:964] [0/21] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:21.409000 29036 torch/_dynamo/convert_frame.py:964] [0/21]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:21.409000 29036 torch/_dynamo/convert_frame.py:964] [0/21]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:21.409000 29036 torch/_dynamo/convert_frame.py:964] [0/21] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:21.409000 29036 torch/_dynamo/convert_frame.py:964] [0/21] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:21,411 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=78, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,411 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,412 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,412 - WARNING - Skipping empty response for id=79, magnitude=1600.0
2025-09-05 17:27:21,412 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:21,412 - INFO - No valid responses to write for this batch
2025-09-05 17:27:21,422 - GPU-0 - INFO - Completed batch 28, total work units processed by this worker: 436
2025-09-05 17:27:21,422 - INFO - Completed batch 28, total work units processed by this worker: 436
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:27:21,510 - GPU-7 - INFO - Processing batch 57 (16 work units)
2025-09-05 17:27:21,510 - INFO - Processing batch 57 (16 work units)
W0905 17:27:21.608000 29043 torch/_dynamo/convert_frame.py:964] [0/82] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:21.608000 29043 torch/_dynamo/convert_frame.py:964] [0/82]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:21.608000 29043 torch/_dynamo/convert_frame.py:964] [0/82]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:21.608000 29043 torch/_dynamo/convert_frame.py:964] [0/82] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:21.608000 29043 torch/_dynamo/convert_frame.py:964] [0/82] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:21,610 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:21,610 - INFO - Falling back to sequential processing
W0905 17:27:21.669000 29043 torch/_dynamo/convert_frame.py:964] [0/83] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:21.669000 29043 torch/_dynamo/convert_frame.py:964] [0/83]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:21.669000 29043 torch/_dynamo/convert_frame.py:964] [0/83]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:21.669000 29043 torch/_dynamo/convert_frame.py:964] [0/83] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:21.669000 29043 torch/_dynamo/convert_frame.py:964] [0/83] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:21,671 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=80, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,671 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,672 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,672 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,672 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:21,672 - INFO - No valid responses to write for this batch
2025-09-05 17:27:21,682 - GPU-7 - INFO - Completed batch 57, total work units processed by this worker: 900
2025-09-05 17:27:21,682 - INFO - Completed batch 57, total work units processed by this worker: 900
2025-09-05 17:27:21,683 - GPU-7 - INFO - Processing batch 58 (16 work units)
2025-09-05 17:27:21,683 - INFO - Processing batch 58 (16 work units)
W0905 17:27:21.778000 29043 torch/_dynamo/convert_frame.py:964] [0/84] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:21.778000 29043 torch/_dynamo/convert_frame.py:964] [0/84]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:21.778000 29043 torch/_dynamo/convert_frame.py:964] [0/84]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:21.778000 29043 torch/_dynamo/convert_frame.py:964] [0/84] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:21.778000 29043 torch/_dynamo/convert_frame.py:964] [0/84] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:21,780 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:21,780 - INFO - Falling back to sequential processing
W0905 17:27:21.834000 29043 torch/_dynamo/convert_frame.py:964] [0/85] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:21.834000 29043 torch/_dynamo/convert_frame.py:964] [0/85]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:21.834000 29043 torch/_dynamo/convert_frame.py:964] [0/85]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:21.834000 29043 torch/_dynamo/convert_frame.py:964] [0/85] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:21.834000 29043 torch/_dynamo/convert_frame.py:964] [0/85] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:21,836 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=81, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=82, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:21,836 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:21,836 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:21,836 - INFO - No valid responses to write for this batch
2025-09-05 17:27:21,847 - GPU-7 - INFO - Completed batch 58, total work units processed by this worker: 916
2025-09-05 17:27:21,847 - INFO - Completed batch 58, total work units processed by this worker: 916
2025-09-05 17:27:23,602 - GPU-0 - INFO - Processing batch 29 (16 work units)
2025-09-05 17:27:23,602 - INFO - Processing batch 29 (16 work units)
W0905 17:27:23.704000 29036 torch/_dynamo/convert_frame.py:964] [0/22] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:23.704000 29036 torch/_dynamo/convert_frame.py:964] [0/22]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:23.704000 29036 torch/_dynamo/convert_frame.py:964] [0/22]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:23.704000 29036 torch/_dynamo/convert_frame.py:964] [0/22] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:23.704000 29036 torch/_dynamo/convert_frame.py:964] [0/22] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:23,706 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:23,706 - INFO - Falling back to sequential processing
W0905 17:27:23.759000 29036 torch/_dynamo/convert_frame.py:964] [0/23] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:23.759000 29036 torch/_dynamo/convert_frame.py:964] [0/23]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:23.759000 29036 torch/_dynamo/convert_frame.py:964] [0/23]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:23.759000 29036 torch/_dynamo/convert_frame.py:964] [0/23] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:23.759000 29036 torch/_dynamo/convert_frame.py:964] [0/23] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:23,761 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=83, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=84, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,761 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,761 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:23,761 - INFO - No valid responses to write for this batch
2025-09-05 17:27:23,771 - GPU-0 - INFO - Completed batch 29, total work units processed by this worker: 452
2025-09-05 17:27:23,771 - INFO - Completed batch 29, total work units processed by this worker: 452
2025-09-05 17:27:23,772 - GPU-0 - INFO - Processing batch 30 (16 work units)
2025-09-05 17:27:23,772 - INFO - Processing batch 30 (16 work units)
W0905 17:27:23.871000 29036 torch/_dynamo/convert_frame.py:964] [0/24] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:23.871000 29036 torch/_dynamo/convert_frame.py:964] [0/24]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:23.871000 29036 torch/_dynamo/convert_frame.py:964] [0/24]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:23.871000 29036 torch/_dynamo/convert_frame.py:964] [0/24] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:23.871000 29036 torch/_dynamo/convert_frame.py:964] [0/24] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:23,873 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:23,873 - INFO - Falling back to sequential processing
W0905 17:27:23.925000 29036 torch/_dynamo/convert_frame.py:964] [0/25] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:23.925000 29036 torch/_dynamo/convert_frame.py:964] [0/25]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:23.925000 29036 torch/_dynamo/convert_frame.py:964] [0/25]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:23.925000 29036 torch/_dynamo/convert_frame.py:964] [0/25] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:23.925000 29036 torch/_dynamo/convert_frame.py:964] [0/25] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:23,927 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=85, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=86, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:23,927 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:23,927 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:23,927 - INFO - No valid responses to write for this batch
2025-09-05 17:27:23,937 - GPU-0 - INFO - Completed batch 30, total work units processed by this worker: 468
2025-09-05 17:27:23,937 - INFO - Completed batch 30, total work units processed by this worker: 468
2025-09-05 17:27:23,952 - GPU-7 - INFO - Processing batch 59 (16 work units)
2025-09-05 17:27:23,952 - INFO - Processing batch 59 (16 work units)
2025-09-05 17:27:24,018 - GPU-3 - INFO - Completed batch 46, total work units processed by this worker: 736
2025-09-05 17:27:24,018 - INFO - Completed batch 46, total work units processed by this worker: 736
W0905 17:27:24.054000 29043 torch/_dynamo/convert_frame.py:964] [0/86] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:24.054000 29043 torch/_dynamo/convert_frame.py:964] [0/86]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:24.054000 29043 torch/_dynamo/convert_frame.py:964] [0/86]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:24.054000 29043 torch/_dynamo/convert_frame.py:964] [0/86] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:24.054000 29043 torch/_dynamo/convert_frame.py:964] [0/86] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:24,056 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:24,056 - INFO - Falling back to sequential processing
W0905 17:27:24.111000 29043 torch/_dynamo/convert_frame.py:964] [0/87] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:24.111000 29043 torch/_dynamo/convert_frame.py:964] [0/87]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:24.111000 29043 torch/_dynamo/convert_frame.py:964] [0/87]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:24.111000 29043 torch/_dynamo/convert_frame.py:964] [0/87] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:24.111000 29043 torch/_dynamo/convert_frame.py:964] [0/87] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:24,113 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:24,113 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,113 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,113 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,113 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=87, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,114 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:24,114 - INFO - No valid responses to write for this batch
2025-09-05 17:27:24,125 - GPU-7 - INFO - Completed batch 59, total work units processed by this worker: 932
2025-09-05 17:27:24,125 - INFO - Completed batch 59, total work units processed by this worker: 932
2025-09-05 17:27:24,125 - GPU-7 - INFO - Processing batch 60 (16 work units)
2025-09-05 17:27:24,125 - INFO - Processing batch 60 (16 work units)
W0905 17:27:24.222000 29043 torch/_dynamo/convert_frame.py:964] [0/88] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:24.222000 29043 torch/_dynamo/convert_frame.py:964] [0/88]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:24.222000 29043 torch/_dynamo/convert_frame.py:964] [0/88]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:24.222000 29043 torch/_dynamo/convert_frame.py:964] [0/88] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:24.222000 29043 torch/_dynamo/convert_frame.py:964] [0/88] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:24,224 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:24,224 - INFO - Falling back to sequential processing
W0905 17:27:24.279000 29043 torch/_dynamo/convert_frame.py:964] [0/89] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:24.279000 29043 torch/_dynamo/convert_frame.py:964] [0/89]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:24.279000 29043 torch/_dynamo/convert_frame.py:964] [0/89]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:24.279000 29043 torch/_dynamo/convert_frame.py:964] [0/89] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:24.279000 29043 torch/_dynamo/convert_frame.py:964] [0/89] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:24,281 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=88, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=89, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - WARNING - Skipping empty response for id=90, magnitude=1600.0
2025-09-05 17:27:24,281 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:24,281 - INFO - No valid responses to write for this batch
2025-09-05 17:27:24,292 - GPU-7 - INFO - Completed batch 60, total work units processed by this worker: 948
2025-09-05 17:27:24,292 - INFO - Completed batch 60, total work units processed by this worker: 948
2025-09-05 17:27:24,631 - GPU-5 - INFO - Completed batch 50, total work units processed by this worker: 800
2025-09-05 17:27:24,631 - INFO - Completed batch 50, total work units processed by this worker: 800
2025-09-05 17:27:25,698 - GPU-3 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:27:25,698 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:27:26,084 - GPU-0 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:27:26,084 - INFO - Processing batch 31 (16 work units)
2025-09-05 17:27:26,226 - GPU-5 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:27:26,226 - INFO - Processing batch 51 (16 work units)
W0905 17:27:26.241000 29036 torch/_dynamo/convert_frame.py:964] [0/26] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:26.241000 29036 torch/_dynamo/convert_frame.py:964] [0/26]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:26.241000 29036 torch/_dynamo/convert_frame.py:964] [0/26]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:26.241000 29036 torch/_dynamo/convert_frame.py:964] [0/26] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:26.241000 29036 torch/_dynamo/convert_frame.py:964] [0/26] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:26,243 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:26,243 - INFO - Falling back to sequential processing
W0905 17:27:26.300000 29036 torch/_dynamo/convert_frame.py:964] [0/27] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:26.300000 29036 torch/_dynamo/convert_frame.py:964] [0/27]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:26.300000 29036 torch/_dynamo/convert_frame.py:964] [0/27]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:26.300000 29036 torch/_dynamo/convert_frame.py:964] [0/27] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:26.300000 29036 torch/_dynamo/convert_frame.py:964] [0/27] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:26,302 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=92, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=92, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=92, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=92, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=92, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=92, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=92, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=92, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=92, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=92, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - GPU-0 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,302 - WARNING - Skipping empty response for id=93, magnitude=1600.0
2025-09-05 17:27:26,303 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=1600.0
2025-09-05 17:27:26,303 - WARNING - Skipping empty response for id=94, magnitude=1600.0
2025-09-05 17:27:26,303 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=1600.0
2025-09-05 17:27:26,303 - WARNING - Skipping empty response for id=94, magnitude=1600.0
2025-09-05 17:27:26,303 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:26,303 - INFO - No valid responses to write for this batch
2025-09-05 17:27:26,338 - GPU-0 - INFO - Completed batch 31, total work units processed by this worker: 484
2025-09-05 17:27:26,338 - INFO - Completed batch 31, total work units processed by this worker: 484
2025-09-05 17:27:26,339 - GPU-0 - INFO - Processing batch 32 (16 work units)
2025-09-05 17:27:26,339 - INFO - Processing batch 32 (16 work units)
W0905 17:27:26.491000 29036 torch/_dynamo/convert_frame.py:964] [0/28] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:26.491000 29036 torch/_dynamo/convert_frame.py:964] [0/28]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:26.491000 29036 torch/_dynamo/convert_frame.py:964] [0/28]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:26.491000 29036 torch/_dynamo/convert_frame.py:964] [0/28] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:26.491000 29036 torch/_dynamo/convert_frame.py:964] [0/28] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:26,492 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:26,492 - INFO - Falling back to sequential processing
W0905 17:27:26.545000 29036 torch/_dynamo/convert_frame.py:964] [0/29] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:26.545000 29036 torch/_dynamo/convert_frame.py:964] [0/29]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:26.545000 29036 torch/_dynamo/convert_frame.py:964] [0/29]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:26.545000 29036 torch/_dynamo/convert_frame.py:964] [0/29] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:26.545000 29036 torch/_dynamo/convert_frame.py:964] [0/29] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:26,546 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=96, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,547 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:26,547 - INFO - No valid responses to write for this batch
2025-09-05 17:27:26,557 - GPU-0 - INFO - Completed batch 32, total work units processed by this worker: 500
2025-09-05 17:27:26,557 - INFO - Completed batch 32, total work units processed by this worker: 500
2025-09-05 17:27:26,716 - GPU-7 - INFO - Processing batch 61 (16 work units)
2025-09-05 17:27:26,716 - INFO - Processing batch 61 (16 work units)
W0905 17:27:26.821000 29043 torch/_dynamo/convert_frame.py:964] [0/90] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:26.821000 29043 torch/_dynamo/convert_frame.py:964] [0/90]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:26.821000 29043 torch/_dynamo/convert_frame.py:964] [0/90]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:26.821000 29043 torch/_dynamo/convert_frame.py:964] [0/90] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:26.821000 29043 torch/_dynamo/convert_frame.py:964] [0/90] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:26,823 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:26,823 - INFO - Falling back to sequential processing
W0905 17:27:26.878000 29043 torch/_dynamo/convert_frame.py:964] [0/91] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:26.878000 29043 torch/_dynamo/convert_frame.py:964] [0/91]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:26.878000 29043 torch/_dynamo/convert_frame.py:964] [0/91]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:26.878000 29043 torch/_dynamo/convert_frame.py:964] [0/91] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:26.878000 29043 torch/_dynamo/convert_frame.py:964] [0/91] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:26,880 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:26,880 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,880 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=97, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=98, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:26,881 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:26,881 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:26,881 - INFO - No valid responses to write for this batch
2025-09-05 17:27:26,892 - GPU-7 - INFO - Completed batch 61, total work units processed by this worker: 964
2025-09-05 17:27:26,892 - INFO - Completed batch 61, total work units processed by this worker: 964
2025-09-05 17:27:26,892 - GPU-7 - INFO - Processing batch 62 (4 work units)
2025-09-05 17:27:26,892 - INFO - Processing batch 62 (4 work units)
W0905 17:27:26.953000 29043 torch/_dynamo/convert_frame.py:964] [0/92] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:26.953000 29043 torch/_dynamo/convert_frame.py:964] [0/92]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:26.953000 29043 torch/_dynamo/convert_frame.py:964] [0/92]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:26.953000 29043 torch/_dynamo/convert_frame.py:964] [0/92] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:26.953000 29043 torch/_dynamo/convert_frame.py:964] [0/92] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:26,955 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:26,955 - INFO - Falling back to sequential processing
W0905 17:27:27.016000 29043 torch/_dynamo/convert_frame.py:964] [0/93] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:27.016000 29043 torch/_dynamo/convert_frame.py:964] [0/93]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:27.016000 29043 torch/_dynamo/convert_frame.py:964] [0/93]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:27.016000 29043 torch/_dynamo/convert_frame.py:964] [0/93] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:27.016000 29043 torch/_dynamo/convert_frame.py:964] [0/93] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:27,018 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:27,018 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:27,018 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:27,018 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:27,018 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:27,018 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:27,018 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:27,018 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:27,018 - WARNING - Skipping empty response for id=99, magnitude=1600.0
2025-09-05 17:27:27,018 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:27,018 - INFO - No valid responses to write for this batch
2025-09-05 17:27:27,019 - GPU-7 - INFO - Completed batch 62, total work units processed by this worker: 968
2025-09-05 17:27:27,019 - INFO - Completed batch 62, total work units processed by this worker: 968
2025-09-05 17:27:27,645 - GPU-1 - INFO - Completed batch 46, total work units processed by this worker: 736
2025-09-05 17:27:27,645 - INFO - Completed batch 46, total work units processed by this worker: 736
2025-09-05 17:27:28,830 - GPU-2 - INFO - Completed batch 18, total work units processed by this worker: 276
2025-09-05 17:27:28,830 - INFO - Completed batch 18, total work units processed by this worker: 276
2025-09-05 17:27:28,960 - GPU-0 - INFO - Processing batch 33 (16 work units)
2025-09-05 17:27:28,960 - INFO - Processing batch 33 (16 work units)
W0905 17:27:29.052000 29036 torch/_dynamo/convert_frame.py:964] [0/30] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:29.052000 29036 torch/_dynamo/convert_frame.py:964] [0/30]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:29.052000 29036 torch/_dynamo/convert_frame.py:964] [0/30]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:29.052000 29036 torch/_dynamo/convert_frame.py:964] [0/30] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:29.052000 29036 torch/_dynamo/convert_frame.py:964] [0/30] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:29,054 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:29,054 - INFO - Falling back to sequential processing
W0905 17:27:29.116000 29036 torch/_dynamo/convert_frame.py:964] [0/31] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:29.116000 29036 torch/_dynamo/convert_frame.py:964] [0/31]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:29.116000 29036 torch/_dynamo/convert_frame.py:964] [0/31]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:29.116000 29036 torch/_dynamo/convert_frame.py:964] [0/31] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:29.116000 29036 torch/_dynamo/convert_frame.py:964] [0/31] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:29,118 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=0, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - WARNING - Skipping empty response for id=1, magnitude=2000.0
2025-09-05 17:27:29,118 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:29,118 - INFO - No valid responses to write for this batch
2025-09-05 17:27:29,121 - GPU-1 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:27:29,121 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:27:29,129 - GPU-0 - INFO - Completed batch 33, total work units processed by this worker: 516
2025-09-05 17:27:29,129 - INFO - Completed batch 33, total work units processed by this worker: 516
2025-09-05 17:27:29,129 - GPU-0 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:27:29,129 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:27:29,204 - GPU-7 - INFO - Processing batch 63 (16 work units)
2025-09-05 17:27:29,204 - INFO - Processing batch 63 (16 work units)
W0905 17:27:29.225000 29036 torch/_dynamo/convert_frame.py:964] [0/32] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:29.225000 29036 torch/_dynamo/convert_frame.py:964] [0/32]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:29.225000 29036 torch/_dynamo/convert_frame.py:964] [0/32]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:29.225000 29036 torch/_dynamo/convert_frame.py:964] [0/32] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:29.225000 29036 torch/_dynamo/convert_frame.py:964] [0/32] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:29,227 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:29,227 - INFO - Falling back to sequential processing
W0905 17:27:29.279000 29036 torch/_dynamo/convert_frame.py:964] [0/33] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:29.279000 29036 torch/_dynamo/convert_frame.py:964] [0/33]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:29.279000 29036 torch/_dynamo/convert_frame.py:964] [0/33]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:29.279000 29036 torch/_dynamo/convert_frame.py:964] [0/33] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:29.279000 29036 torch/_dynamo/convert_frame.py:964] [0/33] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:29,281 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=3, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=3, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=3, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=3, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=3, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=3, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=3, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=3, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=4, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,281 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,281 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:29,281 - INFO - No valid responses to write for this batch
2025-09-05 17:27:29,291 - GPU-0 - INFO - Completed batch 34, total work units processed by this worker: 532
2025-09-05 17:27:29,291 - INFO - Completed batch 34, total work units processed by this worker: 532
W0905 17:27:29.307000 29043 torch/_dynamo/convert_frame.py:964] [0/94] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:29.307000 29043 torch/_dynamo/convert_frame.py:964] [0/94]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:29.307000 29043 torch/_dynamo/convert_frame.py:964] [0/94]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:29.307000 29043 torch/_dynamo/convert_frame.py:964] [0/94] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:29.307000 29043 torch/_dynamo/convert_frame.py:964] [0/94] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:29,309 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:29,309 - INFO - Falling back to sequential processing
W0905 17:27:29.364000 29043 torch/_dynamo/convert_frame.py:964] [0/95] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:29.364000 29043 torch/_dynamo/convert_frame.py:964] [0/95]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:29.364000 29043 torch/_dynamo/convert_frame.py:964] [0/95]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:29.364000 29043 torch/_dynamo/convert_frame.py:964] [0/95] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:29.364000 29043 torch/_dynamo/convert_frame.py:964] [0/95] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:29,366 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=5, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=6, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,366 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,366 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:29,366 - INFO - No valid responses to write for this batch
2025-09-05 17:27:29,381 - GPU-7 - INFO - Completed batch 63, total work units processed by this worker: 984
2025-09-05 17:27:29,381 - INFO - Completed batch 63, total work units processed by this worker: 984
2025-09-05 17:27:29,381 - GPU-7 - INFO - Processing batch 64 (16 work units)
2025-09-05 17:27:29,381 - INFO - Processing batch 64 (16 work units)
W0905 17:27:29.480000 29043 torch/_dynamo/convert_frame.py:964] [0/96] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:29.480000 29043 torch/_dynamo/convert_frame.py:964] [0/96]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:29.480000 29043 torch/_dynamo/convert_frame.py:964] [0/96]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:29.480000 29043 torch/_dynamo/convert_frame.py:964] [0/96] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:29.480000 29043 torch/_dynamo/convert_frame.py:964] [0/96] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:29,482 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:29,482 - INFO - Falling back to sequential processing
W0905 17:27:29.536000 29043 torch/_dynamo/convert_frame.py:964] [0/97] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:29.536000 29043 torch/_dynamo/convert_frame.py:964] [0/97]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:29.536000 29043 torch/_dynamo/convert_frame.py:964] [0/97]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:29.536000 29043 torch/_dynamo/convert_frame.py:964] [0/97] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:29.536000 29043 torch/_dynamo/convert_frame.py:964] [0/97] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:29,538 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:29,538 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,538 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=7, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:29,539 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:29,539 - INFO - No valid responses to write for this batch
2025-09-05 17:27:29,550 - GPU-7 - INFO - Completed batch 64, total work units processed by this worker: 1000
2025-09-05 17:27:29,550 - INFO - Completed batch 64, total work units processed by this worker: 1000
2025-09-05 17:27:31,659 - GPU-0 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:27:31,659 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:27:31,702 - GPU-7 - INFO - Processing batch 65 (16 work units)
2025-09-05 17:27:31,702 - INFO - Processing batch 65 (16 work units)
W0905 17:27:31.757000 29036 torch/_dynamo/convert_frame.py:964] [0/34] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:31.757000 29036 torch/_dynamo/convert_frame.py:964] [0/34]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:31.757000 29036 torch/_dynamo/convert_frame.py:964] [0/34]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:31.757000 29036 torch/_dynamo/convert_frame.py:964] [0/34] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:31.757000 29036 torch/_dynamo/convert_frame.py:964] [0/34] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:31,759 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:31,759 - INFO - Falling back to sequential processing
W0905 17:27:31.800000 29043 torch/_dynamo/convert_frame.py:964] [0/98] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:31.800000 29043 torch/_dynamo/convert_frame.py:964] [0/98]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:31.800000 29043 torch/_dynamo/convert_frame.py:964] [0/98]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:31.800000 29043 torch/_dynamo/convert_frame.py:964] [0/98] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:31.800000 29043 torch/_dynamo/convert_frame.py:964] [0/98] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:31,802 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:31,802 - INFO - Falling back to sequential processing
W0905 17:27:31.812000 29036 torch/_dynamo/convert_frame.py:964] [0/35] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:31.812000 29036 torch/_dynamo/convert_frame.py:964] [0/35]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:31.812000 29036 torch/_dynamo/convert_frame.py:964] [0/35]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:31.812000 29036 torch/_dynamo/convert_frame.py:964] [0/35] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:31.812000 29036 torch/_dynamo/convert_frame.py:964] [0/35] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:31,814 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=8, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=9, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,814 - GPU-0 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,814 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,815 - GPU-0 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,815 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,815 - GPU-0 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,815 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,815 - GPU-0 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,815 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,815 - GPU-0 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,815 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,815 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:31,815 - INFO - No valid responses to write for this batch
2025-09-05 17:27:31,825 - GPU-0 - INFO - Completed batch 35, total work units processed by this worker: 548
2025-09-05 17:27:31,825 - INFO - Completed batch 35, total work units processed by this worker: 548
2025-09-05 17:27:31,825 - GPU-0 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:27:31,825 - INFO - Processing batch 36 (16 work units)
W0905 17:27:31.857000 29043 torch/_dynamo/convert_frame.py:964] [0/99] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:31.857000 29043 torch/_dynamo/convert_frame.py:964] [0/99]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:31.857000 29043 torch/_dynamo/convert_frame.py:964] [0/99]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:31.857000 29043 torch/_dynamo/convert_frame.py:964] [0/99] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:31.857000 29043 torch/_dynamo/convert_frame.py:964] [0/99] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:31,859 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:31,859 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,859 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=10, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=11, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,860 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,860 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:31,860 - INFO - No valid responses to write for this batch
2025-09-05 17:27:31,871 - GPU-7 - INFO - Completed batch 65, total work units processed by this worker: 1016
2025-09-05 17:27:31,871 - INFO - Completed batch 65, total work units processed by this worker: 1016
2025-09-05 17:27:31,871 - GPU-7 - INFO - Processing batch 66 (16 work units)
2025-09-05 17:27:31,871 - INFO - Processing batch 66 (16 work units)
W0905 17:27:31.925000 29036 torch/_dynamo/convert_frame.py:964] [0/36] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:31.925000 29036 torch/_dynamo/convert_frame.py:964] [0/36]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:31.925000 29036 torch/_dynamo/convert_frame.py:964] [0/36]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:31.925000 29036 torch/_dynamo/convert_frame.py:964] [0/36] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:31.925000 29036 torch/_dynamo/convert_frame.py:964] [0/36] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:31,927 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:31,927 - INFO - Falling back to sequential processing
2025-09-05 17:27:31,949 - GPU-3 - INFO - Completed batch 47, total work units processed by this worker: 752
2025-09-05 17:27:31,949 - INFO - Completed batch 47, total work units processed by this worker: 752
2025-09-05 17:27:31,949 - GPU-3 - INFO - Processing batch 48 (16 work units)
2025-09-05 17:27:31,949 - INFO - Processing batch 48 (16 work units)
W0905 17:27:31.971000 29043 torch/_dynamo/convert_frame.py:964] [0/100] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:31.971000 29043 torch/_dynamo/convert_frame.py:964] [0/100]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:31.971000 29043 torch/_dynamo/convert_frame.py:964] [0/100]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:31.971000 29043 torch/_dynamo/convert_frame.py:964] [0/100] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:31.971000 29043 torch/_dynamo/convert_frame.py:964] [0/100] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:31,972 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:31,972 - INFO - Falling back to sequential processing
W0905 17:27:31.978000 29036 torch/_dynamo/convert_frame.py:964] [0/37] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:31.978000 29036 torch/_dynamo/convert_frame.py:964] [0/37]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:31.978000 29036 torch/_dynamo/convert_frame.py:964] [0/37]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:31.978000 29036 torch/_dynamo/convert_frame.py:964] [0/37] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:31.978000 29036 torch/_dynamo/convert_frame.py:964] [0/37] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:31,980 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:31,980 - GPU-0 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,980 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,980 - GPU-0 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,980 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,980 - GPU-0 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,980 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,980 - GPU-0 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,980 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=12, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=13, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:31,981 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:31,981 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:31,981 - INFO - No valid responses to write for this batch
2025-09-05 17:27:31,991 - GPU-0 - INFO - Completed batch 36, total work units processed by this worker: 564
2025-09-05 17:27:31,991 - INFO - Completed batch 36, total work units processed by this worker: 564
W0905 17:27:32.027000 29043 torch/_dynamo/convert_frame.py:964] [0/101] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:32.027000 29043 torch/_dynamo/convert_frame.py:964] [0/101]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:32.027000 29043 torch/_dynamo/convert_frame.py:964] [0/101]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:32.027000 29043 torch/_dynamo/convert_frame.py:964] [0/101] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:32.027000 29043 torch/_dynamo/convert_frame.py:964] [0/101] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:32,029 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=14, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,029 - WARNING - Skipping empty response for id=15, magnitude=2000.0
2025-09-05 17:27:32,030 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:32,030 - INFO - No valid responses to write for this batch
2025-09-05 17:27:32,041 - GPU-7 - INFO - Completed batch 66, total work units processed by this worker: 1032
2025-09-05 17:27:32,041 - INFO - Completed batch 66, total work units processed by this worker: 1032
2025-09-05 17:27:32,138 - GPU-2 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:27:32,138 - INFO - Processing batch 19 (16 work units)
2025-09-05 17:27:33,596 - GPU-5 - INFO - Completed batch 51, total work units processed by this worker: 816
2025-09-05 17:27:33,596 - INFO - Completed batch 51, total work units processed by this worker: 816
2025-09-05 17:27:33,596 - GPU-5 - INFO - Processing batch 52 (16 work units)
2025-09-05 17:27:33,596 - INFO - Processing batch 52 (16 work units)
2025-09-05 17:27:34,204 - GPU-7 - INFO - Processing batch 67 (16 work units)
2025-09-05 17:27:34,204 - INFO - Processing batch 67 (16 work units)
2025-09-05 17:27:34,255 - GPU-0 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:27:34,255 - INFO - Processing batch 37 (16 work units)
W0905 17:27:34.303000 29043 torch/_dynamo/convert_frame.py:964] [0/102] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:34.303000 29043 torch/_dynamo/convert_frame.py:964] [0/102]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:34.303000 29043 torch/_dynamo/convert_frame.py:964] [0/102]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:34.303000 29043 torch/_dynamo/convert_frame.py:964] [0/102] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:34.303000 29043 torch/_dynamo/convert_frame.py:964] [0/102] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:34,305 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:34,305 - INFO - Falling back to sequential processing
W0905 17:27:34.350000 29036 torch/_dynamo/convert_frame.py:964] [0/38] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:34.350000 29036 torch/_dynamo/convert_frame.py:964] [0/38]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:34.350000 29036 torch/_dynamo/convert_frame.py:964] [0/38]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:34.350000 29036 torch/_dynamo/convert_frame.py:964] [0/38] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:34.350000 29036 torch/_dynamo/convert_frame.py:964] [0/38] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:34,352 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:34,352 - INFO - Falling back to sequential processing
W0905 17:27:34.360000 29043 torch/_dynamo/convert_frame.py:964] [0/103] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:34.360000 29043 torch/_dynamo/convert_frame.py:964] [0/103]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:34.360000 29043 torch/_dynamo/convert_frame.py:964] [0/103]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:34.360000 29043 torch/_dynamo/convert_frame.py:964] [0/103] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:34.360000 29043 torch/_dynamo/convert_frame.py:964] [0/103] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:34,362 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=21, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=22, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,362 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,362 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:34,362 - INFO - No valid responses to write for this batch
2025-09-05 17:27:34,374 - GPU-7 - INFO - Completed batch 67, total work units processed by this worker: 1048
2025-09-05 17:27:34,374 - INFO - Completed batch 67, total work units processed by this worker: 1048
2025-09-05 17:27:34,374 - GPU-7 - INFO - Processing batch 68 (16 work units)
2025-09-05 17:27:34,374 - INFO - Processing batch 68 (16 work units)
W0905 17:27:34.405000 29036 torch/_dynamo/convert_frame.py:964] [0/39] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:34.405000 29036 torch/_dynamo/convert_frame.py:964] [0/39]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:34.405000 29036 torch/_dynamo/convert_frame.py:964] [0/39]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:34.405000 29036 torch/_dynamo/convert_frame.py:964] [0/39] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:34.405000 29036 torch/_dynamo/convert_frame.py:964] [0/39] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:34,407 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=23, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,407 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:34,407 - INFO - No valid responses to write for this batch
2025-09-05 17:27:34,417 - GPU-0 - INFO - Completed batch 37, total work units processed by this worker: 580
2025-09-05 17:27:34,417 - INFO - Completed batch 37, total work units processed by this worker: 580
2025-09-05 17:27:34,418 - GPU-0 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:27:34,418 - INFO - Processing batch 38 (16 work units)
W0905 17:27:34.473000 29043 torch/_dynamo/convert_frame.py:964] [0/104] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:34.473000 29043 torch/_dynamo/convert_frame.py:964] [0/104]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:34.473000 29043 torch/_dynamo/convert_frame.py:964] [0/104]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:34.473000 29043 torch/_dynamo/convert_frame.py:964] [0/104] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:34.473000 29043 torch/_dynamo/convert_frame.py:964] [0/104] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:34,474 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:34,474 - INFO - Falling back to sequential processing
W0905 17:27:34.517000 29036 torch/_dynamo/convert_frame.py:964] [0/40] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:34.517000 29036 torch/_dynamo/convert_frame.py:964] [0/40]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:34.517000 29036 torch/_dynamo/convert_frame.py:964] [0/40]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:34.517000 29036 torch/_dynamo/convert_frame.py:964] [0/40] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:34.517000 29036 torch/_dynamo/convert_frame.py:964] [0/40] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:34,519 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:34,519 - INFO - Falling back to sequential processing
W0905 17:27:34.529000 29043 torch/_dynamo/convert_frame.py:964] [0/105] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:34.529000 29043 torch/_dynamo/convert_frame.py:964] [0/105]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:34.529000 29043 torch/_dynamo/convert_frame.py:964] [0/105]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:34.529000 29043 torch/_dynamo/convert_frame.py:964] [0/105] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:34.529000 29043 torch/_dynamo/convert_frame.py:964] [0/105] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:34,531 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=24, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=25, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,531 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:34,531 - INFO - No valid responses to write for this batch
2025-09-05 17:27:34,542 - GPU-7 - INFO - Completed batch 68, total work units processed by this worker: 1064
2025-09-05 17:27:34,542 - INFO - Completed batch 68, total work units processed by this worker: 1064
W0905 17:27:34.571000 29036 torch/_dynamo/convert_frame.py:964] [0/41] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:34.571000 29036 torch/_dynamo/convert_frame.py:964] [0/41]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:34.571000 29036 torch/_dynamo/convert_frame.py:964] [0/41]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:34.571000 29036 torch/_dynamo/convert_frame.py:964] [0/41] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:34.571000 29036 torch/_dynamo/convert_frame.py:964] [0/41] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:34,573 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=26, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=27, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=28, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=28, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=28, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=28, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=28, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=28, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - WARNING - Skipping empty response for id=28, magnitude=2000.0
2025-09-05 17:27:34,573 - WARNING - Skipping empty response for id=28, magnitude=2000.0
2025-09-05 17:27:34,573 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:34,573 - INFO - No valid responses to write for this batch
2025-09-05 17:27:34,583 - GPU-0 - INFO - Completed batch 38, total work units processed by this worker: 596
2025-09-05 17:27:34,583 - INFO - Completed batch 38, total work units processed by this worker: 596
2025-09-05 17:27:34,993 - GPU-1 - INFO - Completed batch 47, total work units processed by this worker: 752
2025-09-05 17:27:34,993 - INFO - Completed batch 47, total work units processed by this worker: 752
2025-09-05 17:27:34,994 - GPU-1 - INFO - Processing batch 48 (16 work units)
2025-09-05 17:27:34,994 - INFO - Processing batch 48 (16 work units)
2025-09-05 17:27:36,680 - GPU-7 - INFO - Processing batch 69 (16 work units)
2025-09-05 17:27:36,680 - INFO - Processing batch 69 (16 work units)
2025-09-05 17:27:36,708 - GPU-0 - INFO - Processing batch 39 (16 work units)
2025-09-05 17:27:36,708 - INFO - Processing batch 39 (16 work units)
W0905 17:27:36.776000 29043 torch/_dynamo/convert_frame.py:964] [0/106] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:36.776000 29043 torch/_dynamo/convert_frame.py:964] [0/106]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:36.776000 29043 torch/_dynamo/convert_frame.py:964] [0/106]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:36.776000 29043 torch/_dynamo/convert_frame.py:964] [0/106] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:36.776000 29043 torch/_dynamo/convert_frame.py:964] [0/106] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:36,778 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:36,778 - INFO - Falling back to sequential processing
W0905 17:27:36.804000 29036 torch/_dynamo/convert_frame.py:964] [0/42] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:36.804000 29036 torch/_dynamo/convert_frame.py:964] [0/42]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:36.804000 29036 torch/_dynamo/convert_frame.py:964] [0/42]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:36.804000 29036 torch/_dynamo/convert_frame.py:964] [0/42] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:36.804000 29036 torch/_dynamo/convert_frame.py:964] [0/42] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:36,806 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:36,806 - INFO - Falling back to sequential processing
W0905 17:27:36.833000 29043 torch/_dynamo/convert_frame.py:964] [0/107] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:36.833000 29043 torch/_dynamo/convert_frame.py:964] [0/107]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:36.833000 29043 torch/_dynamo/convert_frame.py:964] [0/107]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:36.833000 29043 torch/_dynamo/convert_frame.py:964] [0/107] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:36.833000 29043 torch/_dynamo/convert_frame.py:964] [0/107] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:36,835 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=30, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - WARNING - Skipping empty response for id=31, magnitude=2000.0
2025-09-05 17:27:36,835 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:36,835 - INFO - No valid responses to write for this batch
2025-09-05 17:27:36,846 - GPU-7 - INFO - Completed batch 69, total work units processed by this worker: 1080
2025-09-05 17:27:36,846 - INFO - Completed batch 69, total work units processed by this worker: 1080
2025-09-05 17:27:36,847 - GPU-7 - INFO - Processing batch 70 (16 work units)
2025-09-05 17:27:36,847 - INFO - Processing batch 70 (16 work units)
W0905 17:27:36.858000 29036 torch/_dynamo/convert_frame.py:964] [0/43] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:36.858000 29036 torch/_dynamo/convert_frame.py:964] [0/43]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:36.858000 29036 torch/_dynamo/convert_frame.py:964] [0/43]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:36.858000 29036 torch/_dynamo/convert_frame.py:964] [0/43] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:36.858000 29036 torch/_dynamo/convert_frame.py:964] [0/43] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:36,860 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=32, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:36,861 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:36,861 - INFO - No valid responses to write for this batch
2025-09-05 17:27:36,872 - GPU-0 - INFO - Completed batch 39, total work units processed by this worker: 612
2025-09-05 17:27:36,872 - INFO - Completed batch 39, total work units processed by this worker: 612
2025-09-05 17:27:36,872 - GPU-0 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:27:36,872 - INFO - Processing batch 40 (16 work units)
W0905 17:27:36.947000 29043 torch/_dynamo/convert_frame.py:964] [0/108] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:36.947000 29043 torch/_dynamo/convert_frame.py:964] [0/108]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:36.947000 29043 torch/_dynamo/convert_frame.py:964] [0/108]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:36.947000 29043 torch/_dynamo/convert_frame.py:964] [0/108] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:36.947000 29043 torch/_dynamo/convert_frame.py:964] [0/108] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:36,949 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:36,949 - INFO - Falling back to sequential processing
W0905 17:27:36.967000 29036 torch/_dynamo/convert_frame.py:964] [0/44] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:36.967000 29036 torch/_dynamo/convert_frame.py:964] [0/44]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:36.967000 29036 torch/_dynamo/convert_frame.py:964] [0/44]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:36.967000 29036 torch/_dynamo/convert_frame.py:964] [0/44] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:36.967000 29036 torch/_dynamo/convert_frame.py:964] [0/44] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:36,969 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:36,969 - INFO - Falling back to sequential processing
W0905 17:27:37.004000 29043 torch/_dynamo/convert_frame.py:964] [0/109] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:37.004000 29043 torch/_dynamo/convert_frame.py:964] [0/109]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:37.004000 29043 torch/_dynamo/convert_frame.py:964] [0/109]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:37.004000 29043 torch/_dynamo/convert_frame.py:964] [0/109] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:37.004000 29043 torch/_dynamo/convert_frame.py:964] [0/109] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:37,006 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=33, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=34, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,006 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,006 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:37,006 - INFO - No valid responses to write for this batch
2025-09-05 17:27:37,017 - GPU-7 - INFO - Completed batch 70, total work units processed by this worker: 1096
2025-09-05 17:27:37,017 - INFO - Completed batch 70, total work units processed by this worker: 1096
W0905 17:27:37.025000 29036 torch/_dynamo/convert_frame.py:964] [0/45] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:37.025000 29036 torch/_dynamo/convert_frame.py:964] [0/45]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:37.025000 29036 torch/_dynamo/convert_frame.py:964] [0/45]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:37.025000 29036 torch/_dynamo/convert_frame.py:964] [0/45] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:37.025000 29036 torch/_dynamo/convert_frame.py:964] [0/45] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:37,027 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:37,027 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,027 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=35, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=36, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:37,028 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:37,028 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:37,028 - INFO - No valid responses to write for this batch
2025-09-05 17:27:37,038 - GPU-0 - INFO - Completed batch 40, total work units processed by this worker: 628
2025-09-05 17:27:37,038 - INFO - Completed batch 40, total work units processed by this worker: 628
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:27:38,381 - GPU-3 - INFO - Completed batch 48, total work units processed by this worker: 768
2025-09-05 17:27:38,381 - INFO - Completed batch 48, total work units processed by this worker: 768
2025-09-05 17:27:39,228 - GPU-0 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:27:39,228 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:27:39,302 - GPU-7 - INFO - Processing batch 71 (16 work units)
2025-09-05 17:27:39,302 - INFO - Processing batch 71 (16 work units)
W0905 17:27:39.323000 29036 torch/_dynamo/convert_frame.py:964] [0/46] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:39.323000 29036 torch/_dynamo/convert_frame.py:964] [0/46]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:39.323000 29036 torch/_dynamo/convert_frame.py:964] [0/46]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:39.323000 29036 torch/_dynamo/convert_frame.py:964] [0/46] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:39.323000 29036 torch/_dynamo/convert_frame.py:964] [0/46] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:39,325 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:39,325 - INFO - Falling back to sequential processing
W0905 17:27:39.382000 29036 torch/_dynamo/convert_frame.py:964] [0/47] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:39.382000 29036 torch/_dynamo/convert_frame.py:964] [0/47]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:39.382000 29036 torch/_dynamo/convert_frame.py:964] [0/47]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:39.382000 29036 torch/_dynamo/convert_frame.py:964] [0/47] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:39.382000 29036 torch/_dynamo/convert_frame.py:964] [0/47] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:39,384 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=37, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=38, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,385 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,385 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:39,385 - INFO - No valid responses to write for this batch
2025-09-05 17:27:39,395 - GPU-0 - INFO - Completed batch 41, total work units processed by this worker: 644
2025-09-05 17:27:39,395 - INFO - Completed batch 41, total work units processed by this worker: 644
2025-09-05 17:27:39,395 - GPU-0 - INFO - Processing batch 42 (16 work units)
2025-09-05 17:27:39,395 - INFO - Processing batch 42 (16 work units)
W0905 17:27:39.404000 29043 torch/_dynamo/convert_frame.py:964] [0/110] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:39.404000 29043 torch/_dynamo/convert_frame.py:964] [0/110]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:39.404000 29043 torch/_dynamo/convert_frame.py:964] [0/110]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:39.404000 29043 torch/_dynamo/convert_frame.py:964] [0/110] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:39.404000 29043 torch/_dynamo/convert_frame.py:964] [0/110] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:39,406 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:39,406 - INFO - Falling back to sequential processing
W0905 17:27:39.461000 29043 torch/_dynamo/convert_frame.py:964] [0/111] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:39.461000 29043 torch/_dynamo/convert_frame.py:964] [0/111]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:39.461000 29043 torch/_dynamo/convert_frame.py:964] [0/111]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:39.461000 29043 torch/_dynamo/convert_frame.py:964] [0/111] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:39.461000 29043 torch/_dynamo/convert_frame.py:964] [0/111] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:39,463 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=39, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,463 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:39,463 - INFO - No valid responses to write for this batch
2025-09-05 17:27:39,475 - GPU-7 - INFO - Completed batch 71, total work units processed by this worker: 1112
2025-09-05 17:27:39,475 - INFO - Completed batch 71, total work units processed by this worker: 1112
2025-09-05 17:27:39,475 - GPU-7 - INFO - Processing batch 72 (16 work units)
2025-09-05 17:27:39,475 - INFO - Processing batch 72 (16 work units)
W0905 17:27:39.495000 29036 torch/_dynamo/convert_frame.py:964] [0/48] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:39.495000 29036 torch/_dynamo/convert_frame.py:964] [0/48]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:39.495000 29036 torch/_dynamo/convert_frame.py:964] [0/48]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:39.495000 29036 torch/_dynamo/convert_frame.py:964] [0/48] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:39.495000 29036 torch/_dynamo/convert_frame.py:964] [0/48] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:39,496 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:39,496 - INFO - Falling back to sequential processing
W0905 17:27:39.549000 29036 torch/_dynamo/convert_frame.py:964] [0/49] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:39.549000 29036 torch/_dynamo/convert_frame.py:964] [0/49]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:39.549000 29036 torch/_dynamo/convert_frame.py:964] [0/49]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:39.549000 29036 torch/_dynamo/convert_frame.py:964] [0/49] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:39.549000 29036 torch/_dynamo/convert_frame.py:964] [0/49] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:39,550 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=40, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=41, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,551 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:39,551 - INFO - No valid responses to write for this batch
2025-09-05 17:27:39,561 - GPU-0 - INFO - Completed batch 42, total work units processed by this worker: 660
2025-09-05 17:27:39,561 - INFO - Completed batch 42, total work units processed by this worker: 660
W0905 17:27:39.572000 29043 torch/_dynamo/convert_frame.py:964] [0/112] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:39.572000 29043 torch/_dynamo/convert_frame.py:964] [0/112]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:39.572000 29043 torch/_dynamo/convert_frame.py:964] [0/112]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:39.572000 29043 torch/_dynamo/convert_frame.py:964] [0/112] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:39.572000 29043 torch/_dynamo/convert_frame.py:964] [0/112] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:39,574 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:39,574 - INFO - Falling back to sequential processing
2025-09-05 17:27:39,619 - GPU-5 - INFO - Completed batch 52, total work units processed by this worker: 832
2025-09-05 17:27:39,619 - INFO - Completed batch 52, total work units processed by this worker: 832
W0905 17:27:39.629000 29043 torch/_dynamo/convert_frame.py:964] [0/113] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:39.629000 29043 torch/_dynamo/convert_frame.py:964] [0/113]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:39.629000 29043 torch/_dynamo/convert_frame.py:964] [0/113]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:39.629000 29043 torch/_dynamo/convert_frame.py:964] [0/113] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:39.629000 29043 torch/_dynamo/convert_frame.py:964] [0/113] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:39,631 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=42, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=43, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=44, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=44, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=44, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=44, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=44, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=44, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - WARNING - Skipping empty response for id=44, magnitude=2000.0
2025-09-05 17:27:39,631 - WARNING - Skipping empty response for id=44, magnitude=2000.0
2025-09-05 17:27:39,631 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:39,631 - INFO - No valid responses to write for this batch
2025-09-05 17:27:39,642 - GPU-7 - INFO - Completed batch 72, total work units processed by this worker: 1128
2025-09-05 17:27:39,642 - INFO - Completed batch 72, total work units processed by this worker: 1128
2025-09-05 17:27:39,958 - GPU-3 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:27:39,958 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:27:40,876 - GPU-2 - INFO - Completed batch 19, total work units processed by this worker: 292
2025-09-05 17:27:40,876 - INFO - Completed batch 19, total work units processed by this worker: 292
2025-09-05 17:27:40,876 - GPU-2 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:27:40,876 - INFO - Processing batch 20 (16 work units)
2025-09-05 17:27:41,228 - GPU-5 - INFO - Processing batch 53 (16 work units)
2025-09-05 17:27:41,228 - INFO - Processing batch 53 (16 work units)
2025-09-05 17:27:41,841 - GPU-0 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:27:41,841 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:27:41,852 - GPU-1 - INFO - Completed batch 48, total work units processed by this worker: 768
2025-09-05 17:27:41,852 - INFO - Completed batch 48, total work units processed by this worker: 768
2025-09-05 17:27:41,878 - GPU-7 - INFO - Processing batch 73 (16 work units)
2025-09-05 17:27:41,878 - INFO - Processing batch 73 (16 work units)
W0905 17:27:41.943000 29036 torch/_dynamo/convert_frame.py:964] [0/50] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:41.943000 29036 torch/_dynamo/convert_frame.py:964] [0/50]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:41.943000 29036 torch/_dynamo/convert_frame.py:964] [0/50]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:41.943000 29036 torch/_dynamo/convert_frame.py:964] [0/50] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:41.943000 29036 torch/_dynamo/convert_frame.py:964] [0/50] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:41,945 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:41,945 - INFO - Falling back to sequential processing
W0905 17:27:41.978000 29043 torch/_dynamo/convert_frame.py:964] [0/114] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:41.978000 29043 torch/_dynamo/convert_frame.py:964] [0/114]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:41.978000 29043 torch/_dynamo/convert_frame.py:964] [0/114]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:41.978000 29043 torch/_dynamo/convert_frame.py:964] [0/114] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:41.978000 29043 torch/_dynamo/convert_frame.py:964] [0/114] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:41,980 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:41,980 - INFO - Falling back to sequential processing
W0905 17:27:41.998000 29036 torch/_dynamo/convert_frame.py:964] [0/51] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:41.998000 29036 torch/_dynamo/convert_frame.py:964] [0/51]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:41.998000 29036 torch/_dynamo/convert_frame.py:964] [0/51]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:41.998000 29036 torch/_dynamo/convert_frame.py:964] [0/51] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:41.998000 29036 torch/_dynamo/convert_frame.py:964] [0/51] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:42,000 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=49, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=49, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=49, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=49, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=50, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,000 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,000 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:42,000 - INFO - No valid responses to write for this batch
2025-09-05 17:27:42,010 - GPU-0 - INFO - Completed batch 43, total work units processed by this worker: 676
2025-09-05 17:27:42,010 - INFO - Completed batch 43, total work units processed by this worker: 676
2025-09-05 17:27:42,011 - GPU-0 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:27:42,011 - INFO - Processing batch 44 (16 work units)
W0905 17:27:42.035000 29043 torch/_dynamo/convert_frame.py:964] [0/115] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:42.035000 29043 torch/_dynamo/convert_frame.py:964] [0/115]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:42.035000 29043 torch/_dynamo/convert_frame.py:964] [0/115]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:42.035000 29043 torch/_dynamo/convert_frame.py:964] [0/115] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:42.035000 29043 torch/_dynamo/convert_frame.py:964] [0/115] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:42,037 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=51, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=52, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,037 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,037 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:42,037 - INFO - No valid responses to write for this batch
2025-09-05 17:27:42,048 - GPU-7 - INFO - Completed batch 73, total work units processed by this worker: 1144
2025-09-05 17:27:42,048 - INFO - Completed batch 73, total work units processed by this worker: 1144
2025-09-05 17:27:42,048 - GPU-7 - INFO - Processing batch 74 (16 work units)
2025-09-05 17:27:42,048 - INFO - Processing batch 74 (16 work units)
W0905 17:27:42.117000 29036 torch/_dynamo/convert_frame.py:964] [0/52] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:42.117000 29036 torch/_dynamo/convert_frame.py:964] [0/52]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:42.117000 29036 torch/_dynamo/convert_frame.py:964] [0/52]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:42.117000 29036 torch/_dynamo/convert_frame.py:964] [0/52] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:42.117000 29036 torch/_dynamo/convert_frame.py:964] [0/52] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:42,119 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:42,119 - INFO - Falling back to sequential processing
W0905 17:27:42.154000 29043 torch/_dynamo/convert_frame.py:964] [0/116] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:42.154000 29043 torch/_dynamo/convert_frame.py:964] [0/116]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:42.154000 29043 torch/_dynamo/convert_frame.py:964] [0/116]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:42.154000 29043 torch/_dynamo/convert_frame.py:964] [0/116] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:42.154000 29043 torch/_dynamo/convert_frame.py:964] [0/116] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:42,156 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:42,156 - INFO - Falling back to sequential processing
W0905 17:27:42.171000 29036 torch/_dynamo/convert_frame.py:964] [0/53] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:42.171000 29036 torch/_dynamo/convert_frame.py:964] [0/53]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:42.171000 29036 torch/_dynamo/convert_frame.py:964] [0/53]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:42.171000 29036 torch/_dynamo/convert_frame.py:964] [0/53] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:42.171000 29036 torch/_dynamo/convert_frame.py:964] [0/53] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:42,173 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=53, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=54, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,173 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,173 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:42,173 - INFO - No valid responses to write for this batch
2025-09-05 17:27:42,183 - GPU-0 - INFO - Completed batch 44, total work units processed by this worker: 692
2025-09-05 17:27:42,183 - INFO - Completed batch 44, total work units processed by this worker: 692
W0905 17:27:42.210000 29043 torch/_dynamo/convert_frame.py:964] [0/117] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:42.210000 29043 torch/_dynamo/convert_frame.py:964] [0/117]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:42.210000 29043 torch/_dynamo/convert_frame.py:964] [0/117]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:42.210000 29043 torch/_dynamo/convert_frame.py:964] [0/117] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:42.210000 29043 torch/_dynamo/convert_frame.py:964] [0/117] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:42,212 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:42,212 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - WARNING - Skipping empty response for id=55, magnitude=2000.0
2025-09-05 17:27:42,212 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,212 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,212 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,212 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - WARNING - Skipping empty response for id=56, magnitude=2000.0
2025-09-05 17:27:42,213 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:42,213 - INFO - No valid responses to write for this batch
2025-09-05 17:27:42,223 - GPU-7 - INFO - Completed batch 74, total work units processed by this worker: 1160
2025-09-05 17:27:42,223 - INFO - Completed batch 74, total work units processed by this worker: 1160
2025-09-05 17:27:43,515 - GPU-1 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:27:43,515 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:27:44,062 - GPU-4 - INFO - Completed batch 33, total work units processed by this worker: 516
2025-09-05 17:27:44,062 - INFO - Completed batch 33, total work units processed by this worker: 516
2025-09-05 17:27:44,063 - GPU-4 - INFO - Processing batch 34 (16 work units)
2025-09-05 17:27:44,063 - INFO - Processing batch 34 (16 work units)
W0905 17:27:44.168000 29040 torch/_dynamo/convert_frame.py:964] [0/8] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:44.168000 29040 torch/_dynamo/convert_frame.py:964] [0/8]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:44.168000 29040 torch/_dynamo/convert_frame.py:964] [0/8]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:44.168000 29040 torch/_dynamo/convert_frame.py:964] [0/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:44.168000 29040 torch/_dynamo/convert_frame.py:964] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:44,170 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:44,170 - INFO - Falling back to sequential processing
W0905 17:27:44.243000 29040 torch/_dynamo/convert_frame.py:964] [0/9] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:44.243000 29040 torch/_dynamo/convert_frame.py:964] [0/9]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:44.243000 29040 torch/_dynamo/convert_frame.py:964] [0/9]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:44.243000 29040 torch/_dynamo/convert_frame.py:964] [0/9] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:44.243000 29040 torch/_dynamo/convert_frame.py:964] [0/9] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:44,245 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=58, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=58, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=58, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=58, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=58, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=58, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=59, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,245 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,245 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:44,245 - INFO - No valid responses to write for this batch
2025-09-05 17:27:44,256 - GPU-4 - INFO - Completed batch 34, total work units processed by this worker: 532
2025-09-05 17:27:44,256 - INFO - Completed batch 34, total work units processed by this worker: 532
2025-09-05 17:27:44,273 - GPU-7 - INFO - Processing batch 75 (16 work units)
2025-09-05 17:27:44,273 - INFO - Processing batch 75 (16 work units)
W0905 17:27:44.373000 29043 torch/_dynamo/convert_frame.py:964] [0/118] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:44.373000 29043 torch/_dynamo/convert_frame.py:964] [0/118]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:44.373000 29043 torch/_dynamo/convert_frame.py:964] [0/118]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:44.373000 29043 torch/_dynamo/convert_frame.py:964] [0/118] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:44.373000 29043 torch/_dynamo/convert_frame.py:964] [0/118] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:44,375 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:44,375 - INFO - Falling back to sequential processing
W0905 17:27:44.430000 29043 torch/_dynamo/convert_frame.py:964] [0/119] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:44.430000 29043 torch/_dynamo/convert_frame.py:964] [0/119]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:44.430000 29043 torch/_dynamo/convert_frame.py:964] [0/119]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:44.430000 29043 torch/_dynamo/convert_frame.py:964] [0/119] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:44.430000 29043 torch/_dynamo/convert_frame.py:964] [0/119] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:44,432 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=60, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=61, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,432 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,432 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:44,432 - INFO - No valid responses to write for this batch
2025-09-05 17:27:44,441 - GPU-0 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:27:44,441 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:27:44,443 - GPU-7 - INFO - Completed batch 75, total work units processed by this worker: 1176
2025-09-05 17:27:44,443 - INFO - Completed batch 75, total work units processed by this worker: 1176
2025-09-05 17:27:44,444 - GPU-7 - INFO - Processing batch 76 (16 work units)
2025-09-05 17:27:44,444 - INFO - Processing batch 76 (16 work units)
W0905 17:27:44.545000 29036 torch/_dynamo/convert_frame.py:964] [0/54] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:44.545000 29036 torch/_dynamo/convert_frame.py:964] [0/54]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:44.545000 29036 torch/_dynamo/convert_frame.py:964] [0/54]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:44.545000 29036 torch/_dynamo/convert_frame.py:964] [0/54] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:44.545000 29036 torch/_dynamo/convert_frame.py:964] [0/54] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:44,547 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:44,547 - INFO - Falling back to sequential processing
W0905 17:27:44.554000 29043 torch/_dynamo/convert_frame.py:964] [0/120] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:44.554000 29043 torch/_dynamo/convert_frame.py:964] [0/120]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:44.554000 29043 torch/_dynamo/convert_frame.py:964] [0/120]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:44.554000 29043 torch/_dynamo/convert_frame.py:964] [0/120] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:44.554000 29043 torch/_dynamo/convert_frame.py:964] [0/120] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:44,556 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:44,556 - INFO - Falling back to sequential processing
W0905 17:27:44.603000 29036 torch/_dynamo/convert_frame.py:964] [0/55] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:44.603000 29036 torch/_dynamo/convert_frame.py:964] [0/55]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:44.603000 29036 torch/_dynamo/convert_frame.py:964] [0/55]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:44.603000 29036 torch/_dynamo/convert_frame.py:964] [0/55] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:44.603000 29036 torch/_dynamo/convert_frame.py:964] [0/55] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:44,605 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=62, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - WARNING - Skipping empty response for id=63, magnitude=2000.0
2025-09-05 17:27:44,606 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:44,606 - INFO - No valid responses to write for this batch
W0905 17:27:44.611000 29043 torch/_dynamo/convert_frame.py:964] [0/121] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:44.611000 29043 torch/_dynamo/convert_frame.py:964] [0/121]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:44.611000 29043 torch/_dynamo/convert_frame.py:964] [0/121]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:44.611000 29043 torch/_dynamo/convert_frame.py:964] [0/121] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:44.611000 29043 torch/_dynamo/convert_frame.py:964] [0/121] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:44,612 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=64, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,613 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:44,613 - INFO - No valid responses to write for this batch
2025-09-05 17:27:44,619 - GPU-0 - INFO - Completed batch 45, total work units processed by this worker: 708
2025-09-05 17:27:44,619 - INFO - Completed batch 45, total work units processed by this worker: 708
2025-09-05 17:27:44,619 - GPU-0 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:27:44,619 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:27:44,629 - GPU-7 - INFO - Completed batch 76, total work units processed by this worker: 1192
2025-09-05 17:27:44,629 - INFO - Completed batch 76, total work units processed by this worker: 1192
W0905 17:27:44.718000 29036 torch/_dynamo/convert_frame.py:964] [0/56] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:44.718000 29036 torch/_dynamo/convert_frame.py:964] [0/56]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:44.718000 29036 torch/_dynamo/convert_frame.py:964] [0/56]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:44.718000 29036 torch/_dynamo/convert_frame.py:964] [0/56] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:44.718000 29036 torch/_dynamo/convert_frame.py:964] [0/56] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:44,719 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:44,719 - INFO - Falling back to sequential processing
W0905 17:27:44.775000 29036 torch/_dynamo/convert_frame.py:964] [0/57] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:44.775000 29036 torch/_dynamo/convert_frame.py:964] [0/57]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:44.775000 29036 torch/_dynamo/convert_frame.py:964] [0/57]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:44.775000 29036 torch/_dynamo/convert_frame.py:964] [0/57] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:44.775000 29036 torch/_dynamo/convert_frame.py:964] [0/57] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:44,777 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:44,777 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,777 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,777 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,777 - WARNING - Skipping empty response for id=65, magnitude=2000.0
2025-09-05 17:27:44,777 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,777 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,777 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,777 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,777 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,777 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,777 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,777 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - WARNING - Skipping empty response for id=66, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:44,778 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:44,778 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:44,778 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:44,778 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:44,778 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:44,778 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:44,778 - INFO - No valid responses to write for this batch
2025-09-05 17:27:44,788 - GPU-0 - INFO - Completed batch 46, total work units processed by this worker: 724
2025-09-05 17:27:44,788 - INFO - Completed batch 46, total work units processed by this worker: 724
2025-09-05 17:27:46,911 - GPU-0 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:27:46,911 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:27:46,954 - GPU-7 - INFO - Processing batch 77 (16 work units)
2025-09-05 17:27:46,954 - INFO - Processing batch 77 (16 work units)
W0905 17:27:47.018000 29036 torch/_dynamo/convert_frame.py:964] [0/58] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.018000 29036 torch/_dynamo/convert_frame.py:964] [0/58]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.018000 29036 torch/_dynamo/convert_frame.py:964] [0/58]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:47.018000 29036 torch/_dynamo/convert_frame.py:964] [0/58] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.018000 29036 torch/_dynamo/convert_frame.py:964] [0/58] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,020 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,020 - INFO - Falling back to sequential processing
W0905 17:27:47.057000 29043 torch/_dynamo/convert_frame.py:964] [0/122] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.057000 29043 torch/_dynamo/convert_frame.py:964] [0/122]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.057000 29043 torch/_dynamo/convert_frame.py:964] [0/122]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:47.057000 29043 torch/_dynamo/convert_frame.py:964] [0/122] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.057000 29043 torch/_dynamo/convert_frame.py:964] [0/122] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,059 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,059 - INFO - Falling back to sequential processing
W0905 17:27:47.076000 29036 torch/_dynamo/convert_frame.py:964] [0/59] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.076000 29036 torch/_dynamo/convert_frame.py:964] [0/59]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.076000 29036 torch/_dynamo/convert_frame.py:964] [0/59]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:47.076000 29036 torch/_dynamo/convert_frame.py:964] [0/59] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.076000 29036 torch/_dynamo/convert_frame.py:964] [0/59] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,077 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=67, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=68, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,078 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,078 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,078 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,088 - GPU-0 - INFO - Completed batch 47, total work units processed by this worker: 740
2025-09-05 17:27:47,088 - INFO - Completed batch 47, total work units processed by this worker: 740
2025-09-05 17:27:47,089 - GPU-0 - INFO - Processing batch 48 (16 work units)
2025-09-05 17:27:47,089 - INFO - Processing batch 48 (16 work units)
W0905 17:27:47.118000 29043 torch/_dynamo/convert_frame.py:964] [0/123] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.118000 29043 torch/_dynamo/convert_frame.py:964] [0/123]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.118000 29043 torch/_dynamo/convert_frame.py:964] [0/123]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:47.118000 29043 torch/_dynamo/convert_frame.py:964] [0/123] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.118000 29043 torch/_dynamo/convert_frame.py:964] [0/123] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,120 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,120 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - WARNING - Skipping empty response for id=69, magnitude=2000.0
2025-09-05 17:27:47,120 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,120 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,120 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,120 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - WARNING - Skipping empty response for id=70, magnitude=2000.0
2025-09-05 17:27:47,121 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,121 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,121 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,121 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,132 - GPU-7 - INFO - Completed batch 77, total work units processed by this worker: 1208
2025-09-05 17:27:47,132 - INFO - Completed batch 77, total work units processed by this worker: 1208
2025-09-05 17:27:47,132 - GPU-7 - INFO - Processing batch 78 (16 work units)
2025-09-05 17:27:47,132 - INFO - Processing batch 78 (16 work units)
W0905 17:27:47.183000 29036 torch/_dynamo/convert_frame.py:964] [0/60] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.183000 29036 torch/_dynamo/convert_frame.py:964] [0/60]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.183000 29036 torch/_dynamo/convert_frame.py:964] [0/60]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:47.183000 29036 torch/_dynamo/convert_frame.py:964] [0/60] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.183000 29036 torch/_dynamo/convert_frame.py:964] [0/60] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,185 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,185 - INFO - Falling back to sequential processing
W0905 17:27:47.225000 29043 torch/_dynamo/convert_frame.py:964] [0/124] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.225000 29043 torch/_dynamo/convert_frame.py:964] [0/124]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.225000 29043 torch/_dynamo/convert_frame.py:964] [0/124]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:47.225000 29043 torch/_dynamo/convert_frame.py:964] [0/124] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.225000 29043 torch/_dynamo/convert_frame.py:964] [0/124] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,227 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,227 - INFO - Falling back to sequential processing
W0905 17:27:47.237000 29036 torch/_dynamo/convert_frame.py:964] [0/61] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.237000 29036 torch/_dynamo/convert_frame.py:964] [0/61]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.237000 29036 torch/_dynamo/convert_frame.py:964] [0/61]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:47.237000 29036 torch/_dynamo/convert_frame.py:964] [0/61] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.237000 29036 torch/_dynamo/convert_frame.py:964] [0/61] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,239 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,239 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,239 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,240 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,240 - WARNING - Skipping empty response for id=71, magnitude=2000.0
2025-09-05 17:27:47,240 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,240 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,240 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,250 - GPU-0 - INFO - Completed batch 48, total work units processed by this worker: 756
2025-09-05 17:27:47,250 - INFO - Completed batch 48, total work units processed by this worker: 756
W0905 17:27:47.282000 29043 torch/_dynamo/convert_frame.py:964] [0/125] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.282000 29043 torch/_dynamo/convert_frame.py:964] [0/125]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.282000 29043 torch/_dynamo/convert_frame.py:964] [0/125]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:47.282000 29043 torch/_dynamo/convert_frame.py:964] [0/125] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.282000 29043 torch/_dynamo/convert_frame.py:964] [0/125] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,284 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=72, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=73, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,284 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,284 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,295 - GPU-7 - INFO - Completed batch 78, total work units processed by this worker: 1224
2025-09-05 17:27:47,295 - INFO - Completed batch 78, total work units processed by this worker: 1224
2025-09-05 17:27:47,352 - GPU-4 - INFO - Processing batch 35 (16 work units)
2025-09-05 17:27:47,352 - INFO - Processing batch 35 (16 work units)
W0905 17:27:47.447000 29040 torch/_dynamo/convert_frame.py:964] [0/10] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.447000 29040 torch/_dynamo/convert_frame.py:964] [0/10]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.447000 29040 torch/_dynamo/convert_frame.py:964] [0/10]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:47.447000 29040 torch/_dynamo/convert_frame.py:964] [0/10] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.447000 29040 torch/_dynamo/convert_frame.py:964] [0/10] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,449 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,449 - INFO - Falling back to sequential processing
W0905 17:27:47.518000 29040 torch/_dynamo/convert_frame.py:964] [0/11] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.518000 29040 torch/_dynamo/convert_frame.py:964] [0/11]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.518000 29040 torch/_dynamo/convert_frame.py:964] [0/11]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:47.518000 29040 torch/_dynamo/convert_frame.py:964] [0/11] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.518000 29040 torch/_dynamo/convert_frame.py:964] [0/11] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,520 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=74, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=75, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,520 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,520 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,520 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,532 - GPU-4 - INFO - Completed batch 35, total work units processed by this worker: 548
2025-09-05 17:27:47,532 - INFO - Completed batch 35, total work units processed by this worker: 548
2025-09-05 17:27:47,532 - GPU-4 - INFO - Processing batch 36 (16 work units)
2025-09-05 17:27:47,532 - INFO - Processing batch 36 (16 work units)
W0905 17:27:47.629000 29040 torch/_dynamo/convert_frame.py:964] [0/12] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.629000 29040 torch/_dynamo/convert_frame.py:964] [0/12]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.629000 29040 torch/_dynamo/convert_frame.py:964] [0/12]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:47.629000 29040 torch/_dynamo/convert_frame.py:964] [0/12] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.629000 29040 torch/_dynamo/convert_frame.py:964] [0/12] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,631 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,631 - INFO - Falling back to sequential processing
W0905 17:27:47.689000 29040 torch/_dynamo/convert_frame.py:964] [0/13] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:47.689000 29040 torch/_dynamo/convert_frame.py:964] [0/13]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:47.689000 29040 torch/_dynamo/convert_frame.py:964] [0/13]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:47.689000 29040 torch/_dynamo/convert_frame.py:964] [0/13] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:47.689000 29040 torch/_dynamo/convert_frame.py:964] [0/13] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:47,691 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=76, magnitude=2000.0
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - GPU-4 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,691 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,692 - GPU-4 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,692 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,692 - GPU-4 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,692 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,692 - GPU-4 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,692 - WARNING - Skipping empty response for id=77, magnitude=2000.0
2025-09-05 17:27:47,692 - GPU-4 - WARNING - Skipping empty response for id=78, magnitude=2000.0
2025-09-05 17:27:47,692 - WARNING - Skipping empty response for id=78, magnitude=2000.0
2025-09-05 17:27:47,692 - GPU-4 - WARNING - Skipping empty response for id=78, magnitude=2000.0
2025-09-05 17:27:47,692 - WARNING - Skipping empty response for id=78, magnitude=2000.0
2025-09-05 17:27:47,692 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,692 - INFO - No valid responses to write for this batch
2025-09-05 17:27:47,702 - GPU-4 - INFO - Completed batch 36, total work units processed by this worker: 564
2025-09-05 17:27:47,702 - INFO - Completed batch 36, total work units processed by this worker: 564
2025-09-05 17:27:47,885 - GPU-3 - INFO - Completed batch 49, total work units processed by this worker: 784
2025-09-05 17:27:47,885 - INFO - Completed batch 49, total work units processed by this worker: 784
2025-09-05 17:27:47,885 - GPU-3 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:27:47,885 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:27:47,995 - GPU-2 - INFO - Completed batch 20, total work units processed by this worker: 308
2025-09-05 17:27:47,995 - INFO - Completed batch 20, total work units processed by this worker: 308
2025-09-05 17:27:49,633 - GPU-7 - INFO - Processing batch 79 (16 work units)
2025-09-05 17:27:49,633 - INFO - Processing batch 79 (16 work units)
2025-09-05 17:27:49,657 - GPU-0 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:27:49,657 - INFO - Processing batch 49 (16 work units)
W0905 17:27:49.732000 29043 torch/_dynamo/convert_frame.py:964] [0/126] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:49.732000 29043 torch/_dynamo/convert_frame.py:964] [0/126]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:49.732000 29043 torch/_dynamo/convert_frame.py:964] [0/126]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:49.732000 29043 torch/_dynamo/convert_frame.py:964] [0/126] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:49.732000 29043 torch/_dynamo/convert_frame.py:964] [0/126] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:49,733 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:49,734 - INFO - Falling back to sequential processing
W0905 17:27:49.755000 29036 torch/_dynamo/convert_frame.py:964] [0/62] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:49.755000 29036 torch/_dynamo/convert_frame.py:964] [0/62]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:49.755000 29036 torch/_dynamo/convert_frame.py:964] [0/62]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:49.755000 29036 torch/_dynamo/convert_frame.py:964] [0/62] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:49.755000 29036 torch/_dynamo/convert_frame.py:964] [0/62] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:49,757 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:49,757 - INFO - Falling back to sequential processing
W0905 17:27:49.789000 29043 torch/_dynamo/convert_frame.py:964] [0/127] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:49.789000 29043 torch/_dynamo/convert_frame.py:964] [0/127]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:49.789000 29043 torch/_dynamo/convert_frame.py:964] [0/127]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:49.789000 29043 torch/_dynamo/convert_frame.py:964] [0/127] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:49.789000 29043 torch/_dynamo/convert_frame.py:964] [0/127] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:49,790 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=80, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,791 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:49,791 - INFO - No valid responses to write for this batch
2025-09-05 17:27:49,802 - GPU-7 - INFO - Completed batch 79, total work units processed by this worker: 1240
2025-09-05 17:27:49,802 - INFO - Completed batch 79, total work units processed by this worker: 1240
2025-09-05 17:27:49,802 - GPU-7 - INFO - Processing batch 80 (16 work units)
2025-09-05 17:27:49,802 - INFO - Processing batch 80 (16 work units)
W0905 17:27:49.809000 29036 torch/_dynamo/convert_frame.py:964] [0/63] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:49.809000 29036 torch/_dynamo/convert_frame.py:964] [0/63]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:49.809000 29036 torch/_dynamo/convert_frame.py:964] [0/63]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:49.809000 29036 torch/_dynamo/convert_frame.py:964] [0/63] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:49.809000 29036 torch/_dynamo/convert_frame.py:964] [0/63] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:49,811 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=81, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=82, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,812 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,812 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:49,812 - INFO - No valid responses to write for this batch
2025-09-05 17:27:49,825 - GPU-0 - INFO - Completed batch 49, total work units processed by this worker: 772
2025-09-05 17:27:49,825 - INFO - Completed batch 49, total work units processed by this worker: 772
2025-09-05 17:27:49,826 - GPU-0 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:27:49,826 - INFO - Processing batch 50 (16 work units)
W0905 17:27:49.906000 29043 torch/_dynamo/convert_frame.py:964] [0/128] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:49.906000 29043 torch/_dynamo/convert_frame.py:964] [0/128]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:49.906000 29043 torch/_dynamo/convert_frame.py:964] [0/128]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:49.906000 29043 torch/_dynamo/convert_frame.py:964] [0/128] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:49.906000 29043 torch/_dynamo/convert_frame.py:964] [0/128] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:49,907 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:49,907 - INFO - Falling back to sequential processing
W0905 17:27:49.925000 29036 torch/_dynamo/convert_frame.py:964] [0/64] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:49.925000 29036 torch/_dynamo/convert_frame.py:964] [0/64]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:49.925000 29036 torch/_dynamo/convert_frame.py:964] [0/64]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:49.925000 29036 torch/_dynamo/convert_frame.py:964] [0/64] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:49.925000 29036 torch/_dynamo/convert_frame.py:964] [0/64] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:49,927 - GPU-4 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:27:49,927 - INFO - Processing batch 37 (16 work units)
2025-09-05 17:27:49,927 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:49,927 - INFO - Falling back to sequential processing
W0905 17:27:49.962000 29043 torch/_dynamo/convert_frame.py:964] [0/129] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:49.962000 29043 torch/_dynamo/convert_frame.py:964] [0/129]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:49.962000 29043 torch/_dynamo/convert_frame.py:964] [0/129]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:49.962000 29043 torch/_dynamo/convert_frame.py:964] [0/129] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:49.962000 29043 torch/_dynamo/convert_frame.py:964] [0/129] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:49,964 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=83, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,964 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,965 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,965 - WARNING - Skipping empty response for id=84, magnitude=2000.0
2025-09-05 17:27:49,965 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,965 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,965 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,965 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,965 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,965 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,965 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:49,965 - INFO - No valid responses to write for this batch
2025-09-05 17:27:49,976 - GPU-7 - INFO - Completed batch 80, total work units processed by this worker: 1256
2025-09-05 17:27:49,976 - INFO - Completed batch 80, total work units processed by this worker: 1256
W0905 17:27:49.979000 29036 torch/_dynamo/convert_frame.py:964] [0/65] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:49.979000 29036 torch/_dynamo/convert_frame.py:964] [0/65]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:49.979000 29036 torch/_dynamo/convert_frame.py:964] [0/65]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:49.979000 29036 torch/_dynamo/convert_frame.py:964] [0/65] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:49.979000 29036 torch/_dynamo/convert_frame.py:964] [0/65] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:49,981 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:49,981 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,981 - WARNING - Skipping empty response for id=85, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - WARNING - Skipping empty response for id=86, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:49,982 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:49,982 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:49,982 - INFO - No valid responses to write for this batch
2025-09-05 17:27:49,992 - GPU-0 - INFO - Completed batch 50, total work units processed by this worker: 788
2025-09-05 17:27:49,992 - INFO - Completed batch 50, total work units processed by this worker: 788
W0905 17:27:50.028000 29040 torch/_dynamo/convert_frame.py:964] [0/14] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:50.028000 29040 torch/_dynamo/convert_frame.py:964] [0/14]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:50.028000 29040 torch/_dynamo/convert_frame.py:964] [0/14]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:50.028000 29040 torch/_dynamo/convert_frame.py:964] [0/14] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:50.028000 29040 torch/_dynamo/convert_frame.py:964] [0/14] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:50,030 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:50,030 - INFO - Falling back to sequential processing
W0905 17:27:50.088000 29040 torch/_dynamo/convert_frame.py:964] [0/15] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:50.088000 29040 torch/_dynamo/convert_frame.py:964] [0/15]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:50.088000 29040 torch/_dynamo/convert_frame.py:964] [0/15]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:50.088000 29040 torch/_dynamo/convert_frame.py:964] [0/15] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:50.088000 29040 torch/_dynamo/convert_frame.py:964] [0/15] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:50,090 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:50,090 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,090 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,091 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,091 - WARNING - Skipping empty response for id=87, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,091 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:50,091 - INFO - No valid responses to write for this batch
2025-09-05 17:27:50,101 - GPU-4 - INFO - Completed batch 37, total work units processed by this worker: 580
2025-09-05 17:27:50,101 - INFO - Completed batch 37, total work units processed by this worker: 580
2025-09-05 17:27:50,102 - GPU-4 - INFO - Processing batch 38 (16 work units)
2025-09-05 17:27:50,102 - INFO - Processing batch 38 (16 work units)
W0905 17:27:50.202000 29040 torch/_dynamo/convert_frame.py:964] [0/16] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:50.202000 29040 torch/_dynamo/convert_frame.py:964] [0/16]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:50.202000 29040 torch/_dynamo/convert_frame.py:964] [0/16]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:50.202000 29040 torch/_dynamo/convert_frame.py:964] [0/16] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:50.202000 29040 torch/_dynamo/convert_frame.py:964] [0/16] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:50,204 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:50,204 - INFO - Falling back to sequential processing
W0905 17:27:50.262000 29040 torch/_dynamo/convert_frame.py:964] [0/17] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:50.262000 29040 torch/_dynamo/convert_frame.py:964] [0/17]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:50.262000 29040 torch/_dynamo/convert_frame.py:964] [0/17]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:50.262000 29040 torch/_dynamo/convert_frame.py:964] [0/17] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:50.262000 29040 torch/_dynamo/convert_frame.py:964] [0/17] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:50,264 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:50,264 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,264 - WARNING - Skipping empty response for id=88, magnitude=2000.0
2025-09-05 17:27:50,264 - GPU-4 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - GPU-4 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - GPU-4 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - GPU-4 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - GPU-4 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - GPU-4 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,264 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,265 - GPU-4 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,265 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,265 - GPU-4 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,265 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,265 - GPU-4 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,265 - WARNING - Skipping empty response for id=89, magnitude=2000.0
2025-09-05 17:27:50,265 - GPU-4 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - GPU-4 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - GPU-4 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - GPU-4 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - GPU-4 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - GPU-4 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - WARNING - Skipping empty response for id=90, magnitude=2000.0
2025-09-05 17:27:50,265 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:50,265 - INFO - No valid responses to write for this batch
2025-09-05 17:27:50,275 - GPU-4 - INFO - Completed batch 38, total work units processed by this worker: 596
2025-09-05 17:27:50,275 - INFO - Completed batch 38, total work units processed by this worker: 596
2025-09-05 17:27:50,496 - GPU-2 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:27:50,496 - INFO - Processing batch 21 (16 work units)
2025-09-05 17:27:51,146 - GPU-1 - INFO - Completed batch 49, total work units processed by this worker: 784
2025-09-05 17:27:51,146 - INFO - Completed batch 49, total work units processed by this worker: 784
2025-09-05 17:27:51,146 - GPU-1 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:27:51,146 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:27:52,204 - GPU-0 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:27:52,204 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:27:52,314 - GPU-7 - INFO - Processing batch 81 (16 work units)
2025-09-05 17:27:52,314 - INFO - Processing batch 81 (16 work units)
W0905 17:27:52.314000 29036 torch/_dynamo/convert_frame.py:964] [0/66] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.314000 29036 torch/_dynamo/convert_frame.py:964] [0/66]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.314000 29036 torch/_dynamo/convert_frame.py:964] [0/66]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:52.314000 29036 torch/_dynamo/convert_frame.py:964] [0/66] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.314000 29036 torch/_dynamo/convert_frame.py:964] [0/66] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,316 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,316 - INFO - Falling back to sequential processing
W0905 17:27:52.374000 29036 torch/_dynamo/convert_frame.py:964] [0/67] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.374000 29036 torch/_dynamo/convert_frame.py:964] [0/67]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.374000 29036 torch/_dynamo/convert_frame.py:964] [0/67]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:52.374000 29036 torch/_dynamo/convert_frame.py:964] [0/67] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.374000 29036 torch/_dynamo/convert_frame.py:964] [0/67] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,376 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=94, magnitude=2000.0
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,376 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,376 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - WARNING - Skipping empty response for id=95, magnitude=2000.0
2025-09-05 17:27:52,377 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:52,377 - INFO - No valid responses to write for this batch
2025-09-05 17:27:52,387 - GPU-0 - INFO - Completed batch 51, total work units processed by this worker: 804
2025-09-05 17:27:52,387 - INFO - Completed batch 51, total work units processed by this worker: 804
2025-09-05 17:27:52,387 - GPU-0 - INFO - Processing batch 52 (16 work units)
2025-09-05 17:27:52,387 - INFO - Processing batch 52 (16 work units)
W0905 17:27:52.422000 29043 torch/_dynamo/convert_frame.py:964] [0/130] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.422000 29043 torch/_dynamo/convert_frame.py:964] [0/130]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.422000 29043 torch/_dynamo/convert_frame.py:964] [0/130]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:52.422000 29043 torch/_dynamo/convert_frame.py:964] [0/130] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.422000 29043 torch/_dynamo/convert_frame.py:964] [0/130] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,424 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,424 - INFO - Falling back to sequential processing
W0905 17:27:52.479000 29043 torch/_dynamo/convert_frame.py:964] [0/131] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.479000 29043 torch/_dynamo/convert_frame.py:964] [0/131]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.479000 29043 torch/_dynamo/convert_frame.py:964] [0/131]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:52.479000 29043 torch/_dynamo/convert_frame.py:964] [0/131] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.479000 29043 torch/_dynamo/convert_frame.py:964] [0/131] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,481 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,481 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,481 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=96, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,482 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:52,482 - INFO - No valid responses to write for this batch
W0905 17:27:52.489000 29036 torch/_dynamo/convert_frame.py:964] [0/68] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.489000 29036 torch/_dynamo/convert_frame.py:964] [0/68]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.489000 29036 torch/_dynamo/convert_frame.py:964] [0/68]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:52.489000 29036 torch/_dynamo/convert_frame.py:964] [0/68] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.489000 29036 torch/_dynamo/convert_frame.py:964] [0/68] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,490 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,490 - INFO - Falling back to sequential processing
2025-09-05 17:27:52,493 - GPU-7 - INFO - Completed batch 81, total work units processed by this worker: 1272
2025-09-05 17:27:52,493 - INFO - Completed batch 81, total work units processed by this worker: 1272
2025-09-05 17:27:52,493 - GPU-7 - INFO - Processing batch 82 (4 work units)
2025-09-05 17:27:52,493 - INFO - Processing batch 82 (4 work units)
2025-09-05 17:27:52,516 - GPU-4 - INFO - Processing batch 39 (16 work units)
2025-09-05 17:27:52,516 - INFO - Processing batch 39 (16 work units)
W0905 17:27:52.543000 29036 torch/_dynamo/convert_frame.py:964] [0/69] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.543000 29036 torch/_dynamo/convert_frame.py:964] [0/69]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.543000 29036 torch/_dynamo/convert_frame.py:964] [0/69]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:52.543000 29036 torch/_dynamo/convert_frame.py:964] [0/69] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.543000 29036 torch/_dynamo/convert_frame.py:964] [0/69] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,544 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=97, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=98, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,545 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,545 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:52,545 - INFO - No valid responses to write for this batch
W0905 17:27:52.553000 29043 torch/_dynamo/convert_frame.py:964] [0/132] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.553000 29043 torch/_dynamo/convert_frame.py:964] [0/132]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.553000 29043 torch/_dynamo/convert_frame.py:964] [0/132]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:52.553000 29043 torch/_dynamo/convert_frame.py:964] [0/132] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.553000 29043 torch/_dynamo/convert_frame.py:964] [0/132] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,555 - GPU-0 - INFO - Completed batch 52, total work units processed by this worker: 820
2025-09-05 17:27:52,555 - INFO - Completed batch 52, total work units processed by this worker: 820
2025-09-05 17:27:52,555 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,555 - INFO - Falling back to sequential processing
W0905 17:27:52.605000 29040 torch/_dynamo/convert_frame.py:964] [0/18] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.605000 29040 torch/_dynamo/convert_frame.py:964] [0/18]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.605000 29040 torch/_dynamo/convert_frame.py:964] [0/18]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:52.605000 29040 torch/_dynamo/convert_frame.py:964] [0/18] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.605000 29040 torch/_dynamo/convert_frame.py:964] [0/18] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,607 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,607 - INFO - Falling back to sequential processing
W0905 17:27:52.610000 29043 torch/_dynamo/convert_frame.py:964] [0/133] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.610000 29043 torch/_dynamo/convert_frame.py:964] [0/133]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.610000 29043 torch/_dynamo/convert_frame.py:964] [0/133]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:52.610000 29043 torch/_dynamo/convert_frame.py:964] [0/133] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.610000 29043 torch/_dynamo/convert_frame.py:964] [0/133] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,612 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,612 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,612 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,612 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,612 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,612 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,612 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,612 - GPU-7 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,612 - WARNING - Skipping empty response for id=99, magnitude=2000.0
2025-09-05 17:27:52,612 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:52,612 - INFO - No valid responses to write for this batch
2025-09-05 17:27:52,613 - GPU-7 - INFO - Completed batch 82, total work units processed by this worker: 1276
2025-09-05 17:27:52,613 - INFO - Completed batch 82, total work units processed by this worker: 1276
W0905 17:27:52.669000 29040 torch/_dynamo/convert_frame.py:964] [0/19] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.669000 29040 torch/_dynamo/convert_frame.py:964] [0/19]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.669000 29040 torch/_dynamo/convert_frame.py:964] [0/19]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:52.669000 29040 torch/_dynamo/convert_frame.py:964] [0/19] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.669000 29040 torch/_dynamo/convert_frame.py:964] [0/19] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,671 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,671 - GPU-4 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,671 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,671 - GPU-4 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,671 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=0, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,672 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:52,672 - INFO - No valid responses to write for this batch
2025-09-05 17:27:52,682 - GPU-4 - INFO - Completed batch 39, total work units processed by this worker: 612
2025-09-05 17:27:52,682 - INFO - Completed batch 39, total work units processed by this worker: 612
2025-09-05 17:27:52,683 - GPU-4 - INFO - Processing batch 40 (16 work units)
2025-09-05 17:27:52,683 - INFO - Processing batch 40 (16 work units)
W0905 17:27:52.769000 29040 torch/_dynamo/convert_frame.py:964] [0/20] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.769000 29040 torch/_dynamo/convert_frame.py:964] [0/20]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.769000 29040 torch/_dynamo/convert_frame.py:964] [0/20]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:52.769000 29040 torch/_dynamo/convert_frame.py:964] [0/20] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.769000 29040 torch/_dynamo/convert_frame.py:964] [0/20] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,771 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,771 - INFO - Falling back to sequential processing
W0905 17:27:52.825000 29040 torch/_dynamo/convert_frame.py:964] [0/21] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:52.825000 29040 torch/_dynamo/convert_frame.py:964] [0/21]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:52.825000 29040 torch/_dynamo/convert_frame.py:964] [0/21]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:52.825000 29040 torch/_dynamo/convert_frame.py:964] [0/21] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:52.825000 29040 torch/_dynamo/convert_frame.py:964] [0/21] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:52,827 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=1, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=2, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=3, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=3, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=3, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=3, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=3, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=3, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=3, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=3, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - WARNING - Skipping empty response for id=3, magnitude=2400.0
2025-09-05 17:27:52,827 - WARNING - Skipping empty response for id=3, magnitude=2400.0
2025-09-05 17:27:52,827 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:52,827 - INFO - No valid responses to write for this batch
2025-09-05 17:27:52,838 - GPU-4 - INFO - Completed batch 40, total work units processed by this worker: 628
2025-09-05 17:27:52,838 - INFO - Completed batch 40, total work units processed by this worker: 628
2025-09-05 17:27:53,726 - GPU-5 - INFO - Completed batch 53, total work units processed by this worker: 848
2025-09-05 17:27:53,726 - INFO - Completed batch 53, total work units processed by this worker: 848
2025-09-05 17:27:53,726 - GPU-5 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:27:53,726 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:27:54,679 - GPU-0 - INFO - Processing batch 53 (16 work units)
2025-09-05 17:27:54,679 - INFO - Processing batch 53 (16 work units)
W0905 17:27:54.781000 29036 torch/_dynamo/convert_frame.py:964] [0/70] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:54.781000 29036 torch/_dynamo/convert_frame.py:964] [0/70]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:54.781000 29036 torch/_dynamo/convert_frame.py:964] [0/70]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:54.781000 29036 torch/_dynamo/convert_frame.py:964] [0/70] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:54.781000 29036 torch/_dynamo/convert_frame.py:964] [0/70] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:54,783 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:54,783 - INFO - Falling back to sequential processing
W0905 17:27:54.835000 29036 torch/_dynamo/convert_frame.py:964] [0/71] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:54.835000 29036 torch/_dynamo/convert_frame.py:964] [0/71]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:54.835000 29036 torch/_dynamo/convert_frame.py:964] [0/71]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:54.835000 29036 torch/_dynamo/convert_frame.py:964] [0/71] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:54.835000 29036 torch/_dynamo/convert_frame.py:964] [0/71] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:54,837 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=5, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=6, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:54,838 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:54,838 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:54,838 - INFO - No valid responses to write for this batch
2025-09-05 17:27:54,848 - GPU-0 - INFO - Completed batch 53, total work units processed by this worker: 836
2025-09-05 17:27:54,848 - INFO - Completed batch 53, total work units processed by this worker: 836
2025-09-05 17:27:54,848 - GPU-0 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:27:54,848 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:27:54,946 - GPU-7 - INFO - Processing batch 83 (16 work units)
2025-09-05 17:27:54,946 - INFO - Processing batch 83 (16 work units)
W0905 17:27:54.948000 29036 torch/_dynamo/convert_frame.py:964] [0/72] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:54.948000 29036 torch/_dynamo/convert_frame.py:964] [0/72]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:54.948000 29036 torch/_dynamo/convert_frame.py:964] [0/72]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:54.948000 29036 torch/_dynamo/convert_frame.py:964] [0/72] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:54.948000 29036 torch/_dynamo/convert_frame.py:964] [0/72] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:54,950 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:54,950 - INFO - Falling back to sequential processing
W0905 17:27:55.001000 29036 torch/_dynamo/convert_frame.py:964] [0/73] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:55.001000 29036 torch/_dynamo/convert_frame.py:964] [0/73]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:55.001000 29036 torch/_dynamo/convert_frame.py:964] [0/73]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:55.001000 29036 torch/_dynamo/convert_frame.py:964] [0/73] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:55.001000 29036 torch/_dynamo/convert_frame.py:964] [0/73] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:55,003 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=7, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,003 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,003 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,004 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,004 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,004 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,004 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,004 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,004 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,004 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:55,004 - INFO - No valid responses to write for this batch
2025-09-05 17:27:55,014 - GPU-0 - INFO - Completed batch 54, total work units processed by this worker: 852
2025-09-05 17:27:55,014 - INFO - Completed batch 54, total work units processed by this worker: 852
W0905 17:27:55.044000 29043 torch/_dynamo/convert_frame.py:964] [0/134] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:55.044000 29043 torch/_dynamo/convert_frame.py:964] [0/134]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:55.044000 29043 torch/_dynamo/convert_frame.py:964] [0/134]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:55.044000 29043 torch/_dynamo/convert_frame.py:964] [0/134] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:55.044000 29043 torch/_dynamo/convert_frame.py:964] [0/134] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:55,046 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:55,046 - INFO - Falling back to sequential processing
2025-09-05 17:27:55,083 - GPU-4 - INFO - Processing batch 41 (16 work units)
2025-09-05 17:27:55,083 - INFO - Processing batch 41 (16 work units)
W0905 17:27:55.101000 29043 torch/_dynamo/convert_frame.py:964] [0/135] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:55.101000 29043 torch/_dynamo/convert_frame.py:964] [0/135]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:55.101000 29043 torch/_dynamo/convert_frame.py:964] [0/135]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:55.101000 29043 torch/_dynamo/convert_frame.py:964] [0/135] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:55.101000 29043 torch/_dynamo/convert_frame.py:964] [0/135] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:55,103 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=8, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=9, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,103 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:55,103 - INFO - No valid responses to write for this batch
2025-09-05 17:27:55,118 - GPU-7 - INFO - Completed batch 83, total work units processed by this worker: 1292
2025-09-05 17:27:55,118 - INFO - Completed batch 83, total work units processed by this worker: 1292
2025-09-05 17:27:55,119 - GPU-7 - INFO - Processing batch 84 (16 work units)
2025-09-05 17:27:55,119 - INFO - Processing batch 84 (16 work units)
W0905 17:27:55.180000 29040 torch/_dynamo/convert_frame.py:964] [0/22] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:55.180000 29040 torch/_dynamo/convert_frame.py:964] [0/22]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:55.180000 29040 torch/_dynamo/convert_frame.py:964] [0/22]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:55.180000 29040 torch/_dynamo/convert_frame.py:964] [0/22] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:55.180000 29040 torch/_dynamo/convert_frame.py:964] [0/22] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:55,182 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:55,182 - INFO - Falling back to sequential processing
W0905 17:27:55.218000 29043 torch/_dynamo/convert_frame.py:964] [0/136] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:55.218000 29043 torch/_dynamo/convert_frame.py:964] [0/136]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:55.218000 29043 torch/_dynamo/convert_frame.py:964] [0/136]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:55.218000 29043 torch/_dynamo/convert_frame.py:964] [0/136] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:55.218000 29043 torch/_dynamo/convert_frame.py:964] [0/136] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:55,220 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:55,220 - INFO - Falling back to sequential processing
W0905 17:27:55.236000 29040 torch/_dynamo/convert_frame.py:964] [0/23] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:55.236000 29040 torch/_dynamo/convert_frame.py:964] [0/23]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:55.236000 29040 torch/_dynamo/convert_frame.py:964] [0/23]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:55.236000 29040 torch/_dynamo/convert_frame.py:964] [0/23] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:55.236000 29040 torch/_dynamo/convert_frame.py:964] [0/23] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:55,238 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=10, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=11, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,238 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,238 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:55,238 - INFO - No valid responses to write for this batch
2025-09-05 17:27:55,249 - GPU-4 - INFO - Completed batch 41, total work units processed by this worker: 644
2025-09-05 17:27:55,249 - INFO - Completed batch 41, total work units processed by this worker: 644
2025-09-05 17:27:55,249 - GPU-4 - INFO - Processing batch 42 (16 work units)
2025-09-05 17:27:55,249 - INFO - Processing batch 42 (16 work units)
W0905 17:27:55.275000 29043 torch/_dynamo/convert_frame.py:964] [0/137] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:55.275000 29043 torch/_dynamo/convert_frame.py:964] [0/137]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:55.275000 29043 torch/_dynamo/convert_frame.py:964] [0/137]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:55.275000 29043 torch/_dynamo/convert_frame.py:964] [0/137] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:55.275000 29043 torch/_dynamo/convert_frame.py:964] [0/137] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:55,277 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=12, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=13, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,277 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,277 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:55,277 - INFO - No valid responses to write for this batch
2025-09-05 17:27:55,288 - GPU-7 - INFO - Completed batch 84, total work units processed by this worker: 1308
2025-09-05 17:27:55,288 - INFO - Completed batch 84, total work units processed by this worker: 1308
W0905 17:27:55.347000 29040 torch/_dynamo/convert_frame.py:964] [0/24] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:55.347000 29040 torch/_dynamo/convert_frame.py:964] [0/24]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:55.347000 29040 torch/_dynamo/convert_frame.py:964] [0/24]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:55.347000 29040 torch/_dynamo/convert_frame.py:964] [0/24] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:55.347000 29040 torch/_dynamo/convert_frame.py:964] [0/24] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:55,349 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:55,349 - INFO - Falling back to sequential processing
W0905 17:27:55.403000 29040 torch/_dynamo/convert_frame.py:964] [0/25] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:55.403000 29040 torch/_dynamo/convert_frame.py:964] [0/25]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:55.403000 29040 torch/_dynamo/convert_frame.py:964] [0/25]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:55.403000 29040 torch/_dynamo/convert_frame.py:964] [0/25] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:55.403000 29040 torch/_dynamo/convert_frame.py:964] [0/25] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:55,405 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=14, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,405 - GPU-4 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,405 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,406 - GPU-4 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,406 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,406 - GPU-4 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,406 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,406 - GPU-4 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,406 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,406 - GPU-4 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,406 - WARNING - Skipping empty response for id=15, magnitude=2400.0
2025-09-05 17:27:55,406 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:55,406 - INFO - No valid responses to write for this batch
2025-09-05 17:27:55,416 - GPU-4 - INFO - Completed batch 42, total work units processed by this worker: 660
2025-09-05 17:27:55,416 - INFO - Completed batch 42, total work units processed by this worker: 660
2025-09-05 17:27:55,841 - GPU-3 - INFO - Completed batch 50, total work units processed by this worker: 800
2025-09-05 17:27:55,841 - INFO - Completed batch 50, total work units processed by this worker: 800
2025-09-05 17:27:57,320 - GPU-0 - INFO - Processing batch 55 (16 work units)
2025-09-05 17:27:57,320 - INFO - Processing batch 55 (16 work units)
W0905 17:27:57.423000 29036 torch/_dynamo/convert_frame.py:964] [0/74] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.423000 29036 torch/_dynamo/convert_frame.py:964] [0/74]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.423000 29036 torch/_dynamo/convert_frame.py:964] [0/74]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:57.423000 29036 torch/_dynamo/convert_frame.py:964] [0/74] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.423000 29036 torch/_dynamo/convert_frame.py:964] [0/74] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,425 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,425 - INFO - Falling back to sequential processing
W0905 17:27:57.477000 29036 torch/_dynamo/convert_frame.py:964] [0/75] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.477000 29036 torch/_dynamo/convert_frame.py:964] [0/75]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.477000 29036 torch/_dynamo/convert_frame.py:964] [0/75]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:57.477000 29036 torch/_dynamo/convert_frame.py:964] [0/75] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.477000 29036 torch/_dynamo/convert_frame.py:964] [0/75] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,479 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=16, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,479 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:57,479 - INFO - No valid responses to write for this batch
2025-09-05 17:27:57,490 - GPU-0 - INFO - Completed batch 55, total work units processed by this worker: 868
2025-09-05 17:27:57,490 - INFO - Completed batch 55, total work units processed by this worker: 868
2025-09-05 17:27:57,490 - GPU-0 - INFO - Processing batch 56 (16 work units)
2025-09-05 17:27:57,490 - INFO - Processing batch 56 (16 work units)
2025-09-05 17:27:57,522 - GPU-3 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:27:57,522 - INFO - Processing batch 51 (16 work units)
W0905 17:27:57.584000 29036 torch/_dynamo/convert_frame.py:964] [0/76] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.584000 29036 torch/_dynamo/convert_frame.py:964] [0/76]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.584000 29036 torch/_dynamo/convert_frame.py:964] [0/76]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:57.584000 29036 torch/_dynamo/convert_frame.py:964] [0/76] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.584000 29036 torch/_dynamo/convert_frame.py:964] [0/76] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,586 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,586 - INFO - Falling back to sequential processing
2025-09-05 17:27:57,625 - GPU-2 - INFO - Completed batch 21, total work units processed by this worker: 324
2025-09-05 17:27:57,625 - INFO - Completed batch 21, total work units processed by this worker: 324
2025-09-05 17:27:57,625 - GPU-2 - INFO - Processing batch 22 (16 work units)
2025-09-05 17:27:57,625 - INFO - Processing batch 22 (16 work units)
W0905 17:27:57.638000 29036 torch/_dynamo/convert_frame.py:964] [0/77] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.638000 29036 torch/_dynamo/convert_frame.py:964] [0/77]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.638000 29036 torch/_dynamo/convert_frame.py:964] [0/77]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:27:57.638000 29036 torch/_dynamo/convert_frame.py:964] [0/77] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.638000 29036 torch/_dynamo/convert_frame.py:964] [0/77] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,640 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=17, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=18, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=19, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=19, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=19, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=19, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=19, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=19, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=19, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=19, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - WARNING - Skipping empty response for id=19, magnitude=2400.0
2025-09-05 17:27:57,640 - WARNING - Skipping empty response for id=19, magnitude=2400.0
2025-09-05 17:27:57,640 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:27:57,640 - INFO - No valid responses to write for this batch
2025-09-05 17:27:57,650 - GPU-0 - INFO - Completed batch 56, total work units processed by this worker: 884
2025-09-05 17:27:57,650 - INFO - Completed batch 56, total work units processed by this worker: 884
2025-09-05 17:27:57,658 - GPU-7 - INFO - Processing batch 85 (16 work units)
2025-09-05 17:27:57,658 - INFO - Processing batch 85 (16 work units)
2025-09-05 17:27:57,726 - GPU-4 - INFO - Processing batch 43 (16 work units)
2025-09-05 17:27:57,726 - INFO - Processing batch 43 (16 work units)
W0905 17:27:57.753000 29043 torch/_dynamo/convert_frame.py:964] [0/138] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.753000 29043 torch/_dynamo/convert_frame.py:964] [0/138]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.753000 29043 torch/_dynamo/convert_frame.py:964] [0/138]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:57.753000 29043 torch/_dynamo/convert_frame.py:964] [0/138] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.753000 29043 torch/_dynamo/convert_frame.py:964] [0/138] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,755 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,755 - INFO - Falling back to sequential processing
W0905 17:27:57.811000 29043 torch/_dynamo/convert_frame.py:964] [0/139] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.811000 29043 torch/_dynamo/convert_frame.py:964] [0/139]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.811000 29043 torch/_dynamo/convert_frame.py:964] [0/139]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:57.811000 29043 torch/_dynamo/convert_frame.py:964] [0/139] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.811000 29043 torch/_dynamo/convert_frame.py:964] [0/139] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,812 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=23, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,813 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:57,813 - INFO - No valid responses to write for this batch
2025-09-05 17:27:57,824 - GPU-7 - INFO - Completed batch 85, total work units processed by this worker: 1324
2025-09-05 17:27:57,824 - INFO - Completed batch 85, total work units processed by this worker: 1324
2025-09-05 17:27:57,824 - GPU-7 - INFO - Processing batch 86 (16 work units)
2025-09-05 17:27:57,824 - INFO - Processing batch 86 (16 work units)
W0905 17:27:57.827000 29040 torch/_dynamo/convert_frame.py:964] [0/26] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.827000 29040 torch/_dynamo/convert_frame.py:964] [0/26]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.827000 29040 torch/_dynamo/convert_frame.py:964] [0/26]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:57.827000 29040 torch/_dynamo/convert_frame.py:964] [0/26] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.827000 29040 torch/_dynamo/convert_frame.py:964] [0/26] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,829 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,829 - INFO - Falling back to sequential processing
W0905 17:27:57.884000 29040 torch/_dynamo/convert_frame.py:964] [0/27] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.884000 29040 torch/_dynamo/convert_frame.py:964] [0/27]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.884000 29040 torch/_dynamo/convert_frame.py:964] [0/27]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:57.884000 29040 torch/_dynamo/convert_frame.py:964] [0/27] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.884000 29040 torch/_dynamo/convert_frame.py:964] [0/27] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,885 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=24, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=25, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,886 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:57,886 - INFO - No valid responses to write for this batch
2025-09-05 17:27:57,897 - GPU-4 - INFO - Completed batch 43, total work units processed by this worker: 676
2025-09-05 17:27:57,897 - INFO - Completed batch 43, total work units processed by this worker: 676
2025-09-05 17:27:57,897 - GPU-4 - INFO - Processing batch 44 (16 work units)
2025-09-05 17:27:57,897 - INFO - Processing batch 44 (16 work units)
W0905 17:27:57.924000 29043 torch/_dynamo/convert_frame.py:964] [0/140] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.924000 29043 torch/_dynamo/convert_frame.py:964] [0/140]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.924000 29043 torch/_dynamo/convert_frame.py:964] [0/140]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:57.924000 29043 torch/_dynamo/convert_frame.py:964] [0/140] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.924000 29043 torch/_dynamo/convert_frame.py:964] [0/140] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,926 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,926 - INFO - Falling back to sequential processing
W0905 17:27:57.981000 29043 torch/_dynamo/convert_frame.py:964] [0/141] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.981000 29043 torch/_dynamo/convert_frame.py:964] [0/141]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.981000 29043 torch/_dynamo/convert_frame.py:964] [0/141]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:27:57.981000 29043 torch/_dynamo/convert_frame.py:964] [0/141] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.981000 29043 torch/_dynamo/convert_frame.py:964] [0/141] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,982 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=26, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=27, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:57,983 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:57,983 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:27:57,983 - INFO - No valid responses to write for this batch
W0905 17:27:57.990000 29040 torch/_dynamo/convert_frame.py:964] [0/28] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:57.990000 29040 torch/_dynamo/convert_frame.py:964] [0/28]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:57.990000 29040 torch/_dynamo/convert_frame.py:964] [0/28]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:57.990000 29040 torch/_dynamo/convert_frame.py:964] [0/28] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:57.990000 29040 torch/_dynamo/convert_frame.py:964] [0/28] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:57,992 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:57,992 - INFO - Falling back to sequential processing
2025-09-05 17:27:57,994 - GPU-7 - INFO - Completed batch 86, total work units processed by this worker: 1340
2025-09-05 17:27:57,994 - INFO - Completed batch 86, total work units processed by this worker: 1340
W0905 17:27:58.050000 29040 torch/_dynamo/convert_frame.py:964] [0/29] torch._dynamo hit config.recompile_limit (8)
W0905 17:27:58.050000 29040 torch/_dynamo/convert_frame.py:964] [0/29]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:27:58.050000 29040 torch/_dynamo/convert_frame.py:964] [0/29]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:27:58.050000 29040 torch/_dynamo/convert_frame.py:964] [0/29] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:27:58.050000 29040 torch/_dynamo/convert_frame.py:964] [0/29] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:27:58,052 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=28, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=29, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=30, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=30, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - WARNING - Skipping empty response for id=30, magnitude=2400.0
2025-09-05 17:27:58,052 - WARNING - Skipping empty response for id=30, magnitude=2400.0
2025-09-05 17:27:58,052 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:27:58,052 - INFO - No valid responses to write for this batch
2025-09-05 17:27:58,063 - GPU-4 - INFO - Completed batch 44, total work units processed by this worker: 692
2025-09-05 17:27:58,063 - INFO - Completed batch 44, total work units processed by this worker: 692
2025-09-05 17:27:58,144 - GPU-1 - INFO - Completed batch 50, total work units processed by this worker: 800
2025-09-05 17:27:58,144 - INFO - Completed batch 50, total work units processed by this worker: 800
2025-09-05 17:27:59,783 - GPU-1 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:27:59,783 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:28:00,008 - GPU-0 - INFO - Processing batch 57 (16 work units)
2025-09-05 17:28:00,008 - INFO - Processing batch 57 (16 work units)
W0905 17:28:00.103000 29036 torch/_dynamo/convert_frame.py:964] [0/78] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.103000 29036 torch/_dynamo/convert_frame.py:964] [0/78]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.103000 29036 torch/_dynamo/convert_frame.py:964] [0/78]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:00.103000 29036 torch/_dynamo/convert_frame.py:964] [0/78] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.103000 29036 torch/_dynamo/convert_frame.py:964] [0/78] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,105 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,105 - INFO - Falling back to sequential processing
W0905 17:28:00.157000 29036 torch/_dynamo/convert_frame.py:964] [0/79] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.157000 29036 torch/_dynamo/convert_frame.py:964] [0/79]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.157000 29036 torch/_dynamo/convert_frame.py:964] [0/79]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:00.157000 29036 torch/_dynamo/convert_frame.py:964] [0/79] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.157000 29036 torch/_dynamo/convert_frame.py:964] [0/79] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,159 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=32, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,159 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,160 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,160 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,170 - GPU-0 - INFO - Completed batch 57, total work units processed by this worker: 900
2025-09-05 17:28:00,170 - INFO - Completed batch 57, total work units processed by this worker: 900
2025-09-05 17:28:00,170 - GPU-0 - INFO - Processing batch 58 (16 work units)
2025-09-05 17:28:00,170 - INFO - Processing batch 58 (16 work units)
W0905 17:28:00.269000 29036 torch/_dynamo/convert_frame.py:964] [0/80] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.269000 29036 torch/_dynamo/convert_frame.py:964] [0/80]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.269000 29036 torch/_dynamo/convert_frame.py:964] [0/80]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:00.269000 29036 torch/_dynamo/convert_frame.py:964] [0/80] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.269000 29036 torch/_dynamo/convert_frame.py:964] [0/80] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,271 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,271 - INFO - Falling back to sequential processing
2025-09-05 17:28:00,305 - GPU-7 - INFO - Processing batch 87 (16 work units)
2025-09-05 17:28:00,305 - INFO - Processing batch 87 (16 work units)
W0905 17:28:00.323000 29036 torch/_dynamo/convert_frame.py:964] [0/81] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.323000 29036 torch/_dynamo/convert_frame.py:964] [0/81]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.323000 29036 torch/_dynamo/convert_frame.py:964] [0/81]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:00.323000 29036 torch/_dynamo/convert_frame.py:964] [0/81] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.323000 29036 torch/_dynamo/convert_frame.py:964] [0/81] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,325 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=33, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=34, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,325 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,325 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,325 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,330 - GPU-4 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:28:00,330 - INFO - Processing batch 45 (16 work units)
2025-09-05 17:28:00,338 - GPU-0 - INFO - Completed batch 58, total work units processed by this worker: 916
2025-09-05 17:28:00,338 - INFO - Completed batch 58, total work units processed by this worker: 916
W0905 17:28:00.404000 29043 torch/_dynamo/convert_frame.py:964] [0/142] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.404000 29043 torch/_dynamo/convert_frame.py:964] [0/142]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.404000 29043 torch/_dynamo/convert_frame.py:964] [0/142]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:00.404000 29043 torch/_dynamo/convert_frame.py:964] [0/142] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.404000 29043 torch/_dynamo/convert_frame.py:964] [0/142] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,406 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,406 - INFO - Falling back to sequential processing
W0905 17:28:00.426000 29040 torch/_dynamo/convert_frame.py:964] [0/30] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.426000 29040 torch/_dynamo/convert_frame.py:964] [0/30]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.426000 29040 torch/_dynamo/convert_frame.py:964] [0/30]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:00.426000 29040 torch/_dynamo/convert_frame.py:964] [0/30] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.426000 29040 torch/_dynamo/convert_frame.py:964] [0/30] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,428 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,428 - INFO - Falling back to sequential processing
W0905 17:28:00.461000 29043 torch/_dynamo/convert_frame.py:964] [0/143] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.461000 29043 torch/_dynamo/convert_frame.py:964] [0/143]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.461000 29043 torch/_dynamo/convert_frame.py:964] [0/143]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:00.461000 29043 torch/_dynamo/convert_frame.py:964] [0/143] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.461000 29043 torch/_dynamo/convert_frame.py:964] [0/143] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,463 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,463 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,463 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,463 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,463 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,463 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,463 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,463 - GPU-7 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,463 - WARNING - Skipping empty response for id=35, magnitude=2400.0
2025-09-05 17:28:00,463 - GPU-7 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,463 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=36, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,464 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,464 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,464 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,475 - GPU-7 - INFO - Completed batch 87, total work units processed by this worker: 1356
2025-09-05 17:28:00,475 - INFO - Completed batch 87, total work units processed by this worker: 1356
2025-09-05 17:28:00,475 - GPU-7 - INFO - Processing batch 88 (16 work units)
2025-09-05 17:28:00,475 - INFO - Processing batch 88 (16 work units)
W0905 17:28:00.487000 29040 torch/_dynamo/convert_frame.py:964] [0/31] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.487000 29040 torch/_dynamo/convert_frame.py:964] [0/31]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.487000 29040 torch/_dynamo/convert_frame.py:964] [0/31]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:00.487000 29040 torch/_dynamo/convert_frame.py:964] [0/31] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.487000 29040 torch/_dynamo/convert_frame.py:964] [0/31] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,489 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=37, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=38, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,489 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,489 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,489 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,500 - GPU-4 - INFO - Completed batch 45, total work units processed by this worker: 708
2025-09-05 17:28:00,500 - INFO - Completed batch 45, total work units processed by this worker: 708
2025-09-05 17:28:00,500 - GPU-4 - INFO - Processing batch 46 (16 work units)
2025-09-05 17:28:00,500 - INFO - Processing batch 46 (16 work units)
W0905 17:28:00.575000 29043 torch/_dynamo/convert_frame.py:964] [0/144] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.575000 29043 torch/_dynamo/convert_frame.py:964] [0/144]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.575000 29043 torch/_dynamo/convert_frame.py:964] [0/144]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:00.575000 29043 torch/_dynamo/convert_frame.py:964] [0/144] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.575000 29043 torch/_dynamo/convert_frame.py:964] [0/144] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,577 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,577 - INFO - Falling back to sequential processing
W0905 17:28:00.598000 29040 torch/_dynamo/convert_frame.py:964] [0/32] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.598000 29040 torch/_dynamo/convert_frame.py:964] [0/32]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.598000 29040 torch/_dynamo/convert_frame.py:964] [0/32]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:00.598000 29040 torch/_dynamo/convert_frame.py:964] [0/32] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.598000 29040 torch/_dynamo/convert_frame.py:964] [0/32] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,600 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,600 - INFO - Falling back to sequential processing
W0905 17:28:00.631000 29043 torch/_dynamo/convert_frame.py:964] [0/145] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.631000 29043 torch/_dynamo/convert_frame.py:964] [0/145]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.631000 29043 torch/_dynamo/convert_frame.py:964] [0/145]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:00.631000 29043 torch/_dynamo/convert_frame.py:964] [0/145] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.631000 29043 torch/_dynamo/convert_frame.py:964] [0/145] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,633 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,633 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,633 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=39, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,634 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,634 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,645 - GPU-7 - INFO - Completed batch 88, total work units processed by this worker: 1372
2025-09-05 17:28:00,645 - INFO - Completed batch 88, total work units processed by this worker: 1372
W0905 17:28:00.654000 29040 torch/_dynamo/convert_frame.py:964] [0/33] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:00.654000 29040 torch/_dynamo/convert_frame.py:964] [0/33]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:00.654000 29040 torch/_dynamo/convert_frame.py:964] [0/33]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:00.654000 29040 torch/_dynamo/convert_frame.py:964] [0/33] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:00.654000 29040 torch/_dynamo/convert_frame.py:964] [0/33] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:00,656 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=40, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=41, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:00,656 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,656 - INFO - No valid responses to write for this batch
2025-09-05 17:28:00,667 - GPU-4 - INFO - Completed batch 46, total work units processed by this worker: 724
2025-09-05 17:28:00,667 - INFO - Completed batch 46, total work units processed by this worker: 724
2025-09-05 17:28:02,523 - GPU-0 - INFO - Processing batch 59 (16 work units)
2025-09-05 17:28:02,523 - INFO - Processing batch 59 (16 work units)
2025-09-05 17:28:02,569 - GPU-5 - INFO - Completed batch 54, total work units processed by this worker: 864
2025-09-05 17:28:02,569 - INFO - Completed batch 54, total work units processed by this worker: 864
W0905 17:28:02.622000 29036 torch/_dynamo/convert_frame.py:964] [0/82] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:02.622000 29036 torch/_dynamo/convert_frame.py:964] [0/82]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:02.622000 29036 torch/_dynamo/convert_frame.py:964] [0/82]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:02.622000 29036 torch/_dynamo/convert_frame.py:964] [0/82] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:02.622000 29036 torch/_dynamo/convert_frame.py:964] [0/82] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:02,624 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:02,624 - INFO - Falling back to sequential processing
W0905 17:28:02.681000 29036 torch/_dynamo/convert_frame.py:964] [0/83] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:02.681000 29036 torch/_dynamo/convert_frame.py:964] [0/83]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:02.681000 29036 torch/_dynamo/convert_frame.py:964] [0/83]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:02.681000 29036 torch/_dynamo/convert_frame.py:964] [0/83] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:02.681000 29036 torch/_dynamo/convert_frame.py:964] [0/83] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:02,683 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=42, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=43, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,683 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,683 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:02,683 - INFO - No valid responses to write for this batch
2025-09-05 17:28:02,694 - GPU-0 - INFO - Completed batch 59, total work units processed by this worker: 932
2025-09-05 17:28:02,694 - INFO - Completed batch 59, total work units processed by this worker: 932
2025-09-05 17:28:02,694 - GPU-0 - INFO - Processing batch 60 (16 work units)
2025-09-05 17:28:02,694 - INFO - Processing batch 60 (16 work units)
W0905 17:28:02.790000 29036 torch/_dynamo/convert_frame.py:964] [0/84] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:02.790000 29036 torch/_dynamo/convert_frame.py:964] [0/84]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:02.790000 29036 torch/_dynamo/convert_frame.py:964] [0/84]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:02.790000 29036 torch/_dynamo/convert_frame.py:964] [0/84] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:02.790000 29036 torch/_dynamo/convert_frame.py:964] [0/84] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:02,792 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:02,792 - INFO - Falling back to sequential processing
W0905 17:28:02.844000 29036 torch/_dynamo/convert_frame.py:964] [0/85] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:02.844000 29036 torch/_dynamo/convert_frame.py:964] [0/85]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:02.844000 29036 torch/_dynamo/convert_frame.py:964] [0/85]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:02.844000 29036 torch/_dynamo/convert_frame.py:964] [0/85] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:02.844000 29036 torch/_dynamo/convert_frame.py:964] [0/85] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:02,846 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=44, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=45, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:02,846 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:02,846 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:02,846 - INFO - No valid responses to write for this batch
2025-09-05 17:28:02,856 - GPU-0 - INFO - Completed batch 60, total work units processed by this worker: 948
2025-09-05 17:28:02,856 - INFO - Completed batch 60, total work units processed by this worker: 948
2025-09-05 17:28:02,983 - GPU-7 - INFO - Processing batch 89 (16 work units)
2025-09-05 17:28:02,983 - INFO - Processing batch 89 (16 work units)
2025-09-05 17:28:02,988 - GPU-4 - INFO - Processing batch 47 (16 work units)
2025-09-05 17:28:02,988 - INFO - Processing batch 47 (16 work units)
W0905 17:28:03.082000 29043 torch/_dynamo/convert_frame.py:964] [0/146] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:03.082000 29043 torch/_dynamo/convert_frame.py:964] [0/146]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:03.082000 29043 torch/_dynamo/convert_frame.py:964] [0/146]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:03.082000 29043 torch/_dynamo/convert_frame.py:964] [0/146] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:03.082000 29043 torch/_dynamo/convert_frame.py:964] [0/146] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:03,084 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:03,084 - INFO - Falling back to sequential processing
W0905 17:28:03.092000 29040 torch/_dynamo/convert_frame.py:964] [0/34] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:03.092000 29040 torch/_dynamo/convert_frame.py:964] [0/34]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:03.092000 29040 torch/_dynamo/convert_frame.py:964] [0/34]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:03.092000 29040 torch/_dynamo/convert_frame.py:964] [0/34] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:03.092000 29040 torch/_dynamo/convert_frame.py:964] [0/34] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:03,094 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:03,094 - INFO - Falling back to sequential processing
W0905 17:28:03.140000 29043 torch/_dynamo/convert_frame.py:964] [0/147] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:03.140000 29043 torch/_dynamo/convert_frame.py:964] [0/147]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:03.140000 29043 torch/_dynamo/convert_frame.py:964] [0/147]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:03.140000 29043 torch/_dynamo/convert_frame.py:964] [0/147] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:03.140000 29043 torch/_dynamo/convert_frame.py:964] [0/147] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:03,142 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:03,142 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,142 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=46, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - WARNING - Skipping empty response for id=47, magnitude=2400.0
2025-09-05 17:28:03,143 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:03,143 - INFO - No valid responses to write for this batch
W0905 17:28:03.149000 29040 torch/_dynamo/convert_frame.py:964] [0/35] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:03.149000 29040 torch/_dynamo/convert_frame.py:964] [0/35]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:03.149000 29040 torch/_dynamo/convert_frame.py:964] [0/35]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:03.149000 29040 torch/_dynamo/convert_frame.py:964] [0/35] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:03.149000 29040 torch/_dynamo/convert_frame.py:964] [0/35] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:03,151 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=48, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,152 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:03,152 - INFO - No valid responses to write for this batch
2025-09-05 17:28:03,156 - GPU-7 - INFO - Completed batch 89, total work units processed by this worker: 1388
2025-09-05 17:28:03,156 - INFO - Completed batch 89, total work units processed by this worker: 1388
2025-09-05 17:28:03,156 - GPU-7 - INFO - Processing batch 90 (16 work units)
2025-09-05 17:28:03,156 - INFO - Processing batch 90 (16 work units)
2025-09-05 17:28:03,166 - GPU-4 - INFO - Completed batch 47, total work units processed by this worker: 740
2025-09-05 17:28:03,166 - INFO - Completed batch 47, total work units processed by this worker: 740
2025-09-05 17:28:03,166 - GPU-4 - INFO - Processing batch 48 (16 work units)
2025-09-05 17:28:03,166 - INFO - Processing batch 48 (16 work units)
W0905 17:28:03.259000 29043 torch/_dynamo/convert_frame.py:964] [0/148] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:03.259000 29043 torch/_dynamo/convert_frame.py:964] [0/148]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:03.259000 29043 torch/_dynamo/convert_frame.py:964] [0/148]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:03.259000 29043 torch/_dynamo/convert_frame.py:964] [0/148] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:03.259000 29043 torch/_dynamo/convert_frame.py:964] [0/148] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:03,260 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:03,260 - INFO - Falling back to sequential processing
W0905 17:28:03.265000 29040 torch/_dynamo/convert_frame.py:964] [0/36] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:03.265000 29040 torch/_dynamo/convert_frame.py:964] [0/36]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:03.265000 29040 torch/_dynamo/convert_frame.py:964] [0/36]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:03.265000 29040 torch/_dynamo/convert_frame.py:964] [0/36] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:03.265000 29040 torch/_dynamo/convert_frame.py:964] [0/36] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:03,267 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:03,267 - INFO - Falling back to sequential processing
W0905 17:28:03.318000 29043 torch/_dynamo/convert_frame.py:964] [0/149] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:03.318000 29043 torch/_dynamo/convert_frame.py:964] [0/149]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:03.318000 29043 torch/_dynamo/convert_frame.py:964] [0/149]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:03.318000 29043 torch/_dynamo/convert_frame.py:964] [0/149] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:03.318000 29043 torch/_dynamo/convert_frame.py:964] [0/149] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:03,319 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=49, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=50, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,320 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,320 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:03,320 - INFO - No valid responses to write for this batch
W0905 17:28:03.329000 29040 torch/_dynamo/convert_frame.py:964] [0/37] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:03.329000 29040 torch/_dynamo/convert_frame.py:964] [0/37]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:03.329000 29040 torch/_dynamo/convert_frame.py:964] [0/37]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:03.329000 29040 torch/_dynamo/convert_frame.py:964] [0/37] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:03.329000 29040 torch/_dynamo/convert_frame.py:964] [0/37] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:03,331 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-7 - INFO - Completed batch 90, total work units processed by this worker: 1404
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=51, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - INFO - Completed batch 90, total work units processed by this worker: 1404
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=52, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=53, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=53, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=53, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=53, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - WARNING - Skipping empty response for id=53, magnitude=2400.0
2025-09-05 17:28:03,332 - WARNING - Skipping empty response for id=53, magnitude=2400.0
2025-09-05 17:28:03,332 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:03,332 - INFO - No valid responses to write for this batch
2025-09-05 17:28:03,343 - GPU-4 - INFO - Completed batch 48, total work units processed by this worker: 756
2025-09-05 17:28:03,343 - INFO - Completed batch 48, total work units processed by this worker: 756
2025-09-05 17:28:04,201 - GPU-5 - INFO - Processing batch 55 (16 work units)
2025-09-05 17:28:04,201 - INFO - Processing batch 55 (16 work units)
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:28:05,092 - GPU-0 - INFO - Processing batch 61 (16 work units)
2025-09-05 17:28:05,092 - INFO - Processing batch 61 (16 work units)
W0905 17:28:05.202000 29036 torch/_dynamo/convert_frame.py:964] [0/86] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.202000 29036 torch/_dynamo/convert_frame.py:964] [0/86]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.202000 29036 torch/_dynamo/convert_frame.py:964] [0/86]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:05.202000 29036 torch/_dynamo/convert_frame.py:964] [0/86] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.202000 29036 torch/_dynamo/convert_frame.py:964] [0/86] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,204 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,204 - INFO - Falling back to sequential processing
W0905 17:28:05.256000 29036 torch/_dynamo/convert_frame.py:964] [0/87] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.256000 29036 torch/_dynamo/convert_frame.py:964] [0/87]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.256000 29036 torch/_dynamo/convert_frame.py:964] [0/87]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:05.256000 29036 torch/_dynamo/convert_frame.py:964] [0/87] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.256000 29036 torch/_dynamo/convert_frame.py:964] [0/87] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,258 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=55, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,259 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,259 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,269 - GPU-0 - INFO - Completed batch 61, total work units processed by this worker: 964
2025-09-05 17:28:05,269 - INFO - Completed batch 61, total work units processed by this worker: 964
2025-09-05 17:28:05,269 - GPU-0 - INFO - Processing batch 62 (16 work units)
2025-09-05 17:28:05,269 - INFO - Processing batch 62 (16 work units)
2025-09-05 17:28:05,286 - GPU-3 - INFO - Completed batch 51, total work units processed by this worker: 816
2025-09-05 17:28:05,286 - INFO - Completed batch 51, total work units processed by this worker: 816
2025-09-05 17:28:05,286 - GPU-3 - INFO - Processing batch 52 (16 work units)
2025-09-05 17:28:05,286 - INFO - Processing batch 52 (16 work units)
W0905 17:28:05.380000 29036 torch/_dynamo/convert_frame.py:964] [0/88] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.380000 29036 torch/_dynamo/convert_frame.py:964] [0/88]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.380000 29036 torch/_dynamo/convert_frame.py:964] [0/88]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:05.380000 29036 torch/_dynamo/convert_frame.py:964] [0/88] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.380000 29036 torch/_dynamo/convert_frame.py:964] [0/88] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,382 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,382 - INFO - Falling back to sequential processing
W0905 17:28:05.434000 29036 torch/_dynamo/convert_frame.py:964] [0/89] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.434000 29036 torch/_dynamo/convert_frame.py:964] [0/89]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.434000 29036 torch/_dynamo/convert_frame.py:964] [0/89]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:05.434000 29036 torch/_dynamo/convert_frame.py:964] [0/89] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.434000 29036 torch/_dynamo/convert_frame.py:964] [0/89] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,436 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=56, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=57, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - WARNING - Skipping empty response for id=58, magnitude=2400.0
2025-09-05 17:28:05,436 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,436 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,446 - GPU-0 - INFO - Completed batch 62, total work units processed by this worker: 980
2025-09-05 17:28:05,446 - INFO - Completed batch 62, total work units processed by this worker: 980
2025-09-05 17:28:05,644 - GPU-4 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:28:05,644 - INFO - Processing batch 49 (16 work units)
2025-09-05 17:28:05,655 - GPU-7 - INFO - Processing batch 91 (16 work units)
2025-09-05 17:28:05,655 - INFO - Processing batch 91 (16 work units)
2025-09-05 17:28:05,699 - GPU-2 - INFO - Completed batch 22, total work units processed by this worker: 340
2025-09-05 17:28:05,699 - INFO - Completed batch 22, total work units processed by this worker: 340
W0905 17:28:05.745000 29040 torch/_dynamo/convert_frame.py:964] [0/38] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.745000 29040 torch/_dynamo/convert_frame.py:964] [0/38]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.745000 29040 torch/_dynamo/convert_frame.py:964] [0/38]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:05.745000 29040 torch/_dynamo/convert_frame.py:964] [0/38] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.745000 29040 torch/_dynamo/convert_frame.py:964] [0/38] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,747 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,747 - INFO - Falling back to sequential processing
W0905 17:28:05.757000 29043 torch/_dynamo/convert_frame.py:964] [0/150] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.757000 29043 torch/_dynamo/convert_frame.py:964] [0/150]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.757000 29043 torch/_dynamo/convert_frame.py:964] [0/150]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:05.757000 29043 torch/_dynamo/convert_frame.py:964] [0/150] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.757000 29043 torch/_dynamo/convert_frame.py:964] [0/150] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,759 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,759 - INFO - Falling back to sequential processing
W0905 17:28:05.801000 29040 torch/_dynamo/convert_frame.py:964] [0/39] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.801000 29040 torch/_dynamo/convert_frame.py:964] [0/39]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.801000 29040 torch/_dynamo/convert_frame.py:964] [0/39]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:05.801000 29040 torch/_dynamo/convert_frame.py:964] [0/39] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.801000 29040 torch/_dynamo/convert_frame.py:964] [0/39] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,803 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,803 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2400.0
2025-09-05 17:28:05,803 - WARNING - Skipping empty response for id=60, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=60, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=60, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=60, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=60, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=61, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,804 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,804 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,804 - INFO - No valid responses to write for this batch
W0905 17:28:05.814000 29043 torch/_dynamo/convert_frame.py:964] [0/151] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.814000 29043 torch/_dynamo/convert_frame.py:964] [0/151]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.814000 29043 torch/_dynamo/convert_frame.py:964] [0/151]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:05.814000 29043 torch/_dynamo/convert_frame.py:964] [0/151] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.814000 29043 torch/_dynamo/convert_frame.py:964] [0/151] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,815 - GPU-4 - INFO - Completed batch 49, total work units processed by this worker: 772
2025-09-05 17:28:05,815 - INFO - Completed batch 49, total work units processed by this worker: 772
2025-09-05 17:28:05,815 - GPU-4 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:28:05,815 - INFO - Processing batch 50 (16 work units)
2025-09-05 17:28:05,816 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=62, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - WARNING - Skipping empty response for id=63, magnitude=2400.0
2025-09-05 17:28:05,816 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,816 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,830 - GPU-7 - INFO - Completed batch 91, total work units processed by this worker: 1420
2025-09-05 17:28:05,830 - INFO - Completed batch 91, total work units processed by this worker: 1420
2025-09-05 17:28:05,831 - GPU-7 - INFO - Processing batch 92 (16 work units)
2025-09-05 17:28:05,831 - INFO - Processing batch 92 (16 work units)
W0905 17:28:05.925000 29040 torch/_dynamo/convert_frame.py:964] [0/40] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.925000 29040 torch/_dynamo/convert_frame.py:964] [0/40]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.925000 29040 torch/_dynamo/convert_frame.py:964] [0/40]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:05.925000 29040 torch/_dynamo/convert_frame.py:964] [0/40] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.925000 29040 torch/_dynamo/convert_frame.py:964] [0/40] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
W0905 17:28:05.926000 29043 torch/_dynamo/convert_frame.py:964] [0/152] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.926000 29043 torch/_dynamo/convert_frame.py:964] [0/152]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.926000 29043 torch/_dynamo/convert_frame.py:964] [0/152]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:05.926000 29043 torch/_dynamo/convert_frame.py:964] [0/152] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.926000 29043 torch/_dynamo/convert_frame.py:964] [0/152] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,927 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,927 - INFO - Falling back to sequential processing
2025-09-05 17:28:05,928 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,928 - INFO - Falling back to sequential processing
W0905 17:28:05.981000 29040 torch/_dynamo/convert_frame.py:964] [0/41] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.981000 29040 torch/_dynamo/convert_frame.py:964] [0/41]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.981000 29040 torch/_dynamo/convert_frame.py:964] [0/41]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:05.981000 29040 torch/_dynamo/convert_frame.py:964] [0/41] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.981000 29040 torch/_dynamo/convert_frame.py:964] [0/41] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,982 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
W0905 17:28:05.982000 29043 torch/_dynamo/convert_frame.py:964] [0/153] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:05.982000 29043 torch/_dynamo/convert_frame.py:964] [0/153]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:05.982000 29043 torch/_dynamo/convert_frame.py:964] [0/153]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:05.982000 29043 torch/_dynamo/convert_frame.py:964] [0/153] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:05.982000 29043 torch/_dynamo/convert_frame.py:964] [0/153] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=64, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,983 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,983 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,984 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=65, magnitude=2400.0
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - GPU-7 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,984 - WARNING - Skipping empty response for id=66, magnitude=2400.0
2025-09-05 17:28:05,985 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:05,985 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:05,985 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:05,985 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:05,985 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:05,985 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:05,985 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:05,985 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:05,985 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:05,985 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:05,985 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,985 - INFO - No valid responses to write for this batch
2025-09-05 17:28:05,999 - GPU-4 - INFO - Completed batch 50, total work units processed by this worker: 788
2025-09-05 17:28:05,999 - INFO - Completed batch 50, total work units processed by this worker: 788
2025-09-05 17:28:06,001 - GPU-7 - INFO - Completed batch 92, total work units processed by this worker: 1436
2025-09-05 17:28:06,001 - INFO - Completed batch 92, total work units processed by this worker: 1436
2025-09-05 17:28:07,821 - GPU-0 - INFO - Processing batch 63 (16 work units)
2025-09-05 17:28:07,821 - INFO - Processing batch 63 (16 work units)
2025-09-05 17:28:07,908 - GPU-1 - INFO - Completed batch 51, total work units processed by this worker: 816
2025-09-05 17:28:07,908 - INFO - Completed batch 51, total work units processed by this worker: 816
2025-09-05 17:28:07,909 - GPU-1 - INFO - Processing batch 52 (16 work units)
2025-09-05 17:28:07,909 - INFO - Processing batch 52 (16 work units)
W0905 17:28:07.926000 29036 torch/_dynamo/convert_frame.py:964] [0/90] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:07.926000 29036 torch/_dynamo/convert_frame.py:964] [0/90]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:07.926000 29036 torch/_dynamo/convert_frame.py:964] [0/90]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:07.926000 29036 torch/_dynamo/convert_frame.py:964] [0/90] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:07.926000 29036 torch/_dynamo/convert_frame.py:964] [0/90] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:07,930 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:07,930 - INFO - Falling back to sequential processing
W0905 17:28:07.989000 29036 torch/_dynamo/convert_frame.py:964] [0/91] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:07.989000 29036 torch/_dynamo/convert_frame.py:964] [0/91]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:07.989000 29036 torch/_dynamo/convert_frame.py:964] [0/91]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:07.989000 29036 torch/_dynamo/convert_frame.py:964] [0/91] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:07.989000 29036 torch/_dynamo/convert_frame.py:964] [0/91] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:07,991 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=67, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=68, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=69, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=69, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=2400.0
2025-09-05 17:28:07,991 - WARNING - Skipping empty response for id=69, magnitude=2400.0
2025-09-05 17:28:07,991 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:07,991 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,003 - GPU-0 - INFO - Completed batch 63, total work units processed by this worker: 996
2025-09-05 17:28:08,003 - INFO - Completed batch 63, total work units processed by this worker: 996
2025-09-05 17:28:08,003 - GPU-0 - INFO - Processing batch 64 (16 work units)
2025-09-05 17:28:08,003 - INFO - Processing batch 64 (16 work units)
W0905 17:28:08.098000 29036 torch/_dynamo/convert_frame.py:964] [0/92] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:08.098000 29036 torch/_dynamo/convert_frame.py:964] [0/92]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:08.098000 29036 torch/_dynamo/convert_frame.py:964] [0/92]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:08.098000 29036 torch/_dynamo/convert_frame.py:964] [0/92] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:08.098000 29036 torch/_dynamo/convert_frame.py:964] [0/92] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:08,099 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:08,100 - INFO - Falling back to sequential processing
W0905 17:28:08.152000 29036 torch/_dynamo/convert_frame.py:964] [0/93] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:08.152000 29036 torch/_dynamo/convert_frame.py:964] [0/93]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:08.152000 29036 torch/_dynamo/convert_frame.py:964] [0/93]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:08.152000 29036 torch/_dynamo/convert_frame.py:964] [0/93] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:08.152000 29036 torch/_dynamo/convert_frame.py:964] [0/93] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:08,153 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=71, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - WARNING - Skipping empty response for id=72, magnitude=2400.0
2025-09-05 17:28:08,154 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,154 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,164 - GPU-0 - INFO - Completed batch 64, total work units processed by this worker: 1012
2025-09-05 17:28:08,164 - INFO - Completed batch 64, total work units processed by this worker: 1012
2025-09-05 17:28:08,234 - GPU-2 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:28:08,234 - INFO - Processing batch 23 (16 work units)
2025-09-05 17:28:08,304 - GPU-4 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:28:08,304 - INFO - Processing batch 51 (16 work units)
2025-09-05 17:28:08,333 - GPU-7 - INFO - Processing batch 93 (16 work units)
2025-09-05 17:28:08,333 - INFO - Processing batch 93 (16 work units)
W0905 17:28:08.399000 29040 torch/_dynamo/convert_frame.py:964] [0/42] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:08.399000 29040 torch/_dynamo/convert_frame.py:964] [0/42]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:08.399000 29040 torch/_dynamo/convert_frame.py:964] [0/42]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:08.399000 29040 torch/_dynamo/convert_frame.py:964] [0/42] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:08.399000 29040 torch/_dynamo/convert_frame.py:964] [0/42] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:08,401 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:08,401 - INFO - Falling back to sequential processing
W0905 17:28:08.431000 29043 torch/_dynamo/convert_frame.py:964] [0/154] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:08.431000 29043 torch/_dynamo/convert_frame.py:964] [0/154]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:08.431000 29043 torch/_dynamo/convert_frame.py:964] [0/154]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:08.431000 29043 torch/_dynamo/convert_frame.py:964] [0/154] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:08.431000 29043 torch/_dynamo/convert_frame.py:964] [0/154] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:08,433 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:08,433 - INFO - Falling back to sequential processing
W0905 17:28:08.456000 29040 torch/_dynamo/convert_frame.py:964] [0/43] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:08.456000 29040 torch/_dynamo/convert_frame.py:964] [0/43]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:08.456000 29040 torch/_dynamo/convert_frame.py:964] [0/43]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:08.456000 29040 torch/_dynamo/convert_frame.py:964] [0/43] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:08.456000 29040 torch/_dynamo/convert_frame.py:964] [0/43] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:08,458 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=74, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=74, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=74, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=74, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=74, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=74, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=75, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,458 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,458 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,458 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,469 - GPU-4 - INFO - Completed batch 51, total work units processed by this worker: 804
2025-09-05 17:28:08,469 - INFO - Completed batch 51, total work units processed by this worker: 804
2025-09-05 17:28:08,469 - GPU-4 - INFO - Processing batch 52 (16 work units)
2025-09-05 17:28:08,469 - INFO - Processing batch 52 (16 work units)
W0905 17:28:08.488000 29043 torch/_dynamo/convert_frame.py:964] [0/155] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:08.488000 29043 torch/_dynamo/convert_frame.py:964] [0/155]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:08.488000 29043 torch/_dynamo/convert_frame.py:964] [0/155]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:08.488000 29043 torch/_dynamo/convert_frame.py:964] [0/155] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:08.488000 29043 torch/_dynamo/convert_frame.py:964] [0/155] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:08,490 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=76, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=77, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,490 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,490 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,490 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,497 - GPU-6 - INFO - Completed batch 53, total work units processed by this worker: 836
2025-09-05 17:28:08,497 - INFO - Completed batch 53, total work units processed by this worker: 836
2025-09-05 17:28:08,498 - GPU-6 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:28:08,498 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:28:08,506 - GPU-7 - INFO - Completed batch 93, total work units processed by this worker: 1452
2025-09-05 17:28:08,506 - INFO - Completed batch 93, total work units processed by this worker: 1452
2025-09-05 17:28:08,506 - GPU-7 - INFO - Processing batch 94 (16 work units)
2025-09-05 17:28:08,506 - INFO - Processing batch 94 (16 work units)
W0905 17:28:08.561000 29040 torch/_dynamo/convert_frame.py:964] [0/44] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:08.561000 29040 torch/_dynamo/convert_frame.py:964] [0/44]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:08.561000 29040 torch/_dynamo/convert_frame.py:964] [0/44]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:08.561000 29040 torch/_dynamo/convert_frame.py:964] [0/44] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:08.561000 29040 torch/_dynamo/convert_frame.py:964] [0/44] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:08,563 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:08,563 - INFO - Falling back to sequential processing
W0905 17:28:08.604000 29043 torch/_dynamo/convert_frame.py:964] [0/156] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:08.604000 29043 torch/_dynamo/convert_frame.py:964] [0/156]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:08.604000 29043 torch/_dynamo/convert_frame.py:964] [0/156]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:08.604000 29043 torch/_dynamo/convert_frame.py:964] [0/156] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:08.604000 29043 torch/_dynamo/convert_frame.py:964] [0/156] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:08,606 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:08,606 - INFO - Falling back to sequential processing
W0905 17:28:08.617000 29040 torch/_dynamo/convert_frame.py:964] [0/45] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:08.617000 29040 torch/_dynamo/convert_frame.py:964] [0/45]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:08.617000 29040 torch/_dynamo/convert_frame.py:964] [0/45]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:08.617000 29040 torch/_dynamo/convert_frame.py:964] [0/45] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:08.617000 29040 torch/_dynamo/convert_frame.py:964] [0/45] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:08,618 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=78, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - WARNING - Skipping empty response for id=79, magnitude=2400.0
2025-09-05 17:28:08,619 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,619 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,630 - GPU-4 - INFO - Completed batch 52, total work units processed by this worker: 820
2025-09-05 17:28:08,630 - INFO - Completed batch 52, total work units processed by this worker: 820
W0905 17:28:08.661000 29043 torch/_dynamo/convert_frame.py:964] [0/157] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:08.661000 29043 torch/_dynamo/convert_frame.py:964] [0/157]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:08.661000 29043 torch/_dynamo/convert_frame.py:964] [0/157]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:08.661000 29043 torch/_dynamo/convert_frame.py:964] [0/157] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:08.661000 29043 torch/_dynamo/convert_frame.py:964] [0/157] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:08,663 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=81, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=81, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=82, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:08,663 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:08,663 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,663 - INFO - No valid responses to write for this batch
2025-09-05 17:28:08,674 - GPU-7 - INFO - Completed batch 94, total work units processed by this worker: 1468
2025-09-05 17:28:08,674 - INFO - Completed batch 94, total work units processed by this worker: 1468
2025-09-05 17:28:10,340 - GPU-0 - INFO - Processing batch 65 (16 work units)
2025-09-05 17:28:10,340 - INFO - Processing batch 65 (16 work units)
W0905 17:28:10.442000 29036 torch/_dynamo/convert_frame.py:964] [0/94] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:10.442000 29036 torch/_dynamo/convert_frame.py:964] [0/94]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:10.442000 29036 torch/_dynamo/convert_frame.py:964] [0/94]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:10.442000 29036 torch/_dynamo/convert_frame.py:964] [0/94] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:10.442000 29036 torch/_dynamo/convert_frame.py:964] [0/94] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:10,444 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:10,444 - INFO - Falling back to sequential processing
W0905 17:28:10.496000 29036 torch/_dynamo/convert_frame.py:964] [0/95] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:10.496000 29036 torch/_dynamo/convert_frame.py:964] [0/95]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:10.496000 29036 torch/_dynamo/convert_frame.py:964] [0/95]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:10.496000 29036 torch/_dynamo/convert_frame.py:964] [0/95] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:10.496000 29036 torch/_dynamo/convert_frame.py:964] [0/95] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:10,498 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:10,498 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:10,498 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:10,498 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:10,498 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=83, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=84, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,499 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,499 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:10,499 - INFO - No valid responses to write for this batch
2025-09-05 17:28:10,509 - GPU-0 - INFO - Completed batch 65, total work units processed by this worker: 1028
2025-09-05 17:28:10,509 - INFO - Completed batch 65, total work units processed by this worker: 1028
2025-09-05 17:28:10,509 - GPU-0 - INFO - Processing batch 66 (16 work units)
2025-09-05 17:28:10,509 - INFO - Processing batch 66 (16 work units)
W0905 17:28:10.608000 29036 torch/_dynamo/convert_frame.py:964] [0/96] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:10.608000 29036 torch/_dynamo/convert_frame.py:964] [0/96]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:10.608000 29036 torch/_dynamo/convert_frame.py:964] [0/96]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:10.608000 29036 torch/_dynamo/convert_frame.py:964] [0/96] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:10.608000 29036 torch/_dynamo/convert_frame.py:964] [0/96] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:10,610 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:10,610 - INFO - Falling back to sequential processing
W0905 17:28:10.662000 29036 torch/_dynamo/convert_frame.py:964] [0/97] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:10.662000 29036 torch/_dynamo/convert_frame.py:964] [0/97]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:10.662000 29036 torch/_dynamo/convert_frame.py:964] [0/97]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:10.662000 29036 torch/_dynamo/convert_frame.py:964] [0/97] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:10.662000 29036 torch/_dynamo/convert_frame.py:964] [0/97] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:10,664 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=85, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=86, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:10,664 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:10,664 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:10,664 - INFO - No valid responses to write for this batch
2025-09-05 17:28:10,674 - GPU-0 - INFO - Completed batch 66, total work units processed by this worker: 1044
2025-09-05 17:28:10,674 - INFO - Completed batch 66, total work units processed by this worker: 1044
2025-09-05 17:28:10,933 - GPU-4 - INFO - Processing batch 53 (16 work units)
2025-09-05 17:28:10,933 - INFO - Processing batch 53 (16 work units)
2025-09-05 17:28:10,982 - GPU-7 - INFO - Processing batch 95 (16 work units)
2025-09-05 17:28:10,982 - INFO - Processing batch 95 (16 work units)
W0905 17:28:11.034000 29040 torch/_dynamo/convert_frame.py:964] [0/46] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:11.034000 29040 torch/_dynamo/convert_frame.py:964] [0/46]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:11.034000 29040 torch/_dynamo/convert_frame.py:964] [0/46]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:11.034000 29040 torch/_dynamo/convert_frame.py:964] [0/46] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:11.034000 29040 torch/_dynamo/convert_frame.py:964] [0/46] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:11,036 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:11,036 - INFO - Falling back to sequential processing
W0905 17:28:11.083000 29043 torch/_dynamo/convert_frame.py:964] [0/158] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:11.083000 29043 torch/_dynamo/convert_frame.py:964] [0/158]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:11.083000 29043 torch/_dynamo/convert_frame.py:964] [0/158]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:11.083000 29043 torch/_dynamo/convert_frame.py:964] [0/158] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:11.083000 29043 torch/_dynamo/convert_frame.py:964] [0/158] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:11,085 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:11,085 - INFO - Falling back to sequential processing
W0905 17:28:11.091000 29040 torch/_dynamo/convert_frame.py:964] [0/47] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:11.091000 29040 torch/_dynamo/convert_frame.py:964] [0/47]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:11.091000 29040 torch/_dynamo/convert_frame.py:964] [0/47]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:11.091000 29040 torch/_dynamo/convert_frame.py:964] [0/47] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:11.091000 29040 torch/_dynamo/convert_frame.py:964] [0/47] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:11,093 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=87, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,093 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:11,093 - INFO - No valid responses to write for this batch
2025-09-05 17:28:11,104 - GPU-4 - INFO - Completed batch 53, total work units processed by this worker: 836
2025-09-05 17:28:11,104 - INFO - Completed batch 53, total work units processed by this worker: 836
2025-09-05 17:28:11,104 - GPU-4 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:28:11,104 - INFO - Processing batch 54 (16 work units)
W0905 17:28:11.140000 29043 torch/_dynamo/convert_frame.py:964] [0/159] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:11.140000 29043 torch/_dynamo/convert_frame.py:964] [0/159]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:11.140000 29043 torch/_dynamo/convert_frame.py:964] [0/159]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:11.140000 29043 torch/_dynamo/convert_frame.py:964] [0/159] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:11.140000 29043 torch/_dynamo/convert_frame.py:964] [0/159] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:11,142 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:11,142 - GPU-7 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,142 - WARNING - Skipping empty response for id=88, magnitude=2400.0
2025-09-05 17:28:11,142 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,142 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,142 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,142 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,142 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,142 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,142 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,142 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=89, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,143 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:11,143 - INFO - No valid responses to write for this batch
2025-09-05 17:28:11,154 - GPU-7 - INFO - Completed batch 95, total work units processed by this worker: 1484
2025-09-05 17:28:11,154 - INFO - Completed batch 95, total work units processed by this worker: 1484
2025-09-05 17:28:11,154 - GPU-7 - INFO - Processing batch 96 (16 work units)
2025-09-05 17:28:11,154 - INFO - Processing batch 96 (16 work units)
W0905 17:28:11.204000 29040 torch/_dynamo/convert_frame.py:964] [0/48] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:11.204000 29040 torch/_dynamo/convert_frame.py:964] [0/48]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:11.204000 29040 torch/_dynamo/convert_frame.py:964] [0/48]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:11.204000 29040 torch/_dynamo/convert_frame.py:964] [0/48] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:11.204000 29040 torch/_dynamo/convert_frame.py:964] [0/48] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:11,206 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:11,206 - INFO - Falling back to sequential processing
W0905 17:28:11.260000 29040 torch/_dynamo/convert_frame.py:964] [0/49] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:11.260000 29040 torch/_dynamo/convert_frame.py:964] [0/49]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:11.260000 29040 torch/_dynamo/convert_frame.py:964] [0/49]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:11.260000 29040 torch/_dynamo/convert_frame.py:964] [0/49] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:11.260000 29040 torch/_dynamo/convert_frame.py:964] [0/49] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
W0905 17:28:11.261000 29043 torch/_dynamo/convert_frame.py:964] [0/160] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:11.261000 29043 torch/_dynamo/convert_frame.py:964] [0/160]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:11.261000 29043 torch/_dynamo/convert_frame.py:964] [0/160]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:11.261000 29043 torch/_dynamo/convert_frame.py:964] [0/160] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:11.261000 29043 torch/_dynamo/convert_frame.py:964] [0/160] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:11,262 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=90, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=91, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,262 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,262 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:11,262 - INFO - No valid responses to write for this batch
2025-09-05 17:28:11,263 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:11,263 - INFO - Falling back to sequential processing
2025-09-05 17:28:11,273 - GPU-4 - INFO - Completed batch 54, total work units processed by this worker: 852
2025-09-05 17:28:11,273 - INFO - Completed batch 54, total work units processed by this worker: 852
W0905 17:28:11.318000 29043 torch/_dynamo/convert_frame.py:964] [0/161] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:11.318000 29043 torch/_dynamo/convert_frame.py:964] [0/161]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:11.318000 29043 torch/_dynamo/convert_frame.py:964] [0/161]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:11.318000 29043 torch/_dynamo/convert_frame.py:964] [0/161] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:11.318000 29043 torch/_dynamo/convert_frame.py:964] [0/161] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:11,319 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=92, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=93, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:11,320 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:11,320 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:11,320 - INFO - No valid responses to write for this batch
2025-09-05 17:28:11,331 - GPU-7 - INFO - Completed batch 96, total work units processed by this worker: 1500
2025-09-05 17:28:11,331 - INFO - Completed batch 96, total work units processed by this worker: 1500
2025-09-05 17:28:12,830 - GPU-0 - INFO - Processing batch 67 (16 work units)
2025-09-05 17:28:12,830 - INFO - Processing batch 67 (16 work units)
W0905 17:28:12.940000 29036 torch/_dynamo/convert_frame.py:964] [0/98] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:12.940000 29036 torch/_dynamo/convert_frame.py:964] [0/98]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:12.940000 29036 torch/_dynamo/convert_frame.py:964] [0/98]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:12.940000 29036 torch/_dynamo/convert_frame.py:964] [0/98] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:12.940000 29036 torch/_dynamo/convert_frame.py:964] [0/98] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:12,942 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:12,942 - INFO - Falling back to sequential processing
W0905 17:28:12.994000 29036 torch/_dynamo/convert_frame.py:964] [0/99] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:12.994000 29036 torch/_dynamo/convert_frame.py:964] [0/99]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:12.994000 29036 torch/_dynamo/convert_frame.py:964] [0/99]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:12.994000 29036 torch/_dynamo/convert_frame.py:964] [0/99] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:12.994000 29036 torch/_dynamo/convert_frame.py:964] [0/99] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:12,996 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=94, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,996 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,997 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,997 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,997 - GPU-0 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,997 - WARNING - Skipping empty response for id=95, magnitude=2400.0
2025-09-05 17:28:12,997 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:12,997 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,007 - GPU-0 - INFO - Completed batch 67, total work units processed by this worker: 1060
2025-09-05 17:28:13,007 - INFO - Completed batch 67, total work units processed by this worker: 1060
2025-09-05 17:28:13,007 - GPU-0 - INFO - Processing batch 68 (16 work units)
2025-09-05 17:28:13,007 - INFO - Processing batch 68 (16 work units)
W0905 17:28:13.113000 29036 torch/_dynamo/convert_frame.py:964] [0/100] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:13.113000 29036 torch/_dynamo/convert_frame.py:964] [0/100]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:13.113000 29036 torch/_dynamo/convert_frame.py:964] [0/100]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:13.113000 29036 torch/_dynamo/convert_frame.py:964] [0/100] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:13.113000 29036 torch/_dynamo/convert_frame.py:964] [0/100] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:13,115 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:13,115 - INFO - Falling back to sequential processing
W0905 17:28:13.167000 29036 torch/_dynamo/convert_frame.py:964] [0/101] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:13.167000 29036 torch/_dynamo/convert_frame.py:964] [0/101]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:13.167000 29036 torch/_dynamo/convert_frame.py:964] [0/101]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:13.167000 29036 torch/_dynamo/convert_frame.py:964] [0/101] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:13.167000 29036 torch/_dynamo/convert_frame.py:964] [0/101] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:13,169 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=96, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - WARNING - Skipping empty response for id=97, magnitude=2400.0
2025-09-05 17:28:13,169 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,169 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,179 - GPU-0 - INFO - Completed batch 68, total work units processed by this worker: 1076
2025-09-05 17:28:13,179 - INFO - Completed batch 68, total work units processed by this worker: 1076
2025-09-05 17:28:13,474 - GPU-5 - INFO - Completed batch 55, total work units processed by this worker: 880
2025-09-05 17:28:13,474 - INFO - Completed batch 55, total work units processed by this worker: 880
2025-09-05 17:28:13,474 - GPU-5 - INFO - Processing batch 56 (16 work units)
2025-09-05 17:28:13,474 - INFO - Processing batch 56 (16 work units)
2025-09-05 17:28:13,574 - GPU-4 - INFO - Processing batch 55 (4 work units)
2025-09-05 17:28:13,574 - INFO - Processing batch 55 (4 work units)
W0905 17:28:13.637000 29040 torch/_dynamo/convert_frame.py:964] [0/50] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:13.637000 29040 torch/_dynamo/convert_frame.py:964] [0/50]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:13.637000 29040 torch/_dynamo/convert_frame.py:964] [0/50]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:13.637000 29040 torch/_dynamo/convert_frame.py:964] [0/50] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:13.637000 29040 torch/_dynamo/convert_frame.py:964] [0/50] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:13,638 - GPU-7 - INFO - Processing batch 97 (16 work units)
2025-09-05 17:28:13,638 - INFO - Processing batch 97 (16 work units)
2025-09-05 17:28:13,639 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:13,639 - INFO - Falling back to sequential processing
W0905 17:28:13.699000 29040 torch/_dynamo/convert_frame.py:964] [0/51] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:13.699000 29040 torch/_dynamo/convert_frame.py:964] [0/51]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:13.699000 29040 torch/_dynamo/convert_frame.py:964] [0/51]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:13.699000 29040 torch/_dynamo/convert_frame.py:964] [0/51] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:13.699000 29040 torch/_dynamo/convert_frame.py:964] [0/51] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:13,700 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:13,701 - GPU-4 - WARNING - Skipping empty response for id=99, magnitude=2400.0
2025-09-05 17:28:13,701 - WARNING - Skipping empty response for id=99, magnitude=2400.0
2025-09-05 17:28:13,701 - GPU-4 - WARNING - Skipping empty response for id=99, magnitude=2400.0
2025-09-05 17:28:13,701 - WARNING - Skipping empty response for id=99, magnitude=2400.0
2025-09-05 17:28:13,701 - GPU-4 - WARNING - Skipping empty response for id=99, magnitude=2400.0
2025-09-05 17:28:13,701 - WARNING - Skipping empty response for id=99, magnitude=2400.0
2025-09-05 17:28:13,701 - GPU-4 - WARNING - Skipping empty response for id=99, magnitude=2400.0
2025-09-05 17:28:13,701 - WARNING - Skipping empty response for id=99, magnitude=2400.0
2025-09-05 17:28:13,701 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,701 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,702 - GPU-4 - INFO - Completed batch 55, total work units processed by this worker: 856
2025-09-05 17:28:13,702 - INFO - Completed batch 55, total work units processed by this worker: 856
2025-09-05 17:28:13,702 - GPU-4 - INFO - Processing batch 56 (16 work units)
2025-09-05 17:28:13,702 - INFO - Processing batch 56 (16 work units)
W0905 17:28:13.729000 29043 torch/_dynamo/convert_frame.py:964] [0/162] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:13.729000 29043 torch/_dynamo/convert_frame.py:964] [0/162]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:13.729000 29043 torch/_dynamo/convert_frame.py:964] [0/162]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:13.729000 29043 torch/_dynamo/convert_frame.py:964] [0/162] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:13.729000 29043 torch/_dynamo/convert_frame.py:964] [0/162] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:13,731 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:13,731 - INFO - Falling back to sequential processing
W0905 17:28:13.790000 29040 torch/_dynamo/convert_frame.py:964] [0/52] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:13.790000 29040 torch/_dynamo/convert_frame.py:964] [0/52]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:13.790000 29040 torch/_dynamo/convert_frame.py:964] [0/52]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:13.790000 29040 torch/_dynamo/convert_frame.py:964] [0/52] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:13.790000 29040 torch/_dynamo/convert_frame.py:964] [0/52] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:13,791 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:13,791 - INFO - Falling back to sequential processing
W0905 17:28:13.792000 29043 torch/_dynamo/convert_frame.py:964] [0/163] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:13.792000 29043 torch/_dynamo/convert_frame.py:964] [0/163]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:13.792000 29043 torch/_dynamo/convert_frame.py:964] [0/163]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:13.792000 29043 torch/_dynamo/convert_frame.py:964] [0/163] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:13.792000 29043 torch/_dynamo/convert_frame.py:964] [0/163] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:13,794 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=0, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,795 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,795 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,806 - GPU-7 - INFO - Completed batch 97, total work units processed by this worker: 1516
2025-09-05 17:28:13,806 - INFO - Completed batch 97, total work units processed by this worker: 1516
2025-09-05 17:28:13,806 - GPU-7 - INFO - Processing batch 98 (16 work units)
2025-09-05 17:28:13,806 - INFO - Processing batch 98 (16 work units)
W0905 17:28:13.845000 29040 torch/_dynamo/convert_frame.py:964] [0/53] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:13.845000 29040 torch/_dynamo/convert_frame.py:964] [0/53]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:13.845000 29040 torch/_dynamo/convert_frame.py:964] [0/53]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:13.845000 29040 torch/_dynamo/convert_frame.py:964] [0/53] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:13.845000 29040 torch/_dynamo/convert_frame.py:964] [0/53] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:13,847 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=1, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=2, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,847 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,847 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,847 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,862 - GPU-4 - INFO - Completed batch 56, total work units processed by this worker: 872
2025-09-05 17:28:13,862 - INFO - Completed batch 56, total work units processed by this worker: 872
W0905 17:28:13.902000 29043 torch/_dynamo/convert_frame.py:964] [0/164] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:13.902000 29043 torch/_dynamo/convert_frame.py:964] [0/164]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:13.902000 29043 torch/_dynamo/convert_frame.py:964] [0/164]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:13.902000 29043 torch/_dynamo/convert_frame.py:964] [0/164] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:13.902000 29043 torch/_dynamo/convert_frame.py:964] [0/164] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:13,903 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:13,904 - INFO - Falling back to sequential processing
W0905 17:28:13.958000 29043 torch/_dynamo/convert_frame.py:964] [0/165] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:13.958000 29043 torch/_dynamo/convert_frame.py:964] [0/165]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:13.958000 29043 torch/_dynamo/convert_frame.py:964] [0/165]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:13.958000 29043 torch/_dynamo/convert_frame.py:964] [0/165] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:13.958000 29043 torch/_dynamo/convert_frame.py:964] [0/165] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:13,960 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=3, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=4, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:13,960 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:13,960 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,960 - INFO - No valid responses to write for this batch
2025-09-05 17:28:13,971 - GPU-7 - INFO - Completed batch 98, total work units processed by this worker: 1532
2025-09-05 17:28:13,971 - INFO - Completed batch 98, total work units processed by this worker: 1532
2025-09-05 17:28:15,339 - GPU-0 - INFO - Processing batch 69 (16 work units)
2025-09-05 17:28:15,339 - INFO - Processing batch 69 (16 work units)
W0905 17:28:15.442000 29036 torch/_dynamo/convert_frame.py:964] [0/102] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:15.442000 29036 torch/_dynamo/convert_frame.py:964] [0/102]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:15.442000 29036 torch/_dynamo/convert_frame.py:964] [0/102]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:15.442000 29036 torch/_dynamo/convert_frame.py:964] [0/102] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:15.442000 29036 torch/_dynamo/convert_frame.py:964] [0/102] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:15,443 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:15,444 - INFO - Falling back to sequential processing
W0905 17:28:15.496000 29036 torch/_dynamo/convert_frame.py:964] [0/103] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:15.496000 29036 torch/_dynamo/convert_frame.py:964] [0/103]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:15.496000 29036 torch/_dynamo/convert_frame.py:964] [0/103]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:15.496000 29036 torch/_dynamo/convert_frame.py:964] [0/103] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:15.496000 29036 torch/_dynamo/convert_frame.py:964] [0/103] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:15,498 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=5, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=6, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,498 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,498 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:15,498 - INFO - No valid responses to write for this batch
2025-09-05 17:28:15,509 - GPU-0 - INFO - Completed batch 69, total work units processed by this worker: 1092
2025-09-05 17:28:15,509 - INFO - Completed batch 69, total work units processed by this worker: 1092
2025-09-05 17:28:15,509 - GPU-0 - INFO - Processing batch 70 (16 work units)
2025-09-05 17:28:15,509 - INFO - Processing batch 70 (16 work units)
W0905 17:28:15.608000 29036 torch/_dynamo/convert_frame.py:964] [0/104] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:15.608000 29036 torch/_dynamo/convert_frame.py:964] [0/104]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:15.608000 29036 torch/_dynamo/convert_frame.py:964] [0/104]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:15.608000 29036 torch/_dynamo/convert_frame.py:964] [0/104] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:15.608000 29036 torch/_dynamo/convert_frame.py:964] [0/104] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:15,610 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:15,610 - INFO - Falling back to sequential processing
W0905 17:28:15.662000 29036 torch/_dynamo/convert_frame.py:964] [0/105] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:15.662000 29036 torch/_dynamo/convert_frame.py:964] [0/105]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:15.662000 29036 torch/_dynamo/convert_frame.py:964] [0/105]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:15.662000 29036 torch/_dynamo/convert_frame.py:964] [0/105] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:15.662000 29036 torch/_dynamo/convert_frame.py:964] [0/105] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:15,663 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=7, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:15,664 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:15,664 - INFO - No valid responses to write for this batch
2025-09-05 17:28:15,674 - GPU-0 - INFO - Completed batch 70, total work units processed by this worker: 1108
2025-09-05 17:28:15,674 - INFO - Completed batch 70, total work units processed by this worker: 1108
2025-09-05 17:28:16,164 - GPU-4 - INFO - Processing batch 57 (16 work units)
2025-09-05 17:28:16,164 - INFO - Processing batch 57 (16 work units)
2025-09-05 17:28:16,259 - GPU-7 - INFO - Processing batch 99 (16 work units)
2025-09-05 17:28:16,259 - INFO - Processing batch 99 (16 work units)
W0905 17:28:16.261000 29040 torch/_dynamo/convert_frame.py:964] [0/54] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:16.261000 29040 torch/_dynamo/convert_frame.py:964] [0/54]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:16.261000 29040 torch/_dynamo/convert_frame.py:964] [0/54]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:16.261000 29040 torch/_dynamo/convert_frame.py:964] [0/54] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:16.261000 29040 torch/_dynamo/convert_frame.py:964] [0/54] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:16,263 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:16,263 - INFO - Falling back to sequential processing
W0905 17:28:16.318000 29040 torch/_dynamo/convert_frame.py:964] [0/55] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:16.318000 29040 torch/_dynamo/convert_frame.py:964] [0/55]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:16.318000 29040 torch/_dynamo/convert_frame.py:964] [0/55]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:16.318000 29040 torch/_dynamo/convert_frame.py:964] [0/55] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:16.318000 29040 torch/_dynamo/convert_frame.py:964] [0/55] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:16,320 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=8, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=9, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,320 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:16,320 - INFO - No valid responses to write for this batch
2025-09-05 17:28:16,331 - GPU-4 - INFO - Completed batch 57, total work units processed by this worker: 888
2025-09-05 17:28:16,331 - INFO - Completed batch 57, total work units processed by this worker: 888
2025-09-05 17:28:16,331 - GPU-4 - INFO - Processing batch 58 (16 work units)
2025-09-05 17:28:16,331 - INFO - Processing batch 58 (16 work units)
W0905 17:28:16.357000 29043 torch/_dynamo/convert_frame.py:964] [0/166] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:16.357000 29043 torch/_dynamo/convert_frame.py:964] [0/166]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:16.357000 29043 torch/_dynamo/convert_frame.py:964] [0/166]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:16.357000 29043 torch/_dynamo/convert_frame.py:964] [0/166] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:16.357000 29043 torch/_dynamo/convert_frame.py:964] [0/166] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:16,359 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:16,359 - INFO - Falling back to sequential processing
W0905 17:28:16.413000 29043 torch/_dynamo/convert_frame.py:964] [0/167] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:16.413000 29043 torch/_dynamo/convert_frame.py:964] [0/167]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:16.413000 29043 torch/_dynamo/convert_frame.py:964] [0/167]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:16.413000 29043 torch/_dynamo/convert_frame.py:964] [0/167] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:16.413000 29043 torch/_dynamo/convert_frame.py:964] [0/167] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:16,415 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=10, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=11, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,416 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,416 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:16,416 - INFO - No valid responses to write for this batch
2025-09-05 17:28:16,427 - GPU-7 - INFO - Completed batch 99, total work units processed by this worker: 1548
2025-09-05 17:28:16,427 - INFO - Completed batch 99, total work units processed by this worker: 1548
2025-09-05 17:28:16,427 - GPU-7 - INFO - Processing batch 100 (16 work units)
2025-09-05 17:28:16,427 - INFO - Processing batch 100 (16 work units)
W0905 17:28:16.430000 29040 torch/_dynamo/convert_frame.py:964] [0/56] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:16.430000 29040 torch/_dynamo/convert_frame.py:964] [0/56]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:16.430000 29040 torch/_dynamo/convert_frame.py:964] [0/56]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:16.430000 29040 torch/_dynamo/convert_frame.py:964] [0/56] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:16.430000 29040 torch/_dynamo/convert_frame.py:964] [0/56] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:16,432 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:16,432 - INFO - Falling back to sequential processing
W0905 17:28:16.486000 29040 torch/_dynamo/convert_frame.py:964] [0/57] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:16.486000 29040 torch/_dynamo/convert_frame.py:964] [0/57]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:16.486000 29040 torch/_dynamo/convert_frame.py:964] [0/57]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:16.486000 29040 torch/_dynamo/convert_frame.py:964] [0/57] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:16.486000 29040 torch/_dynamo/convert_frame.py:964] [0/57] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:16,487 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=12, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=13, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,488 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,488 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:16,488 - INFO - No valid responses to write for this batch
2025-09-05 17:28:16,503 - GPU-4 - INFO - Completed batch 58, total work units processed by this worker: 904
2025-09-05 17:28:16,503 - INFO - Completed batch 58, total work units processed by this worker: 904
2025-09-05 17:28:16,504 - GPU-1 - INFO - Completed batch 52, total work units processed by this worker: 832
2025-09-05 17:28:16,504 - INFO - Completed batch 52, total work units processed by this worker: 832
W0905 17:28:16.527000 29043 torch/_dynamo/convert_frame.py:964] [0/168] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:16.527000 29043 torch/_dynamo/convert_frame.py:964] [0/168]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:16.527000 29043 torch/_dynamo/convert_frame.py:964] [0/168]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:16.527000 29043 torch/_dynamo/convert_frame.py:964] [0/168] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:16.527000 29043 torch/_dynamo/convert_frame.py:964] [0/168] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:16,528 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:16,528 - INFO - Falling back to sequential processing
W0905 17:28:16.583000 29043 torch/_dynamo/convert_frame.py:964] [0/169] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:16.583000 29043 torch/_dynamo/convert_frame.py:964] [0/169]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:16.583000 29043 torch/_dynamo/convert_frame.py:964] [0/169]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:16.583000 29043 torch/_dynamo/convert_frame.py:964] [0/169] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:16.583000 29043 torch/_dynamo/convert_frame.py:964] [0/169] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:16,585 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:16,585 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - GPU-7 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - WARNING - Skipping empty response for id=14, magnitude=2800.0
2025-09-05 17:28:16,585 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,585 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,585 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,585 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,585 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,585 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - GPU-7 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - WARNING - Skipping empty response for id=15, magnitude=2800.0
2025-09-05 17:28:16,586 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:16,586 - INFO - No valid responses to write for this batch
2025-09-05 17:28:16,597 - GPU-7 - INFO - Completed batch 100, total work units processed by this worker: 1564
2025-09-05 17:28:16,597 - INFO - Completed batch 100, total work units processed by this worker: 1564
2025-09-05 17:28:16,677 - GPU-2 - INFO - Completed batch 23, total work units processed by this worker: 356
2025-09-05 17:28:16,677 - INFO - Completed batch 23, total work units processed by this worker: 356
2025-09-05 17:28:16,678 - GPU-2 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:28:16,678 - INFO - Processing batch 24 (16 work units)
2025-09-05 17:28:18,029 - GPU-0 - INFO - Processing batch 71 (16 work units)
2025-09-05 17:28:18,029 - INFO - Processing batch 71 (16 work units)
2025-09-05 17:28:18,051 - GPU-3 - INFO - Completed batch 52, total work units processed by this worker: 832
2025-09-05 17:28:18,051 - INFO - Completed batch 52, total work units processed by this worker: 832
2025-09-05 17:28:18,087 - GPU-1 - INFO - Processing batch 53 (16 work units)
2025-09-05 17:28:18,087 - INFO - Processing batch 53 (16 work units)
W0905 17:28:18.126000 29036 torch/_dynamo/convert_frame.py:964] [0/106] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:18.126000 29036 torch/_dynamo/convert_frame.py:964] [0/106]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:18.126000 29036 torch/_dynamo/convert_frame.py:964] [0/106]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:18.126000 29036 torch/_dynamo/convert_frame.py:964] [0/106] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:18.126000 29036 torch/_dynamo/convert_frame.py:964] [0/106] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:18,128 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:18,128 - INFO - Falling back to sequential processing
W0905 17:28:18.181000 29036 torch/_dynamo/convert_frame.py:964] [0/107] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:18.181000 29036 torch/_dynamo/convert_frame.py:964] [0/107]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:18.181000 29036 torch/_dynamo/convert_frame.py:964] [0/107]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:18.181000 29036 torch/_dynamo/convert_frame.py:964] [0/107] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:18.181000 29036 torch/_dynamo/convert_frame.py:964] [0/107] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:18,182 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=17, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=17, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=17, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=18, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=19, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=19, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=19, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=19, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=19, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=19, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=19, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=19, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - WARNING - Skipping empty response for id=19, magnitude=2800.0
2025-09-05 17:28:18,183 - WARNING - Skipping empty response for id=19, magnitude=2800.0
2025-09-05 17:28:18,183 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:18,183 - INFO - No valid responses to write for this batch
2025-09-05 17:28:18,193 - GPU-0 - INFO - Completed batch 71, total work units processed by this worker: 1124
2025-09-05 17:28:18,193 - INFO - Completed batch 71, total work units processed by this worker: 1124
2025-09-05 17:28:18,194 - GPU-0 - INFO - Processing batch 72 (16 work units)
2025-09-05 17:28:18,194 - INFO - Processing batch 72 (16 work units)
W0905 17:28:18.288000 29036 torch/_dynamo/convert_frame.py:964] [0/108] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:18.288000 29036 torch/_dynamo/convert_frame.py:964] [0/108]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:18.288000 29036 torch/_dynamo/convert_frame.py:964] [0/108]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:18.288000 29036 torch/_dynamo/convert_frame.py:964] [0/108] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:18.288000 29036 torch/_dynamo/convert_frame.py:964] [0/108] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:18,290 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:18,290 - INFO - Falling back to sequential processing
W0905 17:28:18.342000 29036 torch/_dynamo/convert_frame.py:964] [0/109] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:18.342000 29036 torch/_dynamo/convert_frame.py:964] [0/109]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:18.342000 29036 torch/_dynamo/convert_frame.py:964] [0/109]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:18.342000 29036 torch/_dynamo/convert_frame.py:964] [0/109] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:18.342000 29036 torch/_dynamo/convert_frame.py:964] [0/109] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:18,344 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=21, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=22, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:18,344 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:18,344 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:18,344 - INFO - No valid responses to write for this batch
2025-09-05 17:28:18,377 - GPU-0 - INFO - Completed batch 72, total work units processed by this worker: 1140
2025-09-05 17:28:18,377 - INFO - Completed batch 72, total work units processed by this worker: 1140
2025-09-05 17:28:18,848 - GPU-4 - INFO - Processing batch 59 (16 work units)
2025-09-05 17:28:18,848 - INFO - Processing batch 59 (16 work units)
W0905 17:28:18.945000 29040 torch/_dynamo/convert_frame.py:964] [0/58] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:18.945000 29040 torch/_dynamo/convert_frame.py:964] [0/58]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:18.945000 29040 torch/_dynamo/convert_frame.py:964] [0/58]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:18.945000 29040 torch/_dynamo/convert_frame.py:964] [0/58] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:18.945000 29040 torch/_dynamo/convert_frame.py:964] [0/58] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:18,947 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:18,947 - INFO - Falling back to sequential processing
2025-09-05 17:28:18,968 - GPU-7 - INFO - Processing batch 101 (16 work units)
2025-09-05 17:28:18,968 - INFO - Processing batch 101 (16 work units)
W0905 17:28:19.003000 29040 torch/_dynamo/convert_frame.py:964] [0/59] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:19.003000 29040 torch/_dynamo/convert_frame.py:964] [0/59]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:19.003000 29040 torch/_dynamo/convert_frame.py:964] [0/59]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:19.003000 29040 torch/_dynamo/convert_frame.py:964] [0/59] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:19.003000 29040 torch/_dynamo/convert_frame.py:964] [0/59] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:19,005 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=23, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,005 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:19,005 - INFO - No valid responses to write for this batch
2025-09-05 17:28:19,017 - GPU-4 - INFO - Completed batch 59, total work units processed by this worker: 920
2025-09-05 17:28:19,017 - INFO - Completed batch 59, total work units processed by this worker: 920
2025-09-05 17:28:19,017 - GPU-4 - INFO - Processing batch 60 (16 work units)
2025-09-05 17:28:19,017 - INFO - Processing batch 60 (16 work units)
W0905 17:28:19.071000 29043 torch/_dynamo/convert_frame.py:964] [0/170] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:19.071000 29043 torch/_dynamo/convert_frame.py:964] [0/170]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:19.071000 29043 torch/_dynamo/convert_frame.py:964] [0/170]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:19.071000 29043 torch/_dynamo/convert_frame.py:964] [0/170] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:19.071000 29043 torch/_dynamo/convert_frame.py:964] [0/170] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:19,073 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:19,073 - INFO - Falling back to sequential processing
W0905 17:28:19.116000 29040 torch/_dynamo/convert_frame.py:964] [0/60] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:19.116000 29040 torch/_dynamo/convert_frame.py:964] [0/60]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:19.116000 29040 torch/_dynamo/convert_frame.py:964] [0/60]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:19.116000 29040 torch/_dynamo/convert_frame.py:964] [0/60] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:19.116000 29040 torch/_dynamo/convert_frame.py:964] [0/60] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:19,118 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:19,118 - INFO - Falling back to sequential processing
W0905 17:28:19.128000 29043 torch/_dynamo/convert_frame.py:964] [0/171] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:19.128000 29043 torch/_dynamo/convert_frame.py:964] [0/171]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:19.128000 29043 torch/_dynamo/convert_frame.py:964] [0/171]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:19.128000 29043 torch/_dynamo/convert_frame.py:964] [0/171] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:19.128000 29043 torch/_dynamo/convert_frame.py:964] [0/171] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:19,130 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=24, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=25, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,131 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:19,131 - INFO - No valid responses to write for this batch
2025-09-05 17:28:19,142 - GPU-7 - INFO - Completed batch 101, total work units processed by this worker: 1580
2025-09-05 17:28:19,142 - INFO - Completed batch 101, total work units processed by this worker: 1580
2025-09-05 17:28:19,142 - GPU-7 - INFO - Processing batch 102 (16 work units)
2025-09-05 17:28:19,142 - INFO - Processing batch 102 (16 work units)
W0905 17:28:19.172000 29040 torch/_dynamo/convert_frame.py:964] [0/61] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:19.172000 29040 torch/_dynamo/convert_frame.py:964] [0/61]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:19.172000 29040 torch/_dynamo/convert_frame.py:964] [0/61]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:19.172000 29040 torch/_dynamo/convert_frame.py:964] [0/61] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:19.172000 29040 torch/_dynamo/convert_frame.py:964] [0/61] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:19,174 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=26, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=27, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,174 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,174 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:19,174 - INFO - No valid responses to write for this batch
2025-09-05 17:28:19,185 - GPU-4 - INFO - Completed batch 60, total work units processed by this worker: 936
2025-09-05 17:28:19,185 - INFO - Completed batch 60, total work units processed by this worker: 936
W0905 17:28:19.237000 29043 torch/_dynamo/convert_frame.py:964] [0/172] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:19.237000 29043 torch/_dynamo/convert_frame.py:964] [0/172]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:19.237000 29043 torch/_dynamo/convert_frame.py:964] [0/172]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:19.237000 29043 torch/_dynamo/convert_frame.py:964] [0/172] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:19.237000 29043 torch/_dynamo/convert_frame.py:964] [0/172] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:19,239 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:19,239 - INFO - Falling back to sequential processing
W0905 17:28:19.294000 29043 torch/_dynamo/convert_frame.py:964] [0/173] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:19.294000 29043 torch/_dynamo/convert_frame.py:964] [0/173]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:19.294000 29043 torch/_dynamo/convert_frame.py:964] [0/173]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:19.294000 29043 torch/_dynamo/convert_frame.py:964] [0/173] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:19.294000 29043 torch/_dynamo/convert_frame.py:964] [0/173] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:19,296 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=28, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=29, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=30, magnitude=2800.0
2025-09-05 17:28:19,296 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=2800.0
2025-09-05 17:28:19,296 - WARNING - Skipping empty response for id=30, magnitude=2800.0
2025-09-05 17:28:19,297 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:19,297 - INFO - No valid responses to write for this batch
2025-09-05 17:28:19,308 - GPU-7 - INFO - Completed batch 102, total work units processed by this worker: 1596
2025-09-05 17:28:19,308 - INFO - Completed batch 102, total work units processed by this worker: 1596
2025-09-05 17:28:19,577 - GPU-3 - INFO - Processing batch 53 (16 work units)
2025-09-05 17:28:19,577 - INFO - Processing batch 53 (16 work units)
2025-09-05 17:28:20,589 - GPU-0 - INFO - Processing batch 73 (16 work units)
2025-09-05 17:28:20,589 - INFO - Processing batch 73 (16 work units)
W0905 17:28:20.684000 29036 torch/_dynamo/convert_frame.py:964] [0/110] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:20.684000 29036 torch/_dynamo/convert_frame.py:964] [0/110]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:20.684000 29036 torch/_dynamo/convert_frame.py:964] [0/110]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:20.684000 29036 torch/_dynamo/convert_frame.py:964] [0/110] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:20.684000 29036 torch/_dynamo/convert_frame.py:964] [0/110] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:20,686 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:20,686 - INFO - Falling back to sequential processing
W0905 17:28:20.740000 29036 torch/_dynamo/convert_frame.py:964] [0/111] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:20.740000 29036 torch/_dynamo/convert_frame.py:964] [0/111]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:20.740000 29036 torch/_dynamo/convert_frame.py:964] [0/111]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:20.740000 29036 torch/_dynamo/convert_frame.py:964] [0/111] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:20.740000 29036 torch/_dynamo/convert_frame.py:964] [0/111] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:20,742 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=32, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,742 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:20,742 - INFO - No valid responses to write for this batch
2025-09-05 17:28:20,752 - GPU-0 - INFO - Completed batch 73, total work units processed by this worker: 1156
2025-09-05 17:28:20,752 - INFO - Completed batch 73, total work units processed by this worker: 1156
2025-09-05 17:28:20,753 - GPU-0 - INFO - Processing batch 74 (16 work units)
2025-09-05 17:28:20,753 - INFO - Processing batch 74 (16 work units)
W0905 17:28:20.852000 29036 torch/_dynamo/convert_frame.py:964] [0/112] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:20.852000 29036 torch/_dynamo/convert_frame.py:964] [0/112]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:20.852000 29036 torch/_dynamo/convert_frame.py:964] [0/112]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:20.852000 29036 torch/_dynamo/convert_frame.py:964] [0/112] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:20.852000 29036 torch/_dynamo/convert_frame.py:964] [0/112] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:20,854 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:20,854 - INFO - Falling back to sequential processing
W0905 17:28:20.906000 29036 torch/_dynamo/convert_frame.py:964] [0/113] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:20.906000 29036 torch/_dynamo/convert_frame.py:964] [0/113]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:20.906000 29036 torch/_dynamo/convert_frame.py:964] [0/113]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:20.906000 29036 torch/_dynamo/convert_frame.py:964] [0/113] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:20.906000 29036 torch/_dynamo/convert_frame.py:964] [0/113] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:20,907 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=33, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=34, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:20,908 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:20,908 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:20,908 - INFO - No valid responses to write for this batch
2025-09-05 17:28:20,918 - GPU-0 - INFO - Completed batch 74, total work units processed by this worker: 1172
2025-09-05 17:28:20,918 - INFO - Completed batch 74, total work units processed by this worker: 1172
2025-09-05 17:28:21,529 - GPU-4 - INFO - Processing batch 61 (16 work units)
2025-09-05 17:28:21,529 - INFO - Processing batch 61 (16 work units)
2025-09-05 17:28:21,598 - GPU-7 - INFO - Processing batch 103 (16 work units)
2025-09-05 17:28:21,598 - INFO - Processing batch 103 (16 work units)
W0905 17:28:21.627000 29040 torch/_dynamo/convert_frame.py:964] [0/62] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:21.627000 29040 torch/_dynamo/convert_frame.py:964] [0/62]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:21.627000 29040 torch/_dynamo/convert_frame.py:964] [0/62]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:21.627000 29040 torch/_dynamo/convert_frame.py:964] [0/62] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:21.627000 29040 torch/_dynamo/convert_frame.py:964] [0/62] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:21,629 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:21,629 - INFO - Falling back to sequential processing
W0905 17:28:21.688000 29040 torch/_dynamo/convert_frame.py:964] [0/63] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:21.688000 29040 torch/_dynamo/convert_frame.py:964] [0/63]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:21.688000 29040 torch/_dynamo/convert_frame.py:964] [0/63]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:21.688000 29040 torch/_dynamo/convert_frame.py:964] [0/63] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:21.688000 29040 torch/_dynamo/convert_frame.py:964] [0/63] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:21,690 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=35, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=36, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,690 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,690 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:21,690 - INFO - No valid responses to write for this batch
W0905 17:28:21.694000 29043 torch/_dynamo/convert_frame.py:964] [0/174] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:21.694000 29043 torch/_dynamo/convert_frame.py:964] [0/174]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:21.694000 29043 torch/_dynamo/convert_frame.py:964] [0/174]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:21.694000 29043 torch/_dynamo/convert_frame.py:964] [0/174] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:21.694000 29043 torch/_dynamo/convert_frame.py:964] [0/174] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:21,696 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:21,696 - INFO - Falling back to sequential processing
2025-09-05 17:28:21,701 - GPU-4 - INFO - Completed batch 61, total work units processed by this worker: 952
2025-09-05 17:28:21,701 - INFO - Completed batch 61, total work units processed by this worker: 952
2025-09-05 17:28:21,701 - GPU-4 - INFO - Processing batch 62 (16 work units)
2025-09-05 17:28:21,701 - INFO - Processing batch 62 (16 work units)
2025-09-05 17:28:21,712 - GPU-5 - INFO - Completed batch 56, total work units processed by this worker: 896
2025-09-05 17:28:21,712 - INFO - Completed batch 56, total work units processed by this worker: 896
W0905 17:28:21.751000 29043 torch/_dynamo/convert_frame.py:964] [0/175] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:21.751000 29043 torch/_dynamo/convert_frame.py:964] [0/175]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:21.751000 29043 torch/_dynamo/convert_frame.py:964] [0/175]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:21.751000 29043 torch/_dynamo/convert_frame.py:964] [0/175] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:21.751000 29043 torch/_dynamo/convert_frame.py:964] [0/175] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:21,753 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=37, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=38, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,753 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,753 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:21,753 - INFO - No valid responses to write for this batch
2025-09-05 17:28:21,765 - GPU-7 - INFO - Completed batch 103, total work units processed by this worker: 1612
2025-09-05 17:28:21,765 - INFO - Completed batch 103, total work units processed by this worker: 1612
2025-09-05 17:28:21,765 - GPU-7 - INFO - Processing batch 104 (16 work units)
2025-09-05 17:28:21,765 - INFO - Processing batch 104 (16 work units)
W0905 17:28:21.804000 29040 torch/_dynamo/convert_frame.py:964] [0/64] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:21.804000 29040 torch/_dynamo/convert_frame.py:964] [0/64]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:21.804000 29040 torch/_dynamo/convert_frame.py:964] [0/64]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:21.804000 29040 torch/_dynamo/convert_frame.py:964] [0/64] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:21.804000 29040 torch/_dynamo/convert_frame.py:964] [0/64] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:21,805 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:21,805 - INFO - Falling back to sequential processing
W0905 17:28:21.860000 29040 torch/_dynamo/convert_frame.py:964] [0/65] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:21.860000 29040 torch/_dynamo/convert_frame.py:964] [0/65]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:21.860000 29040 torch/_dynamo/convert_frame.py:964] [0/65]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:21.860000 29040 torch/_dynamo/convert_frame.py:964] [0/65] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:21.860000 29040 torch/_dynamo/convert_frame.py:964] [0/65] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:21,862 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=39, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,862 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:21,862 - INFO - No valid responses to write for this batch
W0905 17:28:21.864000 29043 torch/_dynamo/convert_frame.py:964] [0/176] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:21.864000 29043 torch/_dynamo/convert_frame.py:964] [0/176]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:21.864000 29043 torch/_dynamo/convert_frame.py:964] [0/176]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:21.864000 29043 torch/_dynamo/convert_frame.py:964] [0/176] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:21.864000 29043 torch/_dynamo/convert_frame.py:964] [0/176] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:21,866 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:21,866 - INFO - Falling back to sequential processing
2025-09-05 17:28:21,874 - GPU-4 - INFO - Completed batch 62, total work units processed by this worker: 968
2025-09-05 17:28:21,874 - INFO - Completed batch 62, total work units processed by this worker: 968
W0905 17:28:21.921000 29043 torch/_dynamo/convert_frame.py:964] [0/177] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:21.921000 29043 torch/_dynamo/convert_frame.py:964] [0/177]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:21.921000 29043 torch/_dynamo/convert_frame.py:964] [0/177]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:21.921000 29043 torch/_dynamo/convert_frame.py:964] [0/177] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:21.921000 29043 torch/_dynamo/convert_frame.py:964] [0/177] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:21,923 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:21,923 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,923 - WARNING - Skipping empty response for id=40, magnitude=2800.0
2025-09-05 17:28:21,923 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,923 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,923 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,923 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,923 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,923 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=41, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:21,924 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:21,924 - INFO - No valid responses to write for this batch
2025-09-05 17:28:21,935 - GPU-7 - INFO - Completed batch 104, total work units processed by this worker: 1628
2025-09-05 17:28:21,935 - INFO - Completed batch 104, total work units processed by this worker: 1628
2025-09-05 17:28:23,071 - GPU-0 - INFO - Processing batch 75 (16 work units)
2025-09-05 17:28:23,071 - INFO - Processing batch 75 (16 work units)
W0905 17:28:23.171000 29036 torch/_dynamo/convert_frame.py:964] [0/114] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:23.171000 29036 torch/_dynamo/convert_frame.py:964] [0/114]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:23.171000 29036 torch/_dynamo/convert_frame.py:964] [0/114]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:23.171000 29036 torch/_dynamo/convert_frame.py:964] [0/114] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:23.171000 29036 torch/_dynamo/convert_frame.py:964] [0/114] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:23,173 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:23,173 - INFO - Falling back to sequential processing
W0905 17:28:23.226000 29036 torch/_dynamo/convert_frame.py:964] [0/115] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:23.226000 29036 torch/_dynamo/convert_frame.py:964] [0/115]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:23.226000 29036 torch/_dynamo/convert_frame.py:964] [0/115]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:23.226000 29036 torch/_dynamo/convert_frame.py:964] [0/115] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:23.226000 29036 torch/_dynamo/convert_frame.py:964] [0/115] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:23,228 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=42, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=43, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,228 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,228 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:23,228 - INFO - No valid responses to write for this batch
2025-09-05 17:28:23,239 - GPU-0 - INFO - Completed batch 75, total work units processed by this worker: 1188
2025-09-05 17:28:23,239 - INFO - Completed batch 75, total work units processed by this worker: 1188
2025-09-05 17:28:23,239 - GPU-0 - INFO - Processing batch 76 (16 work units)
2025-09-05 17:28:23,239 - INFO - Processing batch 76 (16 work units)
2025-09-05 17:28:23,320 - GPU-5 - INFO - Processing batch 57 (16 work units)
2025-09-05 17:28:23,320 - INFO - Processing batch 57 (16 work units)
W0905 17:28:23.335000 29036 torch/_dynamo/convert_frame.py:964] [0/116] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:23.335000 29036 torch/_dynamo/convert_frame.py:964] [0/116]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:23.335000 29036 torch/_dynamo/convert_frame.py:964] [0/116]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:23.335000 29036 torch/_dynamo/convert_frame.py:964] [0/116] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:23.335000 29036 torch/_dynamo/convert_frame.py:964] [0/116] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:23,337 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:23,337 - INFO - Falling back to sequential processing
W0905 17:28:23.389000 29036 torch/_dynamo/convert_frame.py:964] [0/117] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:23.389000 29036 torch/_dynamo/convert_frame.py:964] [0/117]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:23.389000 29036 torch/_dynamo/convert_frame.py:964] [0/117]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:23.389000 29036 torch/_dynamo/convert_frame.py:964] [0/117] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:23.389000 29036 torch/_dynamo/convert_frame.py:964] [0/117] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:23,391 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=44, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=45, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=46, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=46, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - WARNING - Skipping empty response for id=46, magnitude=2800.0
2025-09-05 17:28:23,391 - WARNING - Skipping empty response for id=46, magnitude=2800.0
2025-09-05 17:28:23,391 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:23,391 - INFO - No valid responses to write for this batch
2025-09-05 17:28:23,401 - GPU-0 - INFO - Completed batch 76, total work units processed by this worker: 1204
2025-09-05 17:28:23,401 - INFO - Completed batch 76, total work units processed by this worker: 1204
2025-09-05 17:28:24,268 - GPU-4 - INFO - Processing batch 63 (16 work units)
2025-09-05 17:28:24,268 - INFO - Processing batch 63 (16 work units)
2025-09-05 17:28:24,280 - GPU-7 - INFO - Processing batch 105 (16 work units)
2025-09-05 17:28:24,280 - INFO - Processing batch 105 (16 work units)
W0905 17:28:24.370000 29040 torch/_dynamo/convert_frame.py:964] [0/66] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:24.370000 29040 torch/_dynamo/convert_frame.py:964] [0/66]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:24.370000 29040 torch/_dynamo/convert_frame.py:964] [0/66]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:24.370000 29040 torch/_dynamo/convert_frame.py:964] [0/66] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:24.370000 29040 torch/_dynamo/convert_frame.py:964] [0/66] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:24,372 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:24,372 - INFO - Falling back to sequential processing
W0905 17:28:24.381000 29043 torch/_dynamo/convert_frame.py:964] [0/178] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:24.381000 29043 torch/_dynamo/convert_frame.py:964] [0/178]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:24.381000 29043 torch/_dynamo/convert_frame.py:964] [0/178]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:24.381000 29043 torch/_dynamo/convert_frame.py:964] [0/178] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:24.381000 29043 torch/_dynamo/convert_frame.py:964] [0/178] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:24,383 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:24,383 - INFO - Falling back to sequential processing
W0905 17:28:24.427000 29040 torch/_dynamo/convert_frame.py:964] [0/67] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:24.427000 29040 torch/_dynamo/convert_frame.py:964] [0/67]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:24.427000 29040 torch/_dynamo/convert_frame.py:964] [0/67]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:24.427000 29040 torch/_dynamo/convert_frame.py:964] [0/67] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:24.427000 29040 torch/_dynamo/convert_frame.py:964] [0/67] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:24,429 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:24,429 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - WARNING - Skipping empty response for id=48, magnitude=2800.0
2025-09-05 17:28:24,429 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,429 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,430 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:24,430 - INFO - No valid responses to write for this batch
W0905 17:28:24.438000 29043 torch/_dynamo/convert_frame.py:964] [0/179] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:24.438000 29043 torch/_dynamo/convert_frame.py:964] [0/179]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:24.438000 29043 torch/_dynamo/convert_frame.py:964] [0/179]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:24.438000 29043 torch/_dynamo/convert_frame.py:964] [0/179] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:24.438000 29043 torch/_dynamo/convert_frame.py:964] [0/179] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:24,440 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=49, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=50, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,440 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,440 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:24,440 - INFO - No valid responses to write for this batch
2025-09-05 17:28:24,442 - GPU-4 - INFO - Completed batch 63, total work units processed by this worker: 984
2025-09-05 17:28:24,442 - INFO - Completed batch 63, total work units processed by this worker: 984
2025-09-05 17:28:24,442 - GPU-4 - INFO - Processing batch 64 (16 work units)
2025-09-05 17:28:24,442 - INFO - Processing batch 64 (16 work units)
2025-09-05 17:28:24,454 - GPU-7 - INFO - Completed batch 105, total work units processed by this worker: 1644
2025-09-05 17:28:24,454 - INFO - Completed batch 105, total work units processed by this worker: 1644
2025-09-05 17:28:24,454 - GPU-7 - INFO - Processing batch 106 (16 work units)
2025-09-05 17:28:24,454 - INFO - Processing batch 106 (16 work units)
W0905 17:28:24.544000 29040 torch/_dynamo/convert_frame.py:964] [0/68] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:24.544000 29040 torch/_dynamo/convert_frame.py:964] [0/68]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:24.544000 29040 torch/_dynamo/convert_frame.py:964] [0/68]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:24.544000 29040 torch/_dynamo/convert_frame.py:964] [0/68] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:24.544000 29040 torch/_dynamo/convert_frame.py:964] [0/68] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:24,546 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:24,546 - INFO - Falling back to sequential processing
W0905 17:28:24.562000 29043 torch/_dynamo/convert_frame.py:964] [0/180] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:24.562000 29043 torch/_dynamo/convert_frame.py:964] [0/180]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:24.562000 29043 torch/_dynamo/convert_frame.py:964] [0/180]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:24.562000 29043 torch/_dynamo/convert_frame.py:964] [0/180] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:24.562000 29043 torch/_dynamo/convert_frame.py:964] [0/180] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:24,564 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:24,564 - INFO - Falling back to sequential processing
W0905 17:28:24.688000 29040 torch/_dynamo/convert_frame.py:964] [0/69] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:24.688000 29040 torch/_dynamo/convert_frame.py:964] [0/69]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:24.688000 29040 torch/_dynamo/convert_frame.py:964] [0/69]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:24.688000 29040 torch/_dynamo/convert_frame.py:964] [0/69] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:24.688000 29040 torch/_dynamo/convert_frame.py:964] [0/69] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:24,689 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=51, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=52, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,690 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,690 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:24,690 - INFO - No valid responses to write for this batch
W0905 17:28:24.694000 29043 torch/_dynamo/convert_frame.py:964] [0/181] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:24.694000 29043 torch/_dynamo/convert_frame.py:964] [0/181]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:24.694000 29043 torch/_dynamo/convert_frame.py:964] [0/181]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:24.694000 29043 torch/_dynamo/convert_frame.py:964] [0/181] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:24.694000 29043 torch/_dynamo/convert_frame.py:964] [0/181] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:24,696 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=53, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=54, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:24,696 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:24,696 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:24,696 - INFO - No valid responses to write for this batch
2025-09-05 17:28:24,709 - GPU-4 - INFO - Completed batch 64, total work units processed by this worker: 1000
2025-09-05 17:28:24,709 - INFO - Completed batch 64, total work units processed by this worker: 1000
2025-09-05 17:28:24,716 - GPU-7 - INFO - Completed batch 106, total work units processed by this worker: 1660
2025-09-05 17:28:24,716 - INFO - Completed batch 106, total work units processed by this worker: 1660
2025-09-05 17:28:25,524 - GPU-0 - INFO - Processing batch 77 (16 work units)
2025-09-05 17:28:25,524 - INFO - Processing batch 77 (16 work units)
W0905 17:28:25.633000 29036 torch/_dynamo/convert_frame.py:964] [0/118] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:25.633000 29036 torch/_dynamo/convert_frame.py:964] [0/118]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:25.633000 29036 torch/_dynamo/convert_frame.py:964] [0/118]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:25.633000 29036 torch/_dynamo/convert_frame.py:964] [0/118] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:25.633000 29036 torch/_dynamo/convert_frame.py:964] [0/118] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:25,635 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:25,635 - INFO - Falling back to sequential processing
W0905 17:28:25.688000 29036 torch/_dynamo/convert_frame.py:964] [0/119] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:25.688000 29036 torch/_dynamo/convert_frame.py:964] [0/119]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:25.688000 29036 torch/_dynamo/convert_frame.py:964] [0/119]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:25.688000 29036 torch/_dynamo/convert_frame.py:964] [0/119] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:25.688000 29036 torch/_dynamo/convert_frame.py:964] [0/119] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:25,689 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=55, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,690 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:25,690 - INFO - No valid responses to write for this batch
2025-09-05 17:28:25,700 - GPU-0 - INFO - Completed batch 77, total work units processed by this worker: 1220
2025-09-05 17:28:25,700 - INFO - Completed batch 77, total work units processed by this worker: 1220
2025-09-05 17:28:25,701 - GPU-0 - INFO - Processing batch 78 (16 work units)
2025-09-05 17:28:25,701 - INFO - Processing batch 78 (16 work units)
W0905 17:28:25.807000 29036 torch/_dynamo/convert_frame.py:964] [0/120] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:25.807000 29036 torch/_dynamo/convert_frame.py:964] [0/120]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:25.807000 29036 torch/_dynamo/convert_frame.py:964] [0/120]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:25.807000 29036 torch/_dynamo/convert_frame.py:964] [0/120] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:25.807000 29036 torch/_dynamo/convert_frame.py:964] [0/120] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:25,809 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:25,809 - INFO - Falling back to sequential processing
W0905 17:28:25.892000 29036 torch/_dynamo/convert_frame.py:964] [0/121] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:25.892000 29036 torch/_dynamo/convert_frame.py:964] [0/121]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:25.892000 29036 torch/_dynamo/convert_frame.py:964] [0/121]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:25.892000 29036 torch/_dynamo/convert_frame.py:964] [0/121] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:25.892000 29036 torch/_dynamo/convert_frame.py:964] [0/121] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:25,893 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=56, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=57, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:25,894 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:25,894 - INFO - No valid responses to write for this batch
2025-09-05 17:28:25,962 - GPU-0 - INFO - Completed batch 78, total work units processed by this worker: 1236
2025-09-05 17:28:25,962 - INFO - Completed batch 78, total work units processed by this worker: 1236
2025-09-05 17:28:27,044 - GPU-7 - INFO - Processing batch 107 (16 work units)
2025-09-05 17:28:27,044 - INFO - Processing batch 107 (16 work units)
2025-09-05 17:28:27,097 - GPU-4 - INFO - Processing batch 65 (16 work units)
2025-09-05 17:28:27,097 - INFO - Processing batch 65 (16 work units)
W0905 17:28:27.149000 29043 torch/_dynamo/convert_frame.py:964] [0/182] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:27.149000 29043 torch/_dynamo/convert_frame.py:964] [0/182]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:27.149000 29043 torch/_dynamo/convert_frame.py:964] [0/182]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:27.149000 29043 torch/_dynamo/convert_frame.py:964] [0/182] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:27.149000 29043 torch/_dynamo/convert_frame.py:964] [0/182] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:27,151 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:27,151 - INFO - Falling back to sequential processing
W0905 17:28:27.197000 29040 torch/_dynamo/convert_frame.py:964] [0/70] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:27.197000 29040 torch/_dynamo/convert_frame.py:964] [0/70]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:27.197000 29040 torch/_dynamo/convert_frame.py:964] [0/70]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:27.197000 29040 torch/_dynamo/convert_frame.py:964] [0/70] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:27.197000 29040 torch/_dynamo/convert_frame.py:964] [0/70] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:27,199 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:27,199 - INFO - Falling back to sequential processing
W0905 17:28:27.206000 29043 torch/_dynamo/convert_frame.py:964] [0/183] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:27.206000 29043 torch/_dynamo/convert_frame.py:964] [0/183]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:27.206000 29043 torch/_dynamo/convert_frame.py:964] [0/183]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:27.206000 29043 torch/_dynamo/convert_frame.py:964] [0/183] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:27.206000 29043 torch/_dynamo/convert_frame.py:964] [0/183] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:27,208 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:27,208 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:27,208 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:27,208 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:27,208 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:27,208 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:27,208 - WARNING - Skipping empty response for id=58, magnitude=2800.0
2025-09-05 17:28:27,208 - GPU-7 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,208 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=59, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,209 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,209 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:27,209 - INFO - No valid responses to write for this batch
2025-09-05 17:28:27,220 - GPU-7 - INFO - Completed batch 107, total work units processed by this worker: 1676
2025-09-05 17:28:27,220 - INFO - Completed batch 107, total work units processed by this worker: 1676
2025-09-05 17:28:27,220 - GPU-7 - INFO - Processing batch 108 (16 work units)
2025-09-05 17:28:27,220 - INFO - Processing batch 108 (16 work units)
W0905 17:28:27.254000 29040 torch/_dynamo/convert_frame.py:964] [0/71] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:27.254000 29040 torch/_dynamo/convert_frame.py:964] [0/71]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:27.254000 29040 torch/_dynamo/convert_frame.py:964] [0/71]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:27.254000 29040 torch/_dynamo/convert_frame.py:964] [0/71] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:27.254000 29040 torch/_dynamo/convert_frame.py:964] [0/71] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:27,256 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:27,256 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,256 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,256 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,256 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,256 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,256 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,256 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,256 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,256 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,256 - WARNING - Skipping empty response for id=60, magnitude=2800.0
2025-09-05 17:28:27,256 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,256 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,256 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,256 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,256 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,256 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,256 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,256 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - GPU-4 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - WARNING - Skipping empty response for id=61, magnitude=2800.0
2025-09-05 17:28:27,257 - GPU-4 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,257 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,257 - GPU-4 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,257 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,257 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:27,257 - INFO - No valid responses to write for this batch
2025-09-05 17:28:27,268 - GPU-4 - INFO - Completed batch 65, total work units processed by this worker: 1016
2025-09-05 17:28:27,268 - INFO - Completed batch 65, total work units processed by this worker: 1016
2025-09-05 17:28:27,268 - GPU-4 - INFO - Processing batch 66 (16 work units)
2025-09-05 17:28:27,268 - INFO - Processing batch 66 (16 work units)
W0905 17:28:27.317000 29043 torch/_dynamo/convert_frame.py:964] [0/184] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:27.317000 29043 torch/_dynamo/convert_frame.py:964] [0/184]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:27.317000 29043 torch/_dynamo/convert_frame.py:964] [0/184]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:27.317000 29043 torch/_dynamo/convert_frame.py:964] [0/184] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:27.317000 29043 torch/_dynamo/convert_frame.py:964] [0/184] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:27,319 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:27,319 - INFO - Falling back to sequential processing
W0905 17:28:27.373000 29040 torch/_dynamo/convert_frame.py:964] [0/72] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:27.373000 29040 torch/_dynamo/convert_frame.py:964] [0/72]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:27.373000 29040 torch/_dynamo/convert_frame.py:964] [0/72]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:27.373000 29040 torch/_dynamo/convert_frame.py:964] [0/72] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:27.373000 29040 torch/_dynamo/convert_frame.py:964] [0/72] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
W0905 17:28:27.374000 29043 torch/_dynamo/convert_frame.py:964] [0/185] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:27.374000 29043 torch/_dynamo/convert_frame.py:964] [0/185]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:27.374000 29043 torch/_dynamo/convert_frame.py:964] [0/185]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:27.374000 29043 torch/_dynamo/convert_frame.py:964] [0/185] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:27.374000 29043 torch/_dynamo/convert_frame.py:964] [0/185] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:27,375 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:27,375 - INFO - Falling back to sequential processing
2025-09-05 17:28:27,375 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=62, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - WARNING - Skipping empty response for id=63, magnitude=2800.0
2025-09-05 17:28:27,376 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:27,376 - INFO - No valid responses to write for this batch
2025-09-05 17:28:27,387 - GPU-7 - INFO - Completed batch 108, total work units processed by this worker: 1692
2025-09-05 17:28:27,387 - INFO - Completed batch 108, total work units processed by this worker: 1692
W0905 17:28:27.430000 29040 torch/_dynamo/convert_frame.py:964] [0/73] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:27.430000 29040 torch/_dynamo/convert_frame.py:964] [0/73]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:27.430000 29040 torch/_dynamo/convert_frame.py:964] [0/73]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:27.430000 29040 torch/_dynamo/convert_frame.py:964] [0/73] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:27.430000 29040 torch/_dynamo/convert_frame.py:964] [0/73] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:27,432 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=64, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,432 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,432 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,433 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,433 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,433 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,433 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:27,433 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:27,433 - INFO - No valid responses to write for this batch
2025-09-05 17:28:27,444 - GPU-4 - INFO - Completed batch 66, total work units processed by this worker: 1032
2025-09-05 17:28:27,444 - INFO - Completed batch 66, total work units processed by this worker: 1032
2025-09-05 17:28:28,126 - GPU-0 - INFO - Processing batch 79 (16 work units)
2025-09-05 17:28:28,126 - INFO - Processing batch 79 (16 work units)
W0905 17:28:28.224000 29036 torch/_dynamo/convert_frame.py:964] [0/122] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:28.224000 29036 torch/_dynamo/convert_frame.py:964] [0/122]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:28.224000 29036 torch/_dynamo/convert_frame.py:964] [0/122]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:28.224000 29036 torch/_dynamo/convert_frame.py:964] [0/122] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:28.224000 29036 torch/_dynamo/convert_frame.py:964] [0/122] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:28,226 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:28,226 - INFO - Falling back to sequential processing
W0905 17:28:28.278000 29036 torch/_dynamo/convert_frame.py:964] [0/123] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:28.278000 29036 torch/_dynamo/convert_frame.py:964] [0/123]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:28.278000 29036 torch/_dynamo/convert_frame.py:964] [0/123]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:28.278000 29036 torch/_dynamo/convert_frame.py:964] [0/123] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:28.278000 29036 torch/_dynamo/convert_frame.py:964] [0/123] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:28,280 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=65, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=66, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,280 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,280 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:28,280 - INFO - No valid responses to write for this batch
2025-09-05 17:28:28,291 - GPU-0 - INFO - Completed batch 79, total work units processed by this worker: 1252
2025-09-05 17:28:28,291 - INFO - Completed batch 79, total work units processed by this worker: 1252
2025-09-05 17:28:28,291 - GPU-0 - INFO - Processing batch 80 (16 work units)
2025-09-05 17:28:28,291 - INFO - Processing batch 80 (16 work units)
W0905 17:28:28.390000 29036 torch/_dynamo/convert_frame.py:964] [0/124] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:28.390000 29036 torch/_dynamo/convert_frame.py:964] [0/124]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:28.390000 29036 torch/_dynamo/convert_frame.py:964] [0/124]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:28.390000 29036 torch/_dynamo/convert_frame.py:964] [0/124] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:28.390000 29036 torch/_dynamo/convert_frame.py:964] [0/124] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:28,392 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:28,392 - INFO - Falling back to sequential processing
W0905 17:28:28.443000 29036 torch/_dynamo/convert_frame.py:964] [0/125] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:28.443000 29036 torch/_dynamo/convert_frame.py:964] [0/125]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:28.443000 29036 torch/_dynamo/convert_frame.py:964] [0/125]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:28.443000 29036 torch/_dynamo/convert_frame.py:964] [0/125] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:28.443000 29036 torch/_dynamo/convert_frame.py:964] [0/125] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:28,445 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:28,445 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,445 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=67, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=68, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:28,446 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:28,446 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:28,446 - INFO - No valid responses to write for this batch
2025-09-05 17:28:28,456 - GPU-0 - INFO - Completed batch 80, total work units processed by this worker: 1268
2025-09-05 17:28:28,456 - INFO - Completed batch 80, total work units processed by this worker: 1268
2025-09-05 17:28:29,729 - GPU-7 - INFO - Processing batch 109 (16 work units)
2025-09-05 17:28:29,729 - INFO - Processing batch 109 (16 work units)
2025-09-05 17:28:29,792 - GPU-4 - INFO - Processing batch 67 (16 work units)
2025-09-05 17:28:29,792 - INFO - Processing batch 67 (16 work units)
W0905 17:28:29.832000 29043 torch/_dynamo/convert_frame.py:964] [0/186] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:29.832000 29043 torch/_dynamo/convert_frame.py:964] [0/186]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:29.832000 29043 torch/_dynamo/convert_frame.py:964] [0/186]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:29.832000 29043 torch/_dynamo/convert_frame.py:964] [0/186] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:29.832000 29043 torch/_dynamo/convert_frame.py:964] [0/186] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:29,834 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:29,834 - INFO - Falling back to sequential processing
W0905 17:28:29.888000 29043 torch/_dynamo/convert_frame.py:964] [0/187] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:29.888000 29043 torch/_dynamo/convert_frame.py:964] [0/187]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:29.888000 29043 torch/_dynamo/convert_frame.py:964] [0/187]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:29.888000 29043 torch/_dynamo/convert_frame.py:964] [0/187] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:29.888000 29043 torch/_dynamo/convert_frame.py:964] [0/187] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:29,890 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=69, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=70, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,891 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,891 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:29,891 - INFO - No valid responses to write for this batch
W0905 17:28:29.891000 29040 torch/_dynamo/convert_frame.py:964] [0/74] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:29.891000 29040 torch/_dynamo/convert_frame.py:964] [0/74]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:29.891000 29040 torch/_dynamo/convert_frame.py:964] [0/74]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:29.891000 29040 torch/_dynamo/convert_frame.py:964] [0/74] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:29.891000 29040 torch/_dynamo/convert_frame.py:964] [0/74] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:29,893 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:29,893 - INFO - Falling back to sequential processing
2025-09-05 17:28:29,902 - GPU-7 - INFO - Completed batch 109, total work units processed by this worker: 1708
2025-09-05 17:28:29,902 - INFO - Completed batch 109, total work units processed by this worker: 1708
2025-09-05 17:28:29,902 - GPU-7 - INFO - Processing batch 110 (16 work units)
2025-09-05 17:28:29,902 - INFO - Processing batch 110 (16 work units)
W0905 17:28:29.949000 29040 torch/_dynamo/convert_frame.py:964] [0/75] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:29.949000 29040 torch/_dynamo/convert_frame.py:964] [0/75]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:29.949000 29040 torch/_dynamo/convert_frame.py:964] [0/75]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:29.949000 29040 torch/_dynamo/convert_frame.py:964] [0/75] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:29.949000 29040 torch/_dynamo/convert_frame.py:964] [0/75] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:29,950 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=71, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:29,951 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:29,951 - INFO - No valid responses to write for this batch
2025-09-05 17:28:29,962 - GPU-4 - INFO - Completed batch 67, total work units processed by this worker: 1048
2025-09-05 17:28:29,962 - INFO - Completed batch 67, total work units processed by this worker: 1048
2025-09-05 17:28:29,963 - GPU-4 - INFO - Processing batch 68 (16 work units)
2025-09-05 17:28:29,963 - INFO - Processing batch 68 (16 work units)
W0905 17:28:29.995000 29043 torch/_dynamo/convert_frame.py:964] [0/188] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:29.995000 29043 torch/_dynamo/convert_frame.py:964] [0/188]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:29.995000 29043 torch/_dynamo/convert_frame.py:964] [0/188]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:29.995000 29043 torch/_dynamo/convert_frame.py:964] [0/188] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:29.995000 29043 torch/_dynamo/convert_frame.py:964] [0/188] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:29,997 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:29,997 - INFO - Falling back to sequential processing
W0905 17:28:30.051000 29043 torch/_dynamo/convert_frame.py:964] [0/189] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:30.051000 29043 torch/_dynamo/convert_frame.py:964] [0/189]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:30.051000 29043 torch/_dynamo/convert_frame.py:964] [0/189]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:30.051000 29043 torch/_dynamo/convert_frame.py:964] [0/189] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:30.051000 29043 torch/_dynamo/convert_frame.py:964] [0/189] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:30,053 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:30,053 - GPU-7 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:30,053 - WARNING - Skipping empty response for id=72, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=73, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,054 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:30,054 - INFO - No valid responses to write for this batch
W0905 17:28:30.055000 29040 torch/_dynamo/convert_frame.py:964] [0/76] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:30.055000 29040 torch/_dynamo/convert_frame.py:964] [0/76]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:30.055000 29040 torch/_dynamo/convert_frame.py:964] [0/76]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:30.055000 29040 torch/_dynamo/convert_frame.py:964] [0/76] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:30.055000 29040 torch/_dynamo/convert_frame.py:964] [0/76] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:30,057 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:30,057 - INFO - Falling back to sequential processing
2025-09-05 17:28:30,065 - GPU-7 - INFO - Completed batch 110, total work units processed by this worker: 1724
2025-09-05 17:28:30,065 - INFO - Completed batch 110, total work units processed by this worker: 1724
W0905 17:28:30.111000 29040 torch/_dynamo/convert_frame.py:964] [0/77] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:30.111000 29040 torch/_dynamo/convert_frame.py:964] [0/77]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:30.111000 29040 torch/_dynamo/convert_frame.py:964] [0/77]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:30.111000 29040 torch/_dynamo/convert_frame.py:964] [0/77] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:30.111000 29040 torch/_dynamo/convert_frame.py:964] [0/77] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:30,113 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:30,113 - GPU-4 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,113 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,113 - GPU-4 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,113 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,113 - GPU-4 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,113 - WARNING - Skipping empty response for id=74, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=75, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,114 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,114 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:30,114 - INFO - No valid responses to write for this batch
2025-09-05 17:28:30,125 - GPU-4 - INFO - Completed batch 68, total work units processed by this worker: 1064
2025-09-05 17:28:30,125 - INFO - Completed batch 68, total work units processed by this worker: 1064
2025-09-05 17:28:30,600 - GPU-0 - INFO - Processing batch 81 (16 work units)
2025-09-05 17:28:30,600 - INFO - Processing batch 81 (16 work units)
W0905 17:28:30.698000 29036 torch/_dynamo/convert_frame.py:964] [0/126] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:30.698000 29036 torch/_dynamo/convert_frame.py:964] [0/126]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:30.698000 29036 torch/_dynamo/convert_frame.py:964] [0/126]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:30.698000 29036 torch/_dynamo/convert_frame.py:964] [0/126] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:30.698000 29036 torch/_dynamo/convert_frame.py:964] [0/126] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:30,700 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:30,700 - INFO - Falling back to sequential processing
W0905 17:28:30.752000 29036 torch/_dynamo/convert_frame.py:964] [0/127] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:30.752000 29036 torch/_dynamo/convert_frame.py:964] [0/127]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:30.752000 29036 torch/_dynamo/convert_frame.py:964] [0/127]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:30.752000 29036 torch/_dynamo/convert_frame.py:964] [0/127] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:30.752000 29036 torch/_dynamo/convert_frame.py:964] [0/127] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:30,754 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=76, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=77, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,754 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,754 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:30,754 - INFO - No valid responses to write for this batch
2025-09-05 17:28:30,765 - GPU-0 - INFO - Completed batch 81, total work units processed by this worker: 1284
2025-09-05 17:28:30,765 - INFO - Completed batch 81, total work units processed by this worker: 1284
2025-09-05 17:28:30,765 - GPU-0 - INFO - Processing batch 82 (16 work units)
2025-09-05 17:28:30,765 - INFO - Processing batch 82 (16 work units)
W0905 17:28:30.857000 29036 torch/_dynamo/convert_frame.py:964] [0/128] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:30.857000 29036 torch/_dynamo/convert_frame.py:964] [0/128]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:30.857000 29036 torch/_dynamo/convert_frame.py:964] [0/128]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:30.857000 29036 torch/_dynamo/convert_frame.py:964] [0/128] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:30.857000 29036 torch/_dynamo/convert_frame.py:964] [0/128] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:30,859 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:30,859 - INFO - Falling back to sequential processing
W0905 17:28:30.911000 29036 torch/_dynamo/convert_frame.py:964] [0/129] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:30.911000 29036 torch/_dynamo/convert_frame.py:964] [0/129]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:30.911000 29036 torch/_dynamo/convert_frame.py:964] [0/129]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:30.911000 29036 torch/_dynamo/convert_frame.py:964] [0/129] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:30.911000 29036 torch/_dynamo/convert_frame.py:964] [0/129] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:30,913 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=78, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - WARNING - Skipping empty response for id=79, magnitude=2800.0
2025-09-05 17:28:30,913 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:30,913 - INFO - No valid responses to write for this batch
2025-09-05 17:28:30,923 - GPU-0 - INFO - Completed batch 82, total work units processed by this worker: 1300
2025-09-05 17:28:30,923 - INFO - Completed batch 82, total work units processed by this worker: 1300
2025-09-05 17:28:32,397 - GPU-7 - INFO - Processing batch 111 (16 work units)
2025-09-05 17:28:32,397 - INFO - Processing batch 111 (16 work units)
2025-09-05 17:28:32,482 - GPU-4 - INFO - Processing batch 69 (16 work units)
2025-09-05 17:28:32,482 - INFO - Processing batch 69 (16 work units)
W0905 17:28:32.495000 29043 torch/_dynamo/convert_frame.py:964] [0/190] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:32.495000 29043 torch/_dynamo/convert_frame.py:964] [0/190]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:32.495000 29043 torch/_dynamo/convert_frame.py:964] [0/190]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:32.495000 29043 torch/_dynamo/convert_frame.py:964] [0/190] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:32.495000 29043 torch/_dynamo/convert_frame.py:964] [0/190] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:32,497 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:32,497 - INFO - Falling back to sequential processing
W0905 17:28:32.553000 29043 torch/_dynamo/convert_frame.py:964] [0/191] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:32.553000 29043 torch/_dynamo/convert_frame.py:964] [0/191]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:32.553000 29043 torch/_dynamo/convert_frame.py:964] [0/191]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:32.553000 29043 torch/_dynamo/convert_frame.py:964] [0/191] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:32.553000 29043 torch/_dynamo/convert_frame.py:964] [0/191] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:32,555 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=80, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,555 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:32,555 - INFO - No valid responses to write for this batch
2025-09-05 17:28:32,566 - GPU-7 - INFO - Completed batch 111, total work units processed by this worker: 1740
2025-09-05 17:28:32,566 - INFO - Completed batch 111, total work units processed by this worker: 1740
2025-09-05 17:28:32,567 - GPU-7 - INFO - Processing batch 112 (16 work units)
2025-09-05 17:28:32,567 - INFO - Processing batch 112 (16 work units)
W0905 17:28:32.580000 29040 torch/_dynamo/convert_frame.py:964] [0/78] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:32.580000 29040 torch/_dynamo/convert_frame.py:964] [0/78]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:32.580000 29040 torch/_dynamo/convert_frame.py:964] [0/78]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:32.580000 29040 torch/_dynamo/convert_frame.py:964] [0/78] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:32.580000 29040 torch/_dynamo/convert_frame.py:964] [0/78] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:32,582 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:32,582 - INFO - Falling back to sequential processing
W0905 17:28:32.636000 29040 torch/_dynamo/convert_frame.py:964] [0/79] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:32.636000 29040 torch/_dynamo/convert_frame.py:964] [0/79]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:32.636000 29040 torch/_dynamo/convert_frame.py:964] [0/79]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:32.636000 29040 torch/_dynamo/convert_frame.py:964] [0/79] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:32.636000 29040 torch/_dynamo/convert_frame.py:964] [0/79] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:32,638 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:32,638 - GPU-4 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,638 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=81, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=82, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,639 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,639 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:32,639 - INFO - No valid responses to write for this batch
2025-09-05 17:28:32,650 - GPU-4 - INFO - Completed batch 69, total work units processed by this worker: 1080
2025-09-05 17:28:32,650 - INFO - Completed batch 69, total work units processed by this worker: 1080
2025-09-05 17:28:32,650 - GPU-4 - INFO - Processing batch 70 (16 work units)
2025-09-05 17:28:32,650 - INFO - Processing batch 70 (16 work units)
W0905 17:28:32.666000 29043 torch/_dynamo/convert_frame.py:964] [0/192] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:32.666000 29043 torch/_dynamo/convert_frame.py:964] [0/192]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:32.666000 29043 torch/_dynamo/convert_frame.py:964] [0/192]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:32.666000 29043 torch/_dynamo/convert_frame.py:964] [0/192] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:32.666000 29043 torch/_dynamo/convert_frame.py:964] [0/192] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:32,668 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:32,668 - INFO - Falling back to sequential processing
W0905 17:28:32.723000 29043 torch/_dynamo/convert_frame.py:964] [0/193] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:32.723000 29043 torch/_dynamo/convert_frame.py:964] [0/193]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:32.723000 29043 torch/_dynamo/convert_frame.py:964] [0/193]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:32.723000 29043 torch/_dynamo/convert_frame.py:964] [0/193] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:32.723000 29043 torch/_dynamo/convert_frame.py:964] [0/193] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:32,724 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=83, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=84, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,725 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,725 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:32,725 - INFO - No valid responses to write for this batch
2025-09-05 17:28:32,736 - GPU-7 - INFO - Completed batch 112, total work units processed by this worker: 1756
2025-09-05 17:28:32,736 - INFO - Completed batch 112, total work units processed by this worker: 1756
W0905 17:28:32.749000 29040 torch/_dynamo/convert_frame.py:964] [0/80] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:32.749000 29040 torch/_dynamo/convert_frame.py:964] [0/80]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:32.749000 29040 torch/_dynamo/convert_frame.py:964] [0/80]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:32.749000 29040 torch/_dynamo/convert_frame.py:964] [0/80] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:32.749000 29040 torch/_dynamo/convert_frame.py:964] [0/80] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:32,751 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:32,751 - INFO - Falling back to sequential processing
W0905 17:28:32.805000 29040 torch/_dynamo/convert_frame.py:964] [0/81] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:32.805000 29040 torch/_dynamo/convert_frame.py:964] [0/81]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:32.805000 29040 torch/_dynamo/convert_frame.py:964] [0/81]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:32.805000 29040 torch/_dynamo/convert_frame.py:964] [0/81] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:32.805000 29040 torch/_dynamo/convert_frame.py:964] [0/81] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:32,807 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:32,807 - GPU-4 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - GPU-4 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - GPU-4 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - GPU-4 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - GPU-4 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - GPU-4 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - WARNING - Skipping empty response for id=85, magnitude=2800.0
2025-09-05 17:28:32,807 - GPU-4 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,807 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - GPU-4 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - GPU-4 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - GPU-4 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - GPU-4 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - GPU-4 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - GPU-4 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - GPU-4 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - GPU-4 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - WARNING - Skipping empty response for id=86, magnitude=2800.0
2025-09-05 17:28:32,808 - GPU-4 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:32,808 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:32,808 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:32,808 - INFO - No valid responses to write for this batch
2025-09-05 17:28:32,819 - GPU-4 - INFO - Completed batch 70, total work units processed by this worker: 1096
2025-09-05 17:28:32,819 - INFO - Completed batch 70, total work units processed by this worker: 1096
2025-09-05 17:28:33,070 - GPU-0 - INFO - Processing batch 83 (16 work units)
2025-09-05 17:28:33,070 - INFO - Processing batch 83 (16 work units)
W0905 17:28:33.172000 29036 torch/_dynamo/convert_frame.py:964] [0/130] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:33.172000 29036 torch/_dynamo/convert_frame.py:964] [0/130]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:33.172000 29036 torch/_dynamo/convert_frame.py:964] [0/130]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:33.172000 29036 torch/_dynamo/convert_frame.py:964] [0/130] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:33.172000 29036 torch/_dynamo/convert_frame.py:964] [0/130] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:33,174 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:33,174 - INFO - Falling back to sequential processing
W0905 17:28:33.227000 29036 torch/_dynamo/convert_frame.py:964] [0/131] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:33.227000 29036 torch/_dynamo/convert_frame.py:964] [0/131]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:33.227000 29036 torch/_dynamo/convert_frame.py:964] [0/131]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:33.227000 29036 torch/_dynamo/convert_frame.py:964] [0/131] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:33.227000 29036 torch/_dynamo/convert_frame.py:964] [0/131] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:33,229 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=87, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,229 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:33,229 - INFO - No valid responses to write for this batch
2025-09-05 17:28:33,239 - GPU-0 - INFO - Completed batch 83, total work units processed by this worker: 1316
2025-09-05 17:28:33,239 - INFO - Completed batch 83, total work units processed by this worker: 1316
2025-09-05 17:28:33,240 - GPU-0 - INFO - Processing batch 84 (16 work units)
2025-09-05 17:28:33,240 - INFO - Processing batch 84 (16 work units)
W0905 17:28:33.336000 29036 torch/_dynamo/convert_frame.py:964] [0/132] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:33.336000 29036 torch/_dynamo/convert_frame.py:964] [0/132]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:33.336000 29036 torch/_dynamo/convert_frame.py:964] [0/132]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:33.336000 29036 torch/_dynamo/convert_frame.py:964] [0/132] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:33.336000 29036 torch/_dynamo/convert_frame.py:964] [0/132] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:33,338 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:33,338 - INFO - Falling back to sequential processing
W0905 17:28:33.390000 29036 torch/_dynamo/convert_frame.py:964] [0/133] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:33.390000 29036 torch/_dynamo/convert_frame.py:964] [0/133]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:33.390000 29036 torch/_dynamo/convert_frame.py:964] [0/133]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:33.390000 29036 torch/_dynamo/convert_frame.py:964] [0/133] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:33.390000 29036 torch/_dynamo/convert_frame.py:964] [0/133] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:33,392 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:33,392 - GPU-0 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,392 - WARNING - Skipping empty response for id=88, magnitude=2800.0
2025-09-05 17:28:33,392 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,392 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=89, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:33,393 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:33,393 - INFO - No valid responses to write for this batch
2025-09-05 17:28:33,403 - GPU-0 - INFO - Completed batch 84, total work units processed by this worker: 1332
2025-09-05 17:28:33,403 - INFO - Completed batch 84, total work units processed by this worker: 1332
2025-09-05 17:28:33,631 - GPU-2 - INFO - Completed batch 24, total work units processed by this worker: 372
2025-09-05 17:28:33,631 - INFO - Completed batch 24, total work units processed by this worker: 372
2025-09-05 17:28:35,105 - GPU-7 - INFO - Processing batch 113 (16 work units)
2025-09-05 17:28:35,105 - INFO - Processing batch 113 (16 work units)
2025-09-05 17:28:35,156 - GPU-4 - INFO - Processing batch 71 (16 work units)
2025-09-05 17:28:35,156 - INFO - Processing batch 71 (16 work units)
W0905 17:28:35.211000 29043 torch/_dynamo/convert_frame.py:964] [0/194] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:35.211000 29043 torch/_dynamo/convert_frame.py:964] [0/194]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:35.211000 29043 torch/_dynamo/convert_frame.py:964] [0/194]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:35.211000 29043 torch/_dynamo/convert_frame.py:964] [0/194] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:35.211000 29043 torch/_dynamo/convert_frame.py:964] [0/194] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:35,213 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:35,213 - INFO - Falling back to sequential processing
W0905 17:28:35.266000 29040 torch/_dynamo/convert_frame.py:964] [0/82] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:35.266000 29040 torch/_dynamo/convert_frame.py:964] [0/82]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:35.266000 29040 torch/_dynamo/convert_frame.py:964] [0/82]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:35.266000 29040 torch/_dynamo/convert_frame.py:964] [0/82] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:35.266000 29040 torch/_dynamo/convert_frame.py:964] [0/82] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
W0905 17:28:35.268000 29043 torch/_dynamo/convert_frame.py:964] [0/195] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:35.268000 29043 torch/_dynamo/convert_frame.py:964] [0/195]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:35.268000 29043 torch/_dynamo/convert_frame.py:964] [0/195]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:35.268000 29043 torch/_dynamo/convert_frame.py:964] [0/195] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:35.268000 29043 torch/_dynamo/convert_frame.py:964] [0/195] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:35,268 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:35,268 - INFO - Falling back to sequential processing
2025-09-05 17:28:35,270 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=90, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=91, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,270 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,270 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:35,270 - INFO - No valid responses to write for this batch
2025-09-05 17:28:35,283 - GPU-1 - INFO - Completed batch 53, total work units processed by this worker: 848
2025-09-05 17:28:35,283 - INFO - Completed batch 53, total work units processed by this worker: 848
2025-09-05 17:28:35,283 - GPU-1 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:28:35,283 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:28:35,286 - GPU-7 - INFO - Completed batch 113, total work units processed by this worker: 1772
2025-09-05 17:28:35,286 - INFO - Completed batch 113, total work units processed by this worker: 1772
2025-09-05 17:28:35,286 - GPU-7 - INFO - Processing batch 114 (16 work units)
2025-09-05 17:28:35,286 - INFO - Processing batch 114 (16 work units)
W0905 17:28:35.323000 29040 torch/_dynamo/convert_frame.py:964] [0/83] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:35.323000 29040 torch/_dynamo/convert_frame.py:964] [0/83]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:35.323000 29040 torch/_dynamo/convert_frame.py:964] [0/83]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:35.323000 29040 torch/_dynamo/convert_frame.py:964] [0/83] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:35.323000 29040 torch/_dynamo/convert_frame.py:964] [0/83] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:35,325 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=92, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=93, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=94, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=94, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - WARNING - Skipping empty response for id=94, magnitude=2800.0
2025-09-05 17:28:35,325 - WARNING - Skipping empty response for id=94, magnitude=2800.0
2025-09-05 17:28:35,325 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:35,325 - INFO - No valid responses to write for this batch
2025-09-05 17:28:35,337 - GPU-4 - INFO - Completed batch 71, total work units processed by this worker: 1112
2025-09-05 17:28:35,337 - INFO - Completed batch 71, total work units processed by this worker: 1112
2025-09-05 17:28:35,337 - GPU-4 - INFO - Processing batch 72 (16 work units)
2025-09-05 17:28:35,337 - INFO - Processing batch 72 (16 work units)
W0905 17:28:35.393000 29043 torch/_dynamo/convert_frame.py:964] [0/196] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:35.393000 29043 torch/_dynamo/convert_frame.py:964] [0/196]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:35.393000 29043 torch/_dynamo/convert_frame.py:964] [0/196]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:35.393000 29043 torch/_dynamo/convert_frame.py:964] [0/196] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:35.393000 29043 torch/_dynamo/convert_frame.py:964] [0/196] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:35,395 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:35,395 - INFO - Falling back to sequential processing
W0905 17:28:35.438000 29040 torch/_dynamo/convert_frame.py:964] [0/84] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:35.438000 29040 torch/_dynamo/convert_frame.py:964] [0/84]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:35.438000 29040 torch/_dynamo/convert_frame.py:964] [0/84]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:35.438000 29040 torch/_dynamo/convert_frame.py:964] [0/84] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:35.438000 29040 torch/_dynamo/convert_frame.py:964] [0/84] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:35,440 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:35,440 - INFO - Falling back to sequential processing
W0905 17:28:35.450000 29043 torch/_dynamo/convert_frame.py:964] [0/197] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:35.450000 29043 torch/_dynamo/convert_frame.py:964] [0/197]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:35.450000 29043 torch/_dynamo/convert_frame.py:964] [0/197]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:35.450000 29043 torch/_dynamo/convert_frame.py:964] [0/197] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:35.450000 29043 torch/_dynamo/convert_frame.py:964] [0/197] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:35,451 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=96, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,452 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:35,452 - INFO - No valid responses to write for this batch
2025-09-05 17:28:35,463 - GPU-7 - INFO - Completed batch 114, total work units processed by this worker: 1788
2025-09-05 17:28:35,463 - INFO - Completed batch 114, total work units processed by this worker: 1788
W0905 17:28:35.494000 29040 torch/_dynamo/convert_frame.py:964] [0/85] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:35.494000 29040 torch/_dynamo/convert_frame.py:964] [0/85]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:35.494000 29040 torch/_dynamo/convert_frame.py:964] [0/85]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:35.494000 29040 torch/_dynamo/convert_frame.py:964] [0/85] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:35.494000 29040 torch/_dynamo/convert_frame.py:964] [0/85] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:35,496 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:35,496 - GPU-4 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,496 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,496 - GPU-4 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,496 - WARNING - Skipping empty response for id=97, magnitude=2800.0
2025-09-05 17:28:35,496 - GPU-4 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,496 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,496 - GPU-4 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,496 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=98, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,497 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,497 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:35,497 - INFO - No valid responses to write for this batch
2025-09-05 17:28:35,508 - GPU-4 - INFO - Completed batch 72, total work units processed by this worker: 1128
2025-09-05 17:28:35,508 - INFO - Completed batch 72, total work units processed by this worker: 1128
2025-09-05 17:28:35,787 - GPU-0 - INFO - Processing batch 85 (4 work units)
2025-09-05 17:28:35,787 - INFO - Processing batch 85 (4 work units)
W0905 17:28:35.849000 29036 torch/_dynamo/convert_frame.py:964] [0/134] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:35.849000 29036 torch/_dynamo/convert_frame.py:964] [0/134]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:35.849000 29036 torch/_dynamo/convert_frame.py:964] [0/134]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:35.849000 29036 torch/_dynamo/convert_frame.py:964] [0/134] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:35.849000 29036 torch/_dynamo/convert_frame.py:964] [0/134] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:35,851 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:35,851 - INFO - Falling back to sequential processing
W0905 17:28:35.910000 29036 torch/_dynamo/convert_frame.py:964] [0/135] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:35.910000 29036 torch/_dynamo/convert_frame.py:964] [0/135]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:35.910000 29036 torch/_dynamo/convert_frame.py:964] [0/135]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:35.910000 29036 torch/_dynamo/convert_frame.py:964] [0/135] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:35.910000 29036 torch/_dynamo/convert_frame.py:964] [0/135] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:35,911 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:35,912 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,912 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,912 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,912 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,912 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,912 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,912 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,912 - WARNING - Skipping empty response for id=99, magnitude=2800.0
2025-09-05 17:28:35,912 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:35,912 - INFO - No valid responses to write for this batch
2025-09-05 17:28:35,913 - GPU-0 - INFO - Completed batch 85, total work units processed by this worker: 1336
2025-09-05 17:28:35,913 - INFO - Completed batch 85, total work units processed by this worker: 1336
2025-09-05 17:28:35,913 - GPU-0 - INFO - Processing batch 86 (16 work units)
2025-09-05 17:28:35,913 - INFO - Processing batch 86 (16 work units)
W0905 17:28:36.002000 29036 torch/_dynamo/convert_frame.py:964] [0/136] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:36.002000 29036 torch/_dynamo/convert_frame.py:964] [0/136]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:36.002000 29036 torch/_dynamo/convert_frame.py:964] [0/136]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:36.002000 29036 torch/_dynamo/convert_frame.py:964] [0/136] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:36.002000 29036 torch/_dynamo/convert_frame.py:964] [0/136] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:36,004 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:36,004 - INFO - Falling back to sequential processing
W0905 17:28:36.057000 29036 torch/_dynamo/convert_frame.py:964] [0/137] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:36.057000 29036 torch/_dynamo/convert_frame.py:964] [0/137]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:36.057000 29036 torch/_dynamo/convert_frame.py:964] [0/137]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:36.057000 29036 torch/_dynamo/convert_frame.py:964] [0/137] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:36.057000 29036 torch/_dynamo/convert_frame.py:964] [0/137] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:36,059 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:36,059 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,059 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,059 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,059 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,059 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,059 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,059 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,059 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=0, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - WARNING - Skipping empty response for id=1, magnitude=3200.0
2025-09-05 17:28:36,060 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:36,060 - INFO - No valid responses to write for this batch
2025-09-05 17:28:36,074 - GPU-0 - INFO - Completed batch 86, total work units processed by this worker: 1352
2025-09-05 17:28:36,074 - INFO - Completed batch 86, total work units processed by this worker: 1352
2025-09-05 17:28:36,324 - GPU-2 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:28:36,324 - INFO - Processing batch 25 (16 work units)
2025-09-05 17:28:36,938 - GPU-3 - INFO - Completed batch 53, total work units processed by this worker: 848
2025-09-05 17:28:36,938 - INFO - Completed batch 53, total work units processed by this worker: 848
2025-09-05 17:28:36,938 - GPU-3 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:28:36,938 - INFO - Processing batch 54 (16 work units)
2025-09-05 17:28:37,825 - GPU-7 - INFO - Processing batch 115 (16 work units)
2025-09-05 17:28:37,825 - INFO - Processing batch 115 (16 work units)
2025-09-05 17:28:37,840 - GPU-4 - INFO - Processing batch 73 (16 work units)
2025-09-05 17:28:37,840 - INFO - Processing batch 73 (16 work units)
W0905 17:28:37.928000 29043 torch/_dynamo/convert_frame.py:964] [0/198] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:37.928000 29043 torch/_dynamo/convert_frame.py:964] [0/198]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:37.928000 29043 torch/_dynamo/convert_frame.py:964] [0/198]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:37.928000 29043 torch/_dynamo/convert_frame.py:964] [0/198] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:37.928000 29043 torch/_dynamo/convert_frame.py:964] [0/198] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:37,930 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:37,930 - INFO - Falling back to sequential processing
W0905 17:28:37.942000 29040 torch/_dynamo/convert_frame.py:964] [0/86] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:37.942000 29040 torch/_dynamo/convert_frame.py:964] [0/86]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:37.942000 29040 torch/_dynamo/convert_frame.py:964] [0/86]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:37.942000 29040 torch/_dynamo/convert_frame.py:964] [0/86] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:37.942000 29040 torch/_dynamo/convert_frame.py:964] [0/86] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:37,944 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:37,944 - INFO - Falling back to sequential processing
W0905 17:28:37.985000 29043 torch/_dynamo/convert_frame.py:964] [0/199] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:37.985000 29043 torch/_dynamo/convert_frame.py:964] [0/199]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:37.985000 29043 torch/_dynamo/convert_frame.py:964] [0/199]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:37.985000 29043 torch/_dynamo/convert_frame.py:964] [0/199] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:37.985000 29043 torch/_dynamo/convert_frame.py:964] [0/199] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:37,987 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=5, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,987 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,988 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,988 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,988 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,988 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,988 - GPU-7 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,988 - WARNING - Skipping empty response for id=6, magnitude=3200.0
2025-09-05 17:28:37,988 - GPU-7 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:37,988 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:37,988 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:37,988 - INFO - No valid responses to write for this batch
2025-09-05 17:28:37,999 - GPU-7 - INFO - Completed batch 115, total work units processed by this worker: 1804
2025-09-05 17:28:37,999 - INFO - Completed batch 115, total work units processed by this worker: 1804
2025-09-05 17:28:37,999 - GPU-7 - INFO - Processing batch 116 (16 work units)
2025-09-05 17:28:37,999 - INFO - Processing batch 116 (16 work units)
W0905 17:28:37.999000 29040 torch/_dynamo/convert_frame.py:964] [0/87] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:37.999000 29040 torch/_dynamo/convert_frame.py:964] [0/87]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:37.999000 29040 torch/_dynamo/convert_frame.py:964] [0/87]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:37.999000 29040 torch/_dynamo/convert_frame.py:964] [0/87] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:37.999000 29040 torch/_dynamo/convert_frame.py:964] [0/87] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:38,001 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:38,001 - GPU-4 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - GPU-4 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - GPU-4 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - GPU-4 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - GPU-4 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - GPU-4 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - GPU-4 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - GPU-4 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - WARNING - Skipping empty response for id=7, magnitude=3200.0
2025-09-05 17:28:38,001 - GPU-4 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,001 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - GPU-4 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - GPU-4 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - GPU-4 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - GPU-4 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - GPU-4 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - GPU-4 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - GPU-4 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,002 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:38,002 - INFO - No valid responses to write for this batch
2025-09-05 17:28:38,016 - GPU-4 - INFO - Completed batch 73, total work units processed by this worker: 1144
2025-09-05 17:28:38,016 - INFO - Completed batch 73, total work units processed by this worker: 1144
2025-09-05 17:28:38,016 - GPU-4 - INFO - Processing batch 74 (16 work units)
2025-09-05 17:28:38,016 - INFO - Processing batch 74 (16 work units)
W0905 17:28:38.100000 29043 torch/_dynamo/convert_frame.py:964] [0/200] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:38.100000 29043 torch/_dynamo/convert_frame.py:964] [0/200]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:38.100000 29043 torch/_dynamo/convert_frame.py:964] [0/200]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:38.100000 29043 torch/_dynamo/convert_frame.py:964] [0/200] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:38.100000 29043 torch/_dynamo/convert_frame.py:964] [0/200] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:38,102 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:38,102 - INFO - Falling back to sequential processing
W0905 17:28:38.111000 29040 torch/_dynamo/convert_frame.py:964] [0/88] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:38.111000 29040 torch/_dynamo/convert_frame.py:964] [0/88]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:38.111000 29040 torch/_dynamo/convert_frame.py:964] [0/88]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:38.111000 29040 torch/_dynamo/convert_frame.py:964] [0/88] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:38.111000 29040 torch/_dynamo/convert_frame.py:964] [0/88] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:38,113 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:38,113 - INFO - Falling back to sequential processing
W0905 17:28:38.156000 29043 torch/_dynamo/convert_frame.py:964] [0/201] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:38.156000 29043 torch/_dynamo/convert_frame.py:964] [0/201]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:38.156000 29043 torch/_dynamo/convert_frame.py:964] [0/201]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:38.156000 29043 torch/_dynamo/convert_frame.py:964] [0/201] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:38.156000 29043 torch/_dynamo/convert_frame.py:964] [0/201] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:38,158 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:38,158 - GPU-7 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,158 - WARNING - Skipping empty response for id=8, magnitude=3200.0
2025-09-05 17:28:38,158 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,158 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,159 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,159 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,159 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,159 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,159 - GPU-7 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,159 - WARNING - Skipping empty response for id=9, magnitude=3200.0
2025-09-05 17:28:38,159 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - GPU-7 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,159 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:38,159 - INFO - No valid responses to write for this batch
W0905 17:28:38.167000 29040 torch/_dynamo/convert_frame.py:964] [0/89] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:38.167000 29040 torch/_dynamo/convert_frame.py:964] [0/89]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:38.167000 29040 torch/_dynamo/convert_frame.py:964] [0/89]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:38.167000 29040 torch/_dynamo/convert_frame.py:964] [0/89] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:38.167000 29040 torch/_dynamo/convert_frame.py:964] [0/89] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:38,169 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:38,169 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,169 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,169 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,169 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=10, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=11, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,170 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,170 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:38,170 - INFO - No valid responses to write for this batch
2025-09-05 17:28:38,170 - GPU-7 - INFO - Completed batch 116, total work units processed by this worker: 1820
2025-09-05 17:28:38,170 - INFO - Completed batch 116, total work units processed by this worker: 1820
2025-09-05 17:28:38,181 - GPU-4 - INFO - Completed batch 74, total work units processed by this worker: 1160
2025-09-05 17:28:38,181 - INFO - Completed batch 74, total work units processed by this worker: 1160
2025-09-05 17:28:38,359 - GPU-0 - INFO - Processing batch 87 (16 work units)
2025-09-05 17:28:38,359 - INFO - Processing batch 87 (16 work units)
W0905 17:28:38.462000 29036 torch/_dynamo/convert_frame.py:964] [0/138] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:38.462000 29036 torch/_dynamo/convert_frame.py:964] [0/138]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:38.462000 29036 torch/_dynamo/convert_frame.py:964] [0/138]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:38.462000 29036 torch/_dynamo/convert_frame.py:964] [0/138] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:38.462000 29036 torch/_dynamo/convert_frame.py:964] [0/138] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:38,464 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:38,464 - INFO - Falling back to sequential processing
W0905 17:28:38.516000 29036 torch/_dynamo/convert_frame.py:964] [0/139] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:38.516000 29036 torch/_dynamo/convert_frame.py:964] [0/139]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:38.516000 29036 torch/_dynamo/convert_frame.py:964] [0/139]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:38.516000 29036 torch/_dynamo/convert_frame.py:964] [0/139] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:38.516000 29036 torch/_dynamo/convert_frame.py:964] [0/139] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:38,518 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=12, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=13, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,518 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,518 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:38,518 - INFO - No valid responses to write for this batch
2025-09-05 17:28:38,529 - GPU-0 - INFO - Completed batch 87, total work units processed by this worker: 1368
2025-09-05 17:28:38,529 - INFO - Completed batch 87, total work units processed by this worker: 1368
2025-09-05 17:28:38,529 - GPU-0 - INFO - Processing batch 88 (16 work units)
2025-09-05 17:28:38,529 - INFO - Processing batch 88 (16 work units)
W0905 17:28:38.629000 29036 torch/_dynamo/convert_frame.py:964] [0/140] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:38.629000 29036 torch/_dynamo/convert_frame.py:964] [0/140]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:38.629000 29036 torch/_dynamo/convert_frame.py:964] [0/140]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:38.629000 29036 torch/_dynamo/convert_frame.py:964] [0/140] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:38.629000 29036 torch/_dynamo/convert_frame.py:964] [0/140] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:38,630 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:38,630 - INFO - Falling back to sequential processing
W0905 17:28:38.683000 29036 torch/_dynamo/convert_frame.py:964] [0/141] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:38.683000 29036 torch/_dynamo/convert_frame.py:964] [0/141]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:38.683000 29036 torch/_dynamo/convert_frame.py:964] [0/141]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:38.683000 29036 torch/_dynamo/convert_frame.py:964] [0/141] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:38.683000 29036 torch/_dynamo/convert_frame.py:964] [0/141] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:38,685 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=14, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - WARNING - Skipping empty response for id=15, magnitude=3200.0
2025-09-05 17:28:38,685 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:38,685 - INFO - No valid responses to write for this batch
2025-09-05 17:28:38,695 - GPU-0 - INFO - Completed batch 88, total work units processed by this worker: 1384
2025-09-05 17:28:38,695 - INFO - Completed batch 88, total work units processed by this worker: 1384
2025-09-05 17:28:40,269 - GPU-5 - INFO - Completed batch 57, total work units processed by this worker: 912
2025-09-05 17:28:40,269 - INFO - Completed batch 57, total work units processed by this worker: 912
2025-09-05 17:28:40,269 - GPU-5 - INFO - Processing batch 58 (16 work units)
2025-09-05 17:28:40,269 - INFO - Processing batch 58 (16 work units)
2025-09-05 17:28:40,505 - GPU-7 - INFO - Processing batch 117 (16 work units)
2025-09-05 17:28:40,505 - INFO - Processing batch 117 (16 work units)
2025-09-05 17:28:40,533 - GPU-4 - INFO - Processing batch 75 (16 work units)
2025-09-05 17:28:40,533 - INFO - Processing batch 75 (16 work units)
W0905 17:28:40.603000 29043 torch/_dynamo/convert_frame.py:964] [0/202] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:40.603000 29043 torch/_dynamo/convert_frame.py:964] [0/202]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:40.603000 29043 torch/_dynamo/convert_frame.py:964] [0/202]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:40.603000 29043 torch/_dynamo/convert_frame.py:964] [0/202] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:40.603000 29043 torch/_dynamo/convert_frame.py:964] [0/202] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:40,605 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:40,605 - INFO - Falling back to sequential processing
W0905 17:28:40.630000 29040 torch/_dynamo/convert_frame.py:964] [0/90] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:40.630000 29040 torch/_dynamo/convert_frame.py:964] [0/90]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:40.630000 29040 torch/_dynamo/convert_frame.py:964] [0/90]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:40.630000 29040 torch/_dynamo/convert_frame.py:964] [0/90] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:40.630000 29040 torch/_dynamo/convert_frame.py:964] [0/90] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:40,632 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:40,632 - INFO - Falling back to sequential processing
W0905 17:28:40.659000 29043 torch/_dynamo/convert_frame.py:964] [0/203] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:40.659000 29043 torch/_dynamo/convert_frame.py:964] [0/203]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:40.659000 29043 torch/_dynamo/convert_frame.py:964] [0/203]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:40.659000 29043 torch/_dynamo/convert_frame.py:964] [0/203] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:40.659000 29043 torch/_dynamo/convert_frame.py:964] [0/203] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:40,661 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:40,661 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=3200.0
2025-09-05 17:28:40,661 - WARNING - Skipping empty response for id=17, magnitude=3200.0
2025-09-05 17:28:40,661 - GPU-7 - WARNING - Skipping empty response for id=17, magnitude=3200.0
2025-09-05 17:28:40,661 - WARNING - Skipping empty response for id=17, magnitude=3200.0
2025-09-05 17:28:40,661 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,661 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=18, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,662 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,662 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:40,662 - INFO - No valid responses to write for this batch
2025-09-05 17:28:40,673 - GPU-7 - INFO - Completed batch 117, total work units processed by this worker: 1836
2025-09-05 17:28:40,673 - INFO - Completed batch 117, total work units processed by this worker: 1836
2025-09-05 17:28:40,673 - GPU-7 - INFO - Processing batch 118 (16 work units)
2025-09-05 17:28:40,673 - INFO - Processing batch 118 (16 work units)
W0905 17:28:40.688000 29040 torch/_dynamo/convert_frame.py:964] [0/91] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:40.688000 29040 torch/_dynamo/convert_frame.py:964] [0/91]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:40.688000 29040 torch/_dynamo/convert_frame.py:964] [0/91]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:40.688000 29040 torch/_dynamo/convert_frame.py:964] [0/91] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:40.688000 29040 torch/_dynamo/convert_frame.py:964] [0/91] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:40,690 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=19, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=20, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,690 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,690 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:40,690 - INFO - No valid responses to write for this batch
2025-09-05 17:28:40,702 - GPU-4 - INFO - Completed batch 75, total work units processed by this worker: 1176
2025-09-05 17:28:40,702 - INFO - Completed batch 75, total work units processed by this worker: 1176
2025-09-05 17:28:40,702 - GPU-4 - INFO - Processing batch 76 (16 work units)
2025-09-05 17:28:40,702 - INFO - Processing batch 76 (16 work units)
W0905 17:28:40.769000 29043 torch/_dynamo/convert_frame.py:964] [0/204] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:40.769000 29043 torch/_dynamo/convert_frame.py:964] [0/204]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:40.769000 29043 torch/_dynamo/convert_frame.py:964] [0/204]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:40.769000 29043 torch/_dynamo/convert_frame.py:964] [0/204] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:40.769000 29043 torch/_dynamo/convert_frame.py:964] [0/204] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:40,770 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:40,770 - INFO - Falling back to sequential processing
W0905 17:28:40.795000 29040 torch/_dynamo/convert_frame.py:964] [0/92] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:40.795000 29040 torch/_dynamo/convert_frame.py:964] [0/92]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:40.795000 29040 torch/_dynamo/convert_frame.py:964] [0/92]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:40.795000 29040 torch/_dynamo/convert_frame.py:964] [0/92] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:40.795000 29040 torch/_dynamo/convert_frame.py:964] [0/92] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:40,796 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:40,797 - INFO - Falling back to sequential processing
W0905 17:28:40.825000 29043 torch/_dynamo/convert_frame.py:964] [0/205] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:40.825000 29043 torch/_dynamo/convert_frame.py:964] [0/205]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:40.825000 29043 torch/_dynamo/convert_frame.py:964] [0/205]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:40.825000 29043 torch/_dynamo/convert_frame.py:964] [0/205] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:40.825000 29043 torch/_dynamo/convert_frame.py:964] [0/205] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:40,827 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=21, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=22, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,827 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,827 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:40,827 - INFO - No valid responses to write for this batch
2025-09-05 17:28:40,838 - GPU-7 - INFO - Completed batch 118, total work units processed by this worker: 1852
2025-09-05 17:28:40,838 - INFO - Completed batch 118, total work units processed by this worker: 1852
W0905 17:28:40.851000 29040 torch/_dynamo/convert_frame.py:964] [0/93] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:40.851000 29040 torch/_dynamo/convert_frame.py:964] [0/93]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:40.851000 29040 torch/_dynamo/convert_frame.py:964] [0/93]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:40.851000 29040 torch/_dynamo/convert_frame.py:964] [0/93] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:40.851000 29040 torch/_dynamo/convert_frame.py:964] [0/93] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:40,853 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=23, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:40,853 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:40,853 - INFO - No valid responses to write for this batch
2025-09-05 17:28:40,864 - GPU-4 - INFO - Completed batch 76, total work units processed by this worker: 1192
2025-09-05 17:28:40,864 - INFO - Completed batch 76, total work units processed by this worker: 1192
2025-09-05 17:28:40,925 - GPU-0 - INFO - Processing batch 89 (16 work units)
2025-09-05 17:28:40,925 - INFO - Processing batch 89 (16 work units)
W0905 17:28:41.028000 29036 torch/_dynamo/convert_frame.py:964] [0/142] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:41.028000 29036 torch/_dynamo/convert_frame.py:964] [0/142]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:41.028000 29036 torch/_dynamo/convert_frame.py:964] [0/142]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:41.028000 29036 torch/_dynamo/convert_frame.py:964] [0/142] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:41.028000 29036 torch/_dynamo/convert_frame.py:964] [0/142] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:41,030 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:41,030 - INFO - Falling back to sequential processing
W0905 17:28:41.082000 29036 torch/_dynamo/convert_frame.py:964] [0/143] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:41.082000 29036 torch/_dynamo/convert_frame.py:964] [0/143]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:41.082000 29036 torch/_dynamo/convert_frame.py:964] [0/143]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:41.082000 29036 torch/_dynamo/convert_frame.py:964] [0/143] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:41.082000 29036 torch/_dynamo/convert_frame.py:964] [0/143] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:41,084 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:41,084 - GPU-0 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:41,084 - WARNING - Skipping empty response for id=24, magnitude=3200.0
2025-09-05 17:28:41,084 - GPU-0 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,084 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=25, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,085 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:41,085 - INFO - No valid responses to write for this batch
2025-09-05 17:28:41,095 - GPU-0 - INFO - Completed batch 89, total work units processed by this worker: 1400
2025-09-05 17:28:41,095 - INFO - Completed batch 89, total work units processed by this worker: 1400
2025-09-05 17:28:41,096 - GPU-0 - INFO - Processing batch 90 (16 work units)
2025-09-05 17:28:41,096 - INFO - Processing batch 90 (16 work units)
W0905 17:28:41.196000 29036 torch/_dynamo/convert_frame.py:964] [0/144] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:41.196000 29036 torch/_dynamo/convert_frame.py:964] [0/144]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:41.196000 29036 torch/_dynamo/convert_frame.py:964] [0/144]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:41.196000 29036 torch/_dynamo/convert_frame.py:964] [0/144] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:41.196000 29036 torch/_dynamo/convert_frame.py:964] [0/144] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:41,198 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:41,198 - INFO - Falling back to sequential processing
W0905 17:28:41.250000 29036 torch/_dynamo/convert_frame.py:964] [0/145] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:41.250000 29036 torch/_dynamo/convert_frame.py:964] [0/145]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:41.250000 29036 torch/_dynamo/convert_frame.py:964] [0/145]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:41.250000 29036 torch/_dynamo/convert_frame.py:964] [0/145] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:41.250000 29036 torch/_dynamo/convert_frame.py:964] [0/145] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:41,252 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=26, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=27, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:41,252 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:41,252 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:41,252 - INFO - No valid responses to write for this batch
2025-09-05 17:28:41,262 - GPU-0 - INFO - Completed batch 90, total work units processed by this worker: 1416
2025-09-05 17:28:41,262 - INFO - Completed batch 90, total work units processed by this worker: 1416
2025-09-05 17:28:43,191 - GPU-7 - INFO - Processing batch 119 (16 work units)
2025-09-05 17:28:43,191 - INFO - Processing batch 119 (16 work units)
2025-09-05 17:28:43,213 - GPU-4 - INFO - Processing batch 77 (16 work units)
2025-09-05 17:28:43,213 - INFO - Processing batch 77 (16 work units)
W0905 17:28:43.289000 29043 torch/_dynamo/convert_frame.py:964] [0/206] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.289000 29043 torch/_dynamo/convert_frame.py:964] [0/206]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.289000 29043 torch/_dynamo/convert_frame.py:964] [0/206]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:43.289000 29043 torch/_dynamo/convert_frame.py:964] [0/206] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.289000 29043 torch/_dynamo/convert_frame.py:964] [0/206] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:43,291 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,291 - INFO - Falling back to sequential processing
W0905 17:28:43.310000 29040 torch/_dynamo/convert_frame.py:964] [0/94] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.310000 29040 torch/_dynamo/convert_frame.py:964] [0/94]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.310000 29040 torch/_dynamo/convert_frame.py:964] [0/94]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:43.310000 29040 torch/_dynamo/convert_frame.py:964] [0/94] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.310000 29040 torch/_dynamo/convert_frame.py:964] [0/94] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:43,312 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,312 - INFO - Falling back to sequential processing
W0905 17:28:43.346000 29043 torch/_dynamo/convert_frame.py:964] [0/207] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.346000 29043 torch/_dynamo/convert_frame.py:964] [0/207]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.346000 29043 torch/_dynamo/convert_frame.py:964] [0/207]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:43.346000 29043 torch/_dynamo/convert_frame.py:964] [0/207] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.346000 29043 torch/_dynamo/convert_frame.py:964] [0/207] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:43,348 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,348 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:43,348 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=28, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=29, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,349 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,349 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,349 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,360 - GPU-7 - INFO - Completed batch 119, total work units processed by this worker: 1868
2025-09-05 17:28:43,360 - INFO - Completed batch 119, total work units processed by this worker: 1868
2025-09-05 17:28:43,360 - GPU-7 - INFO - Processing batch 120 (16 work units)
2025-09-05 17:28:43,360 - INFO - Processing batch 120 (16 work units)
W0905 17:28:43.368000 29040 torch/_dynamo/convert_frame.py:964] [0/95] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.368000 29040 torch/_dynamo/convert_frame.py:964] [0/95]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.368000 29040 torch/_dynamo/convert_frame.py:964] [0/95]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:43.368000 29040 torch/_dynamo/convert_frame.py:964] [0/95] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.368000 29040 torch/_dynamo/convert_frame.py:964] [0/95] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:43,370 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,370 - GPU-4 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - GPU-4 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - GPU-4 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - GPU-4 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - GPU-4 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - GPU-4 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,370 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,371 - WARNING - Skipping empty response for id=30, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - WARNING - Skipping empty response for id=31, magnitude=3200.0
2025-09-05 17:28:43,371 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,371 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,384 - GPU-4 - INFO - Completed batch 77, total work units processed by this worker: 1208
2025-09-05 17:28:43,384 - INFO - Completed batch 77, total work units processed by this worker: 1208
2025-09-05 17:28:43,385 - GPU-4 - INFO - Processing batch 78 (16 work units)
2025-09-05 17:28:43,385 - INFO - Processing batch 78 (16 work units)
2025-09-05 17:28:43,386 - GPU-0 - INFO - Processing batch 91 (16 work units)
2025-09-05 17:28:43,386 - INFO - Processing batch 91 (16 work units)
W0905 17:28:43.458000 29043 torch/_dynamo/convert_frame.py:964] [0/208] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.458000 29043 torch/_dynamo/convert_frame.py:964] [0/208]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.458000 29043 torch/_dynamo/convert_frame.py:964] [0/208]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:43.458000 29043 torch/_dynamo/convert_frame.py:964] [0/208] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.458000 29043 torch/_dynamo/convert_frame.py:964] [0/208] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:43,460 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,460 - INFO - Falling back to sequential processing
W0905 17:28:43.498000 29040 torch/_dynamo/convert_frame.py:964] [0/96] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.498000 29040 torch/_dynamo/convert_frame.py:964] [0/96]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.498000 29040 torch/_dynamo/convert_frame.py:964] [0/96]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:43.498000 29040 torch/_dynamo/convert_frame.py:964] [0/96] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.498000 29040 torch/_dynamo/convert_frame.py:964] [0/96] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
W0905 17:28:43.499000 29036 torch/_dynamo/convert_frame.py:964] [0/146] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.499000 29036 torch/_dynamo/convert_frame.py:964] [0/146]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.499000 29036 torch/_dynamo/convert_frame.py:964] [0/146]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:43.499000 29036 torch/_dynamo/convert_frame.py:964] [0/146] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.499000 29036 torch/_dynamo/convert_frame.py:964] [0/146] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:43,500 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,500 - INFO - Falling back to sequential processing
2025-09-05 17:28:43,501 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,502 - INFO - Falling back to sequential processing
W0905 17:28:43.515000 29043 torch/_dynamo/convert_frame.py:964] [0/209] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.515000 29043 torch/_dynamo/convert_frame.py:964] [0/209]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.515000 29043 torch/_dynamo/convert_frame.py:964] [0/209]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:43.515000 29043 torch/_dynamo/convert_frame.py:964] [0/209] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.515000 29043 torch/_dynamo/convert_frame.py:964] [0/209] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:43,517 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=32, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,517 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,517 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,528 - GPU-7 - INFO - Completed batch 120, total work units processed by this worker: 1884
2025-09-05 17:28:43,528 - INFO - Completed batch 120, total work units processed by this worker: 1884
W0905 17:28:43.554000 29036 torch/_dynamo/convert_frame.py:964] [0/147] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.554000 29036 torch/_dynamo/convert_frame.py:964] [0/147]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.554000 29036 torch/_dynamo/convert_frame.py:964] [0/147]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:43.554000 29036 torch/_dynamo/convert_frame.py:964] [0/147] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.554000 29036 torch/_dynamo/convert_frame.py:964] [0/147] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
W0905 17:28:43.555000 29040 torch/_dynamo/convert_frame.py:964] [0/97] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.555000 29040 torch/_dynamo/convert_frame.py:964] [0/97]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.555000 29040 torch/_dynamo/convert_frame.py:964] [0/97]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:43.555000 29040 torch/_dynamo/convert_frame.py:964] [0/97] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.555000 29040 torch/_dynamo/convert_frame.py:964] [0/97] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:43,556 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=36, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,556 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,556 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,556 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,557 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=33, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=34, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,557 - WARNING - Skipping empty response for id=35, magnitude=3200.0
2025-09-05 17:28:43,557 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,557 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,576 - GPU-0 - INFO - Completed batch 91, total work units processed by this worker: 1432
2025-09-05 17:28:43,576 - INFO - Completed batch 91, total work units processed by this worker: 1432
2025-09-05 17:28:43,577 - GPU-0 - INFO - Processing batch 92 (16 work units)
2025-09-05 17:28:43,577 - INFO - Processing batch 92 (16 work units)
2025-09-05 17:28:43,577 - GPU-4 - INFO - Completed batch 78, total work units processed by this worker: 1224
2025-09-05 17:28:43,577 - INFO - Completed batch 78, total work units processed by this worker: 1224
W0905 17:28:43.669000 29036 torch/_dynamo/convert_frame.py:964] [0/148] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.669000 29036 torch/_dynamo/convert_frame.py:964] [0/148]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.669000 29036 torch/_dynamo/convert_frame.py:964] [0/148]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:43.669000 29036 torch/_dynamo/convert_frame.py:964] [0/148] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.669000 29036 torch/_dynamo/convert_frame.py:964] [0/148] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:43,671 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,671 - INFO - Falling back to sequential processing
W0905 17:28:43.723000 29036 torch/_dynamo/convert_frame.py:964] [0/149] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:43.723000 29036 torch/_dynamo/convert_frame.py:964] [0/149]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:43.723000 29036 torch/_dynamo/convert_frame.py:964] [0/149]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:43.723000 29036 torch/_dynamo/convert_frame.py:964] [0/149] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:43.723000 29036 torch/_dynamo/convert_frame.py:964] [0/149] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:43,725 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=37, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=38, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:43,725 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:43,725 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,725 - INFO - No valid responses to write for this batch
2025-09-05 17:28:43,735 - GPU-0 - INFO - Completed batch 92, total work units processed by this worker: 1448
2025-09-05 17:28:43,735 - INFO - Completed batch 92, total work units processed by this worker: 1448
2025-09-05 17:28:45,809 - GPU-0 - INFO - Processing batch 93 (16 work units)
2025-09-05 17:28:45,809 - INFO - Processing batch 93 (16 work units)
2025-09-05 17:28:45,853 - GPU-7 - INFO - Processing batch 121 (16 work units)
2025-09-05 17:28:45,853 - INFO - Processing batch 121 (16 work units)
2025-09-05 17:28:45,903 - GPU-4 - INFO - Processing batch 79 (16 work units)
2025-09-05 17:28:45,903 - INFO - Processing batch 79 (16 work units)
W0905 17:28:45.911000 29036 torch/_dynamo/convert_frame.py:964] [0/150] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:45.911000 29036 torch/_dynamo/convert_frame.py:964] [0/150]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:45.911000 29036 torch/_dynamo/convert_frame.py:964] [0/150]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:45.911000 29036 torch/_dynamo/convert_frame.py:964] [0/150] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:45.911000 29036 torch/_dynamo/convert_frame.py:964] [0/150] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:45,913 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:45,913 - INFO - Falling back to sequential processing
W0905 17:28:45.957000 29043 torch/_dynamo/convert_frame.py:964] [0/210] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:45.957000 29043 torch/_dynamo/convert_frame.py:964] [0/210]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:45.957000 29043 torch/_dynamo/convert_frame.py:964] [0/210]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:45.957000 29043 torch/_dynamo/convert_frame.py:964] [0/210] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:45.957000 29043 torch/_dynamo/convert_frame.py:964] [0/210] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:45,959 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:45,959 - INFO - Falling back to sequential processing
W0905 17:28:45.965000 29036 torch/_dynamo/convert_frame.py:964] [0/151] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:45.965000 29036 torch/_dynamo/convert_frame.py:964] [0/151]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:45.965000 29036 torch/_dynamo/convert_frame.py:964] [0/151]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:45.965000 29036 torch/_dynamo/convert_frame.py:964] [0/151] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:45.965000 29036 torch/_dynamo/convert_frame.py:964] [0/151] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:45,967 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:45,967 - GPU-0 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - GPU-0 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - GPU-0 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - GPU-0 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - GPU-0 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - GPU-0 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - GPU-0 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - GPU-0 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,967 - WARNING - Skipping empty response for id=39, magnitude=3200.0
2025-09-05 17:28:45,968 - GPU-0 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - GPU-0 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - GPU-0 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - GPU-0 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - GPU-0 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - GPU-0 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - GPU-0 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - GPU-0 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:45,968 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:45,968 - INFO - No valid responses to write for this batch
2025-09-05 17:28:45,978 - GPU-0 - INFO - Completed batch 93, total work units processed by this worker: 1464
2025-09-05 17:28:45,978 - INFO - Completed batch 93, total work units processed by this worker: 1464
2025-09-05 17:28:45,978 - GPU-0 - INFO - Processing batch 94 (16 work units)
2025-09-05 17:28:45,978 - INFO - Processing batch 94 (16 work units)
W0905 17:28:46.003000 29040 torch/_dynamo/convert_frame.py:964] [0/98] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:46.003000 29040 torch/_dynamo/convert_frame.py:964] [0/98]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:46.003000 29040 torch/_dynamo/convert_frame.py:964] [0/98]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:46.003000 29040 torch/_dynamo/convert_frame.py:964] [0/98] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:46.003000 29040 torch/_dynamo/convert_frame.py:964] [0/98] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:46,005 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:46,005 - INFO - Falling back to sequential processing
W0905 17:28:46.014000 29043 torch/_dynamo/convert_frame.py:964] [0/211] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:46.014000 29043 torch/_dynamo/convert_frame.py:964] [0/211]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:46.014000 29043 torch/_dynamo/convert_frame.py:964] [0/211]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:46.014000 29043 torch/_dynamo/convert_frame.py:964] [0/211] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:46.014000 29043 torch/_dynamo/convert_frame.py:964] [0/211] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:46,015 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=40, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=41, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,016 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:46,016 - INFO - No valid responses to write for this batch
2025-09-05 17:28:46,027 - GPU-7 - INFO - Completed batch 121, total work units processed by this worker: 1900
2025-09-05 17:28:46,027 - INFO - Completed batch 121, total work units processed by this worker: 1900
2025-09-05 17:28:46,027 - GPU-7 - INFO - Processing batch 122 (16 work units)
2025-09-05 17:28:46,027 - INFO - Processing batch 122 (16 work units)
W0905 17:28:46.060000 29040 torch/_dynamo/convert_frame.py:964] [0/99] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:46.060000 29040 torch/_dynamo/convert_frame.py:964] [0/99]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:46.060000 29040 torch/_dynamo/convert_frame.py:964] [0/99]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:46.060000 29040 torch/_dynamo/convert_frame.py:964] [0/99] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:46.060000 29040 torch/_dynamo/convert_frame.py:964] [0/99] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:46,062 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=42, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=43, magnitude=3200.0
2025-09-05 17:28:46,062 - GPU-4 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,062 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,063 - GPU-4 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,063 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,063 - GPU-4 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,063 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,063 - GPU-4 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,063 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,063 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:46,063 - INFO - No valid responses to write for this batch
2025-09-05 17:28:46,074 - GPU-4 - INFO - Completed batch 79, total work units processed by this worker: 1240
2025-09-05 17:28:46,074 - INFO - Completed batch 79, total work units processed by this worker: 1240
2025-09-05 17:28:46,074 - GPU-4 - INFO - Processing batch 80 (16 work units)
2025-09-05 17:28:46,074 - INFO - Processing batch 80 (16 work units)
W0905 17:28:46.074000 29036 torch/_dynamo/convert_frame.py:964] [0/152] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:46.074000 29036 torch/_dynamo/convert_frame.py:964] [0/152]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:46.074000 29036 torch/_dynamo/convert_frame.py:964] [0/152]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:46.074000 29036 torch/_dynamo/convert_frame.py:964] [0/152] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:46.074000 29036 torch/_dynamo/convert_frame.py:964] [0/152] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:46,076 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:46,076 - INFO - Falling back to sequential processing
W0905 17:28:46.120000 29043 torch/_dynamo/convert_frame.py:964] [0/212] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:46.120000 29043 torch/_dynamo/convert_frame.py:964] [0/212]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:46.120000 29043 torch/_dynamo/convert_frame.py:964] [0/212]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:46.120000 29043 torch/_dynamo/convert_frame.py:964] [0/212] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:46.120000 29043 torch/_dynamo/convert_frame.py:964] [0/212] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:46,122 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:46,122 - INFO - Falling back to sequential processing
W0905 17:28:46.128000 29036 torch/_dynamo/convert_frame.py:964] [0/153] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:46.128000 29036 torch/_dynamo/convert_frame.py:964] [0/153]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:46.128000 29036 torch/_dynamo/convert_frame.py:964] [0/153]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:46.128000 29036 torch/_dynamo/convert_frame.py:964] [0/153] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:46.128000 29036 torch/_dynamo/convert_frame.py:964] [0/153] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:46,130 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:46,130 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,130 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,130 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,130 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,130 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,130 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,130 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,130 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,130 - GPU-0 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,130 - WARNING - Skipping empty response for id=44, magnitude=3200.0
2025-09-05 17:28:46,130 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,130 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,130 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,130 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - GPU-0 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - WARNING - Skipping empty response for id=45, magnitude=3200.0
2025-09-05 17:28:46,131 - GPU-0 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,131 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,131 - GPU-0 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,131 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,131 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:46,131 - INFO - No valid responses to write for this batch
2025-09-05 17:28:46,141 - GPU-0 - INFO - Completed batch 94, total work units processed by this worker: 1480
2025-09-05 17:28:46,141 - INFO - Completed batch 94, total work units processed by this worker: 1480
W0905 17:28:46.173000 29040 torch/_dynamo/convert_frame.py:964] [0/100] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:46.173000 29040 torch/_dynamo/convert_frame.py:964] [0/100]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:46.173000 29040 torch/_dynamo/convert_frame.py:964] [0/100]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:46.173000 29040 torch/_dynamo/convert_frame.py:964] [0/100] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:46.173000 29040 torch/_dynamo/convert_frame.py:964] [0/100] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:46,175 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:46,175 - INFO - Falling back to sequential processing
W0905 17:28:46.176000 29043 torch/_dynamo/convert_frame.py:964] [0/213] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:46.176000 29043 torch/_dynamo/convert_frame.py:964] [0/213]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:46.176000 29043 torch/_dynamo/convert_frame.py:964] [0/213]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:46.176000 29043 torch/_dynamo/convert_frame.py:964] [0/213] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:46.176000 29043 torch/_dynamo/convert_frame.py:964] [0/213] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:46,178 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=46, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - WARNING - Skipping empty response for id=47, magnitude=3200.0
2025-09-05 17:28:46,178 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:46,178 - INFO - No valid responses to write for this batch
2025-09-05 17:28:46,189 - GPU-7 - INFO - Completed batch 122, total work units processed by this worker: 1916
2025-09-05 17:28:46,189 - INFO - Completed batch 122, total work units processed by this worker: 1916
W0905 17:28:46.229000 29040 torch/_dynamo/convert_frame.py:964] [0/101] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:46.229000 29040 torch/_dynamo/convert_frame.py:964] [0/101]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:46.229000 29040 torch/_dynamo/convert_frame.py:964] [0/101]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:46.229000 29040 torch/_dynamo/convert_frame.py:964] [0/101] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:46.229000 29040 torch/_dynamo/convert_frame.py:964] [0/101] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:46,231 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=48, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:46,231 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:46,231 - INFO - No valid responses to write for this batch
2025-09-05 17:28:46,243 - GPU-4 - INFO - Completed batch 80, total work units processed by this worker: 1256
2025-09-05 17:28:46,243 - INFO - Completed batch 80, total work units processed by this worker: 1256
2025-09-05 17:28:48,214 - GPU-0 - INFO - Processing batch 95 (16 work units)
2025-09-05 17:28:48,214 - INFO - Processing batch 95 (16 work units)
W0905 17:28:48.313000 29036 torch/_dynamo/convert_frame.py:964] [0/154] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.313000 29036 torch/_dynamo/convert_frame.py:964] [0/154]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.313000 29036 torch/_dynamo/convert_frame.py:964] [0/154]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:48.313000 29036 torch/_dynamo/convert_frame.py:964] [0/154] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.313000 29036 torch/_dynamo/convert_frame.py:964] [0/154] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,315 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,315 - INFO - Falling back to sequential processing
W0905 17:28:48.370000 29036 torch/_dynamo/convert_frame.py:964] [0/155] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.370000 29036 torch/_dynamo/convert_frame.py:964] [0/155]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.370000 29036 torch/_dynamo/convert_frame.py:964] [0/155]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:48.370000 29036 torch/_dynamo/convert_frame.py:964] [0/155] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.370000 29036 torch/_dynamo/convert_frame.py:964] [0/155] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,372 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=49, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=50, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,372 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,372 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,372 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,391 - GPU-0 - INFO - Completed batch 95, total work units processed by this worker: 1496
2025-09-05 17:28:48,391 - INFO - Completed batch 95, total work units processed by this worker: 1496
2025-09-05 17:28:48,391 - GPU-0 - INFO - Processing batch 96 (16 work units)
2025-09-05 17:28:48,391 - INFO - Processing batch 96 (16 work units)
W0905 17:28:48.489000 29036 torch/_dynamo/convert_frame.py:964] [0/156] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.489000 29036 torch/_dynamo/convert_frame.py:964] [0/156]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.489000 29036 torch/_dynamo/convert_frame.py:964] [0/156]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:48.489000 29036 torch/_dynamo/convert_frame.py:964] [0/156] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.489000 29036 torch/_dynamo/convert_frame.py:964] [0/156] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,491 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,491 - INFO - Falling back to sequential processing
2025-09-05 17:28:48,521 - GPU-7 - INFO - Processing batch 123 (16 work units)
2025-09-05 17:28:48,521 - INFO - Processing batch 123 (16 work units)
W0905 17:28:48.543000 29036 torch/_dynamo/convert_frame.py:964] [0/157] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.543000 29036 torch/_dynamo/convert_frame.py:964] [0/157]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.543000 29036 torch/_dynamo/convert_frame.py:964] [0/157]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:48.543000 29036 torch/_dynamo/convert_frame.py:964] [0/157] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.543000 29036 torch/_dynamo/convert_frame.py:964] [0/157] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,545 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,545 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,545 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,545 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,545 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,545 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,545 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,545 - GPU-0 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,545 - WARNING - Skipping empty response for id=51, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=52, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,546 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,546 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,546 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,563 - GPU-4 - INFO - Processing batch 81 (16 work units)
2025-09-05 17:28:48,563 - INFO - Processing batch 81 (16 work units)
2025-09-05 17:28:48,563 - GPU-0 - INFO - Completed batch 96, total work units processed by this worker: 1512
2025-09-05 17:28:48,563 - INFO - Completed batch 96, total work units processed by this worker: 1512
W0905 17:28:48.631000 29043 torch/_dynamo/convert_frame.py:964] [0/214] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.631000 29043 torch/_dynamo/convert_frame.py:964] [0/214]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.631000 29043 torch/_dynamo/convert_frame.py:964] [0/214]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:48.631000 29043 torch/_dynamo/convert_frame.py:964] [0/214] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.631000 29043 torch/_dynamo/convert_frame.py:964] [0/214] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,633 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,633 - INFO - Falling back to sequential processing
W0905 17:28:48.673000 29040 torch/_dynamo/convert_frame.py:964] [0/102] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.673000 29040 torch/_dynamo/convert_frame.py:964] [0/102]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.673000 29040 torch/_dynamo/convert_frame.py:964] [0/102]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:48.673000 29040 torch/_dynamo/convert_frame.py:964] [0/102] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.673000 29040 torch/_dynamo/convert_frame.py:964] [0/102] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,674 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,675 - INFO - Falling back to sequential processing
W0905 17:28:48.687000 29043 torch/_dynamo/convert_frame.py:964] [0/215] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.687000 29043 torch/_dynamo/convert_frame.py:964] [0/215]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.687000 29043 torch/_dynamo/convert_frame.py:964] [0/215]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:48.687000 29043 torch/_dynamo/convert_frame.py:964] [0/215] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.687000 29043 torch/_dynamo/convert_frame.py:964] [0/215] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,689 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,689 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - GPU-7 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - WARNING - Skipping empty response for id=53, magnitude=3200.0
2025-09-05 17:28:48,689 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,689 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,689 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,689 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,689 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,689 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,689 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,689 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - GPU-7 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - WARNING - Skipping empty response for id=54, magnitude=3200.0
2025-09-05 17:28:48,690 - GPU-7 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,690 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,690 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,690 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,701 - GPU-7 - INFO - Completed batch 123, total work units processed by this worker: 1932
2025-09-05 17:28:48,701 - INFO - Completed batch 123, total work units processed by this worker: 1932
2025-09-05 17:28:48,701 - GPU-7 - INFO - Processing batch 124 (16 work units)
2025-09-05 17:28:48,701 - INFO - Processing batch 124 (16 work units)
W0905 17:28:48.729000 29040 torch/_dynamo/convert_frame.py:964] [0/103] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.729000 29040 torch/_dynamo/convert_frame.py:964] [0/103]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.729000 29040 torch/_dynamo/convert_frame.py:964] [0/103]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:48.729000 29040 torch/_dynamo/convert_frame.py:964] [0/103] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.729000 29040 torch/_dynamo/convert_frame.py:964] [0/103] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,731 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,731 - GPU-4 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,731 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=55, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,732 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,732 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,743 - GPU-4 - INFO - Completed batch 81, total work units processed by this worker: 1272
2025-09-05 17:28:48,743 - INFO - Completed batch 81, total work units processed by this worker: 1272
2025-09-05 17:28:48,743 - GPU-4 - INFO - Processing batch 82 (16 work units)
2025-09-05 17:28:48,743 - INFO - Processing batch 82 (16 work units)
W0905 17:28:48.806000 29043 torch/_dynamo/convert_frame.py:964] [0/216] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.806000 29043 torch/_dynamo/convert_frame.py:964] [0/216]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.806000 29043 torch/_dynamo/convert_frame.py:964] [0/216]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:48.806000 29043 torch/_dynamo/convert_frame.py:964] [0/216] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.806000 29043 torch/_dynamo/convert_frame.py:964] [0/216] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,808 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,808 - INFO - Falling back to sequential processing
W0905 17:28:48.845000 29040 torch/_dynamo/convert_frame.py:964] [0/104] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.845000 29040 torch/_dynamo/convert_frame.py:964] [0/104]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.845000 29040 torch/_dynamo/convert_frame.py:964] [0/104]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:48.845000 29040 torch/_dynamo/convert_frame.py:964] [0/104] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.845000 29040 torch/_dynamo/convert_frame.py:964] [0/104] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,847 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,847 - INFO - Falling back to sequential processing
W0905 17:28:48.862000 29043 torch/_dynamo/convert_frame.py:964] [0/217] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.862000 29043 torch/_dynamo/convert_frame.py:964] [0/217]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.862000 29043 torch/_dynamo/convert_frame.py:964] [0/217]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:48.862000 29043 torch/_dynamo/convert_frame.py:964] [0/217] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.862000 29043 torch/_dynamo/convert_frame.py:964] [0/217] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,864 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=56, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=57, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,864 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,864 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,875 - GPU-7 - INFO - Completed batch 124, total work units processed by this worker: 1948
2025-09-05 17:28:48,875 - INFO - Completed batch 124, total work units processed by this worker: 1948
W0905 17:28:48.901000 29040 torch/_dynamo/convert_frame.py:964] [0/105] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:48.901000 29040 torch/_dynamo/convert_frame.py:964] [0/105]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:48.901000 29040 torch/_dynamo/convert_frame.py:964] [0/105]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:48.901000 29040 torch/_dynamo/convert_frame.py:964] [0/105] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:48.901000 29040 torch/_dynamo/convert_frame.py:964] [0/105] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:48,903 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=58, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=59, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:48,903 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:48,903 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,903 - INFO - No valid responses to write for this batch
2025-09-05 17:28:48,914 - GPU-4 - INFO - Completed batch 82, total work units processed by this worker: 1288
2025-09-05 17:28:48,914 - INFO - Completed batch 82, total work units processed by this worker: 1288
2025-09-05 17:28:50,632 - GPU-0 - INFO - Processing batch 97 (16 work units)
2025-09-05 17:28:50,632 - INFO - Processing batch 97 (16 work units)
W0905 17:28:50.731000 29036 torch/_dynamo/convert_frame.py:964] [0/158] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:50.731000 29036 torch/_dynamo/convert_frame.py:964] [0/158]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:50.731000 29036 torch/_dynamo/convert_frame.py:964] [0/158]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:50.731000 29036 torch/_dynamo/convert_frame.py:964] [0/158] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:50.731000 29036 torch/_dynamo/convert_frame.py:964] [0/158] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:50,733 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:50,733 - INFO - Falling back to sequential processing
W0905 17:28:50.785000 29036 torch/_dynamo/convert_frame.py:964] [0/159] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:50.785000 29036 torch/_dynamo/convert_frame.py:964] [0/159]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:50.785000 29036 torch/_dynamo/convert_frame.py:964] [0/159]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:50.785000 29036 torch/_dynamo/convert_frame.py:964] [0/159] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:50.785000 29036 torch/_dynamo/convert_frame.py:964] [0/159] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:50,787 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=60, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=61, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,788 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,788 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:50,788 - INFO - No valid responses to write for this batch
2025-09-05 17:28:50,798 - GPU-0 - INFO - Completed batch 97, total work units processed by this worker: 1528
2025-09-05 17:28:50,798 - INFO - Completed batch 97, total work units processed by this worker: 1528
2025-09-05 17:28:50,798 - GPU-0 - INFO - Processing batch 98 (16 work units)
2025-09-05 17:28:50,798 - INFO - Processing batch 98 (16 work units)
W0905 17:28:50.895000 29036 torch/_dynamo/convert_frame.py:964] [0/160] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:50.895000 29036 torch/_dynamo/convert_frame.py:964] [0/160]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:50.895000 29036 torch/_dynamo/convert_frame.py:964] [0/160]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:50.895000 29036 torch/_dynamo/convert_frame.py:964] [0/160] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:50.895000 29036 torch/_dynamo/convert_frame.py:964] [0/160] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:50,897 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:50,897 - INFO - Falling back to sequential processing
W0905 17:28:50.949000 29036 torch/_dynamo/convert_frame.py:964] [0/161] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:50.949000 29036 torch/_dynamo/convert_frame.py:964] [0/161]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:50.949000 29036 torch/_dynamo/convert_frame.py:964] [0/161]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:50.949000 29036 torch/_dynamo/convert_frame.py:964] [0/161] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:50.949000 29036 torch/_dynamo/convert_frame.py:964] [0/161] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:50,950 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=62, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - WARNING - Skipping empty response for id=63, magnitude=3200.0
2025-09-05 17:28:50,951 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:50,951 - INFO - No valid responses to write for this batch
2025-09-05 17:28:50,961 - GPU-0 - INFO - Completed batch 98, total work units processed by this worker: 1544
2025-09-05 17:28:50,961 - INFO - Completed batch 98, total work units processed by this worker: 1544
2025-09-05 17:28:51,186 - GPU-7 - INFO - Processing batch 125 (16 work units)
2025-09-05 17:28:51,186 - INFO - Processing batch 125 (16 work units)
2025-09-05 17:28:51,228 - GPU-4 - INFO - Processing batch 83 (16 work units)
2025-09-05 17:28:51,228 - INFO - Processing batch 83 (16 work units)
W0905 17:28:51.294000 29043 torch/_dynamo/convert_frame.py:964] [0/218] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:51.294000 29043 torch/_dynamo/convert_frame.py:964] [0/218]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:51.294000 29043 torch/_dynamo/convert_frame.py:964] [0/218]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:51.294000 29043 torch/_dynamo/convert_frame.py:964] [0/218] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:51.294000 29043 torch/_dynamo/convert_frame.py:964] [0/218] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:51,296 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:51,296 - INFO - Falling back to sequential processing
W0905 17:28:51.325000 29040 torch/_dynamo/convert_frame.py:964] [0/106] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:51.325000 29040 torch/_dynamo/convert_frame.py:964] [0/106]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:51.325000 29040 torch/_dynamo/convert_frame.py:964] [0/106]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:51.325000 29040 torch/_dynamo/convert_frame.py:964] [0/106] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:51.325000 29040 torch/_dynamo/convert_frame.py:964] [0/106] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:51,327 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:51,327 - INFO - Falling back to sequential processing
W0905 17:28:51.351000 29043 torch/_dynamo/convert_frame.py:964] [0/219] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:51.351000 29043 torch/_dynamo/convert_frame.py:964] [0/219]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:51.351000 29043 torch/_dynamo/convert_frame.py:964] [0/219]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:51.351000 29043 torch/_dynamo/convert_frame.py:964] [0/219] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:51.351000 29043 torch/_dynamo/convert_frame.py:964] [0/219] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:51,353 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=64, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,353 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:51,353 - INFO - No valid responses to write for this batch
2025-09-05 17:28:51,365 - GPU-7 - INFO - Completed batch 125, total work units processed by this worker: 1964
2025-09-05 17:28:51,365 - INFO - Completed batch 125, total work units processed by this worker: 1964
2025-09-05 17:28:51,365 - GPU-7 - INFO - Processing batch 126 (16 work units)
2025-09-05 17:28:51,365 - INFO - Processing batch 126 (16 work units)
W0905 17:28:51.382000 29040 torch/_dynamo/convert_frame.py:964] [0/107] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:51.382000 29040 torch/_dynamo/convert_frame.py:964] [0/107]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:51.382000 29040 torch/_dynamo/convert_frame.py:964] [0/107]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:51.382000 29040 torch/_dynamo/convert_frame.py:964] [0/107] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:51.382000 29040 torch/_dynamo/convert_frame.py:964] [0/107] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:51,384 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=65, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=66, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,384 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,384 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:51,384 - INFO - No valid responses to write for this batch
2025-09-05 17:28:51,396 - GPU-4 - INFO - Completed batch 83, total work units processed by this worker: 1304
2025-09-05 17:28:51,396 - INFO - Completed batch 83, total work units processed by this worker: 1304
2025-09-05 17:28:51,396 - GPU-4 - INFO - Processing batch 84 (16 work units)
2025-09-05 17:28:51,396 - INFO - Processing batch 84 (16 work units)
W0905 17:28:51.465000 29043 torch/_dynamo/convert_frame.py:964] [0/220] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:51.465000 29043 torch/_dynamo/convert_frame.py:964] [0/220]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:51.465000 29043 torch/_dynamo/convert_frame.py:964] [0/220]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:51.465000 29043 torch/_dynamo/convert_frame.py:964] [0/220] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:51.465000 29043 torch/_dynamo/convert_frame.py:964] [0/220] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:51,467 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:51,467 - INFO - Falling back to sequential processing
W0905 17:28:51.495000 29040 torch/_dynamo/convert_frame.py:964] [0/108] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:51.495000 29040 torch/_dynamo/convert_frame.py:964] [0/108]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:51.495000 29040 torch/_dynamo/convert_frame.py:964] [0/108]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:51.495000 29040 torch/_dynamo/convert_frame.py:964] [0/108] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:51.495000 29040 torch/_dynamo/convert_frame.py:964] [0/108] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:51,497 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:51,497 - INFO - Falling back to sequential processing
W0905 17:28:51.521000 29043 torch/_dynamo/convert_frame.py:964] [0/221] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:51.521000 29043 torch/_dynamo/convert_frame.py:964] [0/221]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:51.521000 29043 torch/_dynamo/convert_frame.py:964] [0/221]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:51.521000 29043 torch/_dynamo/convert_frame.py:964] [0/221] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:51.521000 29043 torch/_dynamo/convert_frame.py:964] [0/221] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:51,523 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:51,523 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,523 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=67, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=68, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,524 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,524 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:51,524 - INFO - No valid responses to write for this batch
2025-09-05 17:28:51,535 - GPU-7 - INFO - Completed batch 126, total work units processed by this worker: 1980
2025-09-05 17:28:51,535 - INFO - Completed batch 126, total work units processed by this worker: 1980
W0905 17:28:51.551000 29040 torch/_dynamo/convert_frame.py:964] [0/109] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:51.551000 29040 torch/_dynamo/convert_frame.py:964] [0/109]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:51.551000 29040 torch/_dynamo/convert_frame.py:964] [0/109]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:51.551000 29040 torch/_dynamo/convert_frame.py:964] [0/109] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:51.551000 29040 torch/_dynamo/convert_frame.py:964] [0/109] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:51,553 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:51,553 - GPU-4 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - GPU-4 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - GPU-4 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - GPU-4 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - GPU-4 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - GPU-4 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - WARNING - Skipping empty response for id=69, magnitude=3200.0
2025-09-05 17:28:51,553 - GPU-4 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,553 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,553 - GPU-4 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,553 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,553 - GPU-4 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,553 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - GPU-4 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - GPU-4 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - GPU-4 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - GPU-4 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - GPU-4 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - GPU-4 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - WARNING - Skipping empty response for id=70, magnitude=3200.0
2025-09-05 17:28:51,554 - GPU-4 - WARNING - Skipping empty response for id=71, magnitude=3200.0
2025-09-05 17:28:51,554 - WARNING - Skipping empty response for id=71, magnitude=3200.0
2025-09-05 17:28:51,554 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:51,554 - INFO - No valid responses to write for this batch
2025-09-05 17:28:51,565 - GPU-4 - INFO - Completed batch 84, total work units processed by this worker: 1320
2025-09-05 17:28:51,565 - INFO - Completed batch 84, total work units processed by this worker: 1320
2025-09-05 17:28:52,465 - GPU-1 - INFO - Completed batch 54, total work units processed by this worker: 864
2025-09-05 17:28:52,465 - INFO - Completed batch 54, total work units processed by this worker: 864
2025-09-05 17:28:53,261 - GPU-2 - INFO - Completed batch 25, total work units processed by this worker: 388
2025-09-05 17:28:53,261 - INFO - Completed batch 25, total work units processed by this worker: 388
2025-09-05 17:28:53,261 - GPU-2 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:28:53,261 - INFO - Processing batch 26 (16 work units)
2025-09-05 17:28:53,269 - GPU-0 - INFO - Processing batch 99 (16 work units)
2025-09-05 17:28:53,269 - INFO - Processing batch 99 (16 work units)
W0905 17:28:53.364000 29036 torch/_dynamo/convert_frame.py:964] [0/162] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:53.364000 29036 torch/_dynamo/convert_frame.py:964] [0/162]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:53.364000 29036 torch/_dynamo/convert_frame.py:964] [0/162]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:53.364000 29036 torch/_dynamo/convert_frame.py:964] [0/162] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:53.364000 29036 torch/_dynamo/convert_frame.py:964] [0/162] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:53,366 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:53,366 - INFO - Falling back to sequential processing
W0905 17:28:53.419000 29036 torch/_dynamo/convert_frame.py:964] [0/163] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:53.419000 29036 torch/_dynamo/convert_frame.py:964] [0/163]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:53.419000 29036 torch/_dynamo/convert_frame.py:964] [0/163]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:53.419000 29036 torch/_dynamo/convert_frame.py:964] [0/163] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:53.419000 29036 torch/_dynamo/convert_frame.py:964] [0/163] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:53,420 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=72, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=72, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=73, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,421 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:53,421 - INFO - No valid responses to write for this batch
2025-09-05 17:28:53,431 - GPU-0 - INFO - Completed batch 99, total work units processed by this worker: 1560
2025-09-05 17:28:53,431 - INFO - Completed batch 99, total work units processed by this worker: 1560
2025-09-05 17:28:53,432 - GPU-0 - INFO - Processing batch 100 (16 work units)
2025-09-05 17:28:53,432 - INFO - Processing batch 100 (16 work units)
W0905 17:28:53.524000 29036 torch/_dynamo/convert_frame.py:964] [0/164] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:53.524000 29036 torch/_dynamo/convert_frame.py:964] [0/164]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:53.524000 29036 torch/_dynamo/convert_frame.py:964] [0/164]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:53.524000 29036 torch/_dynamo/convert_frame.py:964] [0/164] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:53.524000 29036 torch/_dynamo/convert_frame.py:964] [0/164] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:53,526 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:53,526 - INFO - Falling back to sequential processing
W0905 17:28:53.578000 29036 torch/_dynamo/convert_frame.py:964] [0/165] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:53.578000 29036 torch/_dynamo/convert_frame.py:964] [0/165]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:53.578000 29036 torch/_dynamo/convert_frame.py:964] [0/165]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:53.578000 29036 torch/_dynamo/convert_frame.py:964] [0/165] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:53.578000 29036 torch/_dynamo/convert_frame.py:964] [0/165] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:53,580 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=74, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=75, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:53,580 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:53,580 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:53,580 - INFO - No valid responses to write for this batch
2025-09-05 17:28:53,590 - GPU-0 - INFO - Completed batch 100, total work units processed by this worker: 1576
2025-09-05 17:28:53,590 - INFO - Completed batch 100, total work units processed by this worker: 1576
2025-09-05 17:28:53,853 - GPU-7 - INFO - Processing batch 127 (16 work units)
2025-09-05 17:28:53,853 - INFO - Processing batch 127 (16 work units)
2025-09-05 17:28:53,867 - GPU-1 - INFO - Processing batch 55 (16 work units)
2025-09-05 17:28:53,867 - INFO - Processing batch 55 (16 work units)
2025-09-05 17:28:53,890 - GPU-4 - INFO - Processing batch 85 (16 work units)
2025-09-05 17:28:53,890 - INFO - Processing batch 85 (16 work units)
W0905 17:28:53.951000 29043 torch/_dynamo/convert_frame.py:964] [0/222] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:53.951000 29043 torch/_dynamo/convert_frame.py:964] [0/222]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:53.951000 29043 torch/_dynamo/convert_frame.py:964] [0/222]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:53.951000 29043 torch/_dynamo/convert_frame.py:964] [0/222] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:53.951000 29043 torch/_dynamo/convert_frame.py:964] [0/222] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:53,953 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:53,953 - INFO - Falling back to sequential processing
W0905 17:28:53.989000 29040 torch/_dynamo/convert_frame.py:964] [0/110] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:53.989000 29040 torch/_dynamo/convert_frame.py:964] [0/110]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:53.989000 29040 torch/_dynamo/convert_frame.py:964] [0/110]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:53.989000 29040 torch/_dynamo/convert_frame.py:964] [0/110] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:53.989000 29040 torch/_dynamo/convert_frame.py:964] [0/110] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:53,991 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:53,991 - INFO - Falling back to sequential processing
W0905 17:28:54.008000 29043 torch/_dynamo/convert_frame.py:964] [0/223] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:54.008000 29043 torch/_dynamo/convert_frame.py:964] [0/223]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:54.008000 29043 torch/_dynamo/convert_frame.py:964] [0/223]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:54.008000 29043 torch/_dynamo/convert_frame.py:964] [0/223] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:54.008000 29043 torch/_dynamo/convert_frame.py:964] [0/223] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:54,010 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:54,010 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:54,010 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:54,010 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:54,010 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:54,010 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:54,010 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:54,010 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:54,010 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:54,010 - GPU-7 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:54,010 - WARNING - Skipping empty response for id=76, magnitude=3200.0
2025-09-05 17:28:54,010 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,010 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,010 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,010 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,010 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,010 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,010 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,010 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,010 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,010 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,011 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,011 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,011 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,011 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,011 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,011 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,011 - GPU-7 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,011 - WARNING - Skipping empty response for id=77, magnitude=3200.0
2025-09-05 17:28:54,011 - GPU-7 - WARNING - Skipping empty response for id=78, magnitude=3200.0
2025-09-05 17:28:54,011 - WARNING - Skipping empty response for id=78, magnitude=3200.0
2025-09-05 17:28:54,011 - GPU-7 - WARNING - Skipping empty response for id=78, magnitude=3200.0
2025-09-05 17:28:54,011 - WARNING - Skipping empty response for id=78, magnitude=3200.0
2025-09-05 17:28:54,011 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:54,011 - INFO - No valid responses to write for this batch
2025-09-05 17:28:54,022 - GPU-7 - INFO - Completed batch 127, total work units processed by this worker: 1996
2025-09-05 17:28:54,022 - INFO - Completed batch 127, total work units processed by this worker: 1996
2025-09-05 17:28:54,022 - GPU-7 - INFO - Processing batch 128 (16 work units)
2025-09-05 17:28:54,022 - INFO - Processing batch 128 (16 work units)
W0905 17:28:54.046000 29040 torch/_dynamo/convert_frame.py:964] [0/111] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:54.046000 29040 torch/_dynamo/convert_frame.py:964] [0/111]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:54.046000 29040 torch/_dynamo/convert_frame.py:964] [0/111]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:54.046000 29040 torch/_dynamo/convert_frame.py:964] [0/111] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:54.046000 29040 torch/_dynamo/convert_frame.py:964] [0/111] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:54,047 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=80, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,048 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:54,048 - INFO - No valid responses to write for this batch
2025-09-05 17:28:54,059 - GPU-4 - INFO - Completed batch 85, total work units processed by this worker: 1336
2025-09-05 17:28:54,059 - INFO - Completed batch 85, total work units processed by this worker: 1336
2025-09-05 17:28:54,060 - GPU-4 - INFO - Processing batch 86 (16 work units)
2025-09-05 17:28:54,060 - INFO - Processing batch 86 (16 work units)
W0905 17:28:54.118000 29043 torch/_dynamo/convert_frame.py:964] [0/224] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:54.118000 29043 torch/_dynamo/convert_frame.py:964] [0/224]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:54.118000 29043 torch/_dynamo/convert_frame.py:964] [0/224]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:54.118000 29043 torch/_dynamo/convert_frame.py:964] [0/224] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:54.118000 29043 torch/_dynamo/convert_frame.py:964] [0/224] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:54,119 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:54,119 - INFO - Falling back to sequential processing
W0905 17:28:54.158000 29040 torch/_dynamo/convert_frame.py:964] [0/112] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:54.158000 29040 torch/_dynamo/convert_frame.py:964] [0/112]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:54.158000 29040 torch/_dynamo/convert_frame.py:964] [0/112]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:54.158000 29040 torch/_dynamo/convert_frame.py:964] [0/112] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:54.158000 29040 torch/_dynamo/convert_frame.py:964] [0/112] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:54,160 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:54,160 - INFO - Falling back to sequential processing
W0905 17:28:54.174000 29043 torch/_dynamo/convert_frame.py:964] [0/225] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:54.174000 29043 torch/_dynamo/convert_frame.py:964] [0/225]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:54.174000 29043 torch/_dynamo/convert_frame.py:964] [0/225]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:54.174000 29043 torch/_dynamo/convert_frame.py:964] [0/225] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:54.174000 29043 torch/_dynamo/convert_frame.py:964] [0/225] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:54,175 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=81, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=82, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,176 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,176 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:54,176 - INFO - No valid responses to write for this batch
2025-09-05 17:28:54,187 - GPU-7 - INFO - Completed batch 128, total work units processed by this worker: 2012
2025-09-05 17:28:54,187 - INFO - Completed batch 128, total work units processed by this worker: 2012
W0905 17:28:54.215000 29040 torch/_dynamo/convert_frame.py:964] [0/113] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:54.215000 29040 torch/_dynamo/convert_frame.py:964] [0/113]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:54.215000 29040 torch/_dynamo/convert_frame.py:964] [0/113]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:54.215000 29040 torch/_dynamo/convert_frame.py:964] [0/113] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:54.215000 29040 torch/_dynamo/convert_frame.py:964] [0/113] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:54,217 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=83, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=84, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:54,217 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:54,217 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:54,217 - INFO - No valid responses to write for this batch
2025-09-05 17:28:54,228 - GPU-4 - INFO - Completed batch 86, total work units processed by this worker: 1352
2025-09-05 17:28:54,228 - INFO - Completed batch 86, total work units processed by this worker: 1352
2025-09-05 17:28:54,298 - GPU-3 - INFO - Completed batch 54, total work units processed by this worker: 864
2025-09-05 17:28:54,298 - INFO - Completed batch 54, total work units processed by this worker: 864
skipping cudagraphs due to skipping cudagraphs due to cpu device (arg357_1)
2025-09-05 17:28:55,843 - GPU-0 - INFO - Processing batch 101 (16 work units)
2025-09-05 17:28:55,843 - INFO - Processing batch 101 (16 work units)
W0905 17:28:56.045000 29036 torch/_dynamo/convert_frame.py:964] [0/166] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.045000 29036 torch/_dynamo/convert_frame.py:964] [0/166]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.045000 29036 torch/_dynamo/convert_frame.py:964] [0/166]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:56.045000 29036 torch/_dynamo/convert_frame.py:964] [0/166] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.045000 29036 torch/_dynamo/convert_frame.py:964] [0/166] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,047 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,047 - INFO - Falling back to sequential processing
W0905 17:28:56.103000 29036 torch/_dynamo/convert_frame.py:964] [0/167] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.103000 29036 torch/_dynamo/convert_frame.py:964] [0/167]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.103000 29036 torch/_dynamo/convert_frame.py:964] [0/167]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:56.103000 29036 torch/_dynamo/convert_frame.py:964] [0/167] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.103000 29036 torch/_dynamo/convert_frame.py:964] [0/167] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,105 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=85, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=86, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - WARNING - Skipping empty response for id=87, magnitude=3200.0
2025-09-05 17:28:56,105 - WARNING - Skipping empty response for id=87, magnitude=3200.0
2025-09-05 17:28:56,105 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,105 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,118 - GPU-3 - INFO - Processing batch 55 (16 work units)
2025-09-05 17:28:56,118 - INFO - Processing batch 55 (16 work units)
2025-09-05 17:28:56,163 - GPU-0 - INFO - Completed batch 101, total work units processed by this worker: 1592
2025-09-05 17:28:56,163 - INFO - Completed batch 101, total work units processed by this worker: 1592
2025-09-05 17:28:56,164 - GPU-0 - INFO - Processing batch 102 (16 work units)
2025-09-05 17:28:56,164 - INFO - Processing batch 102 (16 work units)
W0905 17:28:56.307000 29036 torch/_dynamo/convert_frame.py:964] [0/168] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.307000 29036 torch/_dynamo/convert_frame.py:964] [0/168]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.307000 29036 torch/_dynamo/convert_frame.py:964] [0/168]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:56.307000 29036 torch/_dynamo/convert_frame.py:964] [0/168] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.307000 29036 torch/_dynamo/convert_frame.py:964] [0/168] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,309 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,309 - INFO - Falling back to sequential processing
W0905 17:28:56.367000 29036 torch/_dynamo/convert_frame.py:964] [0/169] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.367000 29036 torch/_dynamo/convert_frame.py:964] [0/169]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.367000 29036 torch/_dynamo/convert_frame.py:964] [0/169]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:56.367000 29036 torch/_dynamo/convert_frame.py:964] [0/169] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.367000 29036 torch/_dynamo/convert_frame.py:964] [0/169] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,369 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=88, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=88, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=89, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,369 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,369 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,384 - GPU-0 - INFO - Completed batch 102, total work units processed by this worker: 1608
2025-09-05 17:28:56,384 - INFO - Completed batch 102, total work units processed by this worker: 1608
2025-09-05 17:28:56,544 - GPU-7 - INFO - Processing batch 129 (16 work units)
2025-09-05 17:28:56,544 - INFO - Processing batch 129 (16 work units)
2025-09-05 17:28:56,593 - GPU-4 - INFO - Processing batch 87 (16 work units)
2025-09-05 17:28:56,593 - INFO - Processing batch 87 (16 work units)
W0905 17:28:56.649000 29043 torch/_dynamo/convert_frame.py:964] [0/226] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.649000 29043 torch/_dynamo/convert_frame.py:964] [0/226]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.649000 29043 torch/_dynamo/convert_frame.py:964] [0/226]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:56.649000 29043 torch/_dynamo/convert_frame.py:964] [0/226] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.649000 29043 torch/_dynamo/convert_frame.py:964] [0/226] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,650 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,651 - INFO - Falling back to sequential processing
W0905 17:28:56.703000 29040 torch/_dynamo/convert_frame.py:964] [0/114] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.703000 29040 torch/_dynamo/convert_frame.py:964] [0/114]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.703000 29040 torch/_dynamo/convert_frame.py:964] [0/114]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:56.703000 29040 torch/_dynamo/convert_frame.py:964] [0/114] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.703000 29040 torch/_dynamo/convert_frame.py:964] [0/114] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,704 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,705 - INFO - Falling back to sequential processing
W0905 17:28:56.705000 29043 torch/_dynamo/convert_frame.py:964] [0/227] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.705000 29043 torch/_dynamo/convert_frame.py:964] [0/227]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.705000 29043 torch/_dynamo/convert_frame.py:964] [0/227]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:56.705000 29043 torch/_dynamo/convert_frame.py:964] [0/227] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.705000 29043 torch/_dynamo/convert_frame.py:964] [0/227] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,707 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,707 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,707 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,707 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,707 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,707 - GPU-7 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,707 - WARNING - Skipping empty response for id=90, magnitude=3200.0
2025-09-05 17:28:56,707 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,707 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,707 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,707 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,707 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,707 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - WARNING - Skipping empty response for id=91, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,708 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,708 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,708 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,708 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,708 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,708 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,719 - GPU-7 - INFO - Completed batch 129, total work units processed by this worker: 2028
2025-09-05 17:28:56,719 - INFO - Completed batch 129, total work units processed by this worker: 2028
2025-09-05 17:28:56,719 - GPU-7 - INFO - Processing batch 130 (16 work units)
2025-09-05 17:28:56,719 - INFO - Processing batch 130 (16 work units)
W0905 17:28:56.759000 29040 torch/_dynamo/convert_frame.py:964] [0/115] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.759000 29040 torch/_dynamo/convert_frame.py:964] [0/115]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.759000 29040 torch/_dynamo/convert_frame.py:964] [0/115]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:56.759000 29040 torch/_dynamo/convert_frame.py:964] [0/115] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.759000 29040 torch/_dynamo/convert_frame.py:964] [0/115] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,761 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=92, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,761 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,762 - GPU-4 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,762 - WARNING - Skipping empty response for id=93, magnitude=3200.0
2025-09-05 17:28:56,762 - GPU-4 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,762 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,762 - GPU-4 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,762 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,762 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,762 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,773 - GPU-4 - INFO - Completed batch 87, total work units processed by this worker: 1368
2025-09-05 17:28:56,773 - INFO - Completed batch 87, total work units processed by this worker: 1368
2025-09-05 17:28:56,773 - GPU-4 - INFO - Processing batch 88 (16 work units)
2025-09-05 17:28:56,773 - INFO - Processing batch 88 (16 work units)
W0905 17:28:56.826000 29043 torch/_dynamo/convert_frame.py:964] [0/228] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.826000 29043 torch/_dynamo/convert_frame.py:964] [0/228]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.826000 29043 torch/_dynamo/convert_frame.py:964] [0/228]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:56.826000 29043 torch/_dynamo/convert_frame.py:964] [0/228] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.826000 29043 torch/_dynamo/convert_frame.py:964] [0/228] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,828 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,828 - INFO - Falling back to sequential processing
W0905 17:28:56.879000 29040 torch/_dynamo/convert_frame.py:964] [0/116] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.879000 29040 torch/_dynamo/convert_frame.py:964] [0/116]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.879000 29040 torch/_dynamo/convert_frame.py:964] [0/116]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:56.879000 29040 torch/_dynamo/convert_frame.py:964] [0/116] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.879000 29040 torch/_dynamo/convert_frame.py:964] [0/116] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,881 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,881 - INFO - Falling back to sequential processing
W0905 17:28:56.888000 29043 torch/_dynamo/convert_frame.py:964] [0/229] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.888000 29043 torch/_dynamo/convert_frame.py:964] [0/229]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.888000 29043 torch/_dynamo/convert_frame.py:964] [0/229]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 134378535485136)
W0905 17:28:56.888000 29043 torch/_dynamo/convert_frame.py:964] [0/229] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.888000 29043 torch/_dynamo/convert_frame.py:964] [0/229] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,889 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=94, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - WARNING - Skipping empty response for id=95, magnitude=3200.0
2025-09-05 17:28:56,890 - GPU-7 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,890 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,901 - GPU-7 - INFO - Completed batch 130, total work units processed by this worker: 2044
2025-09-05 17:28:56,901 - INFO - Completed batch 130, total work units processed by this worker: 2044
W0905 17:28:56.935000 29040 torch/_dynamo/convert_frame.py:964] [0/117] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:56.935000 29040 torch/_dynamo/convert_frame.py:964] [0/117]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:56.935000 29040 torch/_dynamo/convert_frame.py:964] [0/117]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 133336277453312)
W0905 17:28:56.935000 29040 torch/_dynamo/convert_frame.py:964] [0/117] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:56.935000 29040 torch/_dynamo/convert_frame.py:964] [0/117] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:56,937 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=96, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,937 - GPU-4 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,937 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,938 - GPU-4 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,938 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,938 - GPU-4 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,938 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,938 - GPU-4 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,938 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:56,938 - GPU-4 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,938 - INFO - No valid responses to write for this batch
2025-09-05 17:28:56,949 - GPU-4 - INFO - Completed batch 88, total work units processed by this worker: 1384
2025-09-05 17:28:56,949 - INFO - Completed batch 88, total work units processed by this worker: 1384
2025-09-05 17:28:57,229 - GPU-5 - INFO - Completed batch 58, total work units processed by this worker: 928
2025-09-05 17:28:57,229 - INFO - Completed batch 58, total work units processed by this worker: 928
2025-09-05 17:28:58,513 - GPU-0 - INFO - Processing batch 103 (16 work units)
2025-09-05 17:28:58,513 - INFO - Processing batch 103 (16 work units)
W0905 17:28:58.618000 29036 torch/_dynamo/convert_frame.py:964] [0/170] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:58.618000 29036 torch/_dynamo/convert_frame.py:964] [0/170]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:58.618000 29036 torch/_dynamo/convert_frame.py:964] [0/170]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:58.618000 29036 torch/_dynamo/convert_frame.py:964] [0/170] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:58.618000 29036 torch/_dynamo/convert_frame.py:964] [0/170] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:58,620 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:58,620 - INFO - Falling back to sequential processing
W0905 17:28:58.672000 29036 torch/_dynamo/convert_frame.py:964] [0/171] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:58.672000 29036 torch/_dynamo/convert_frame.py:964] [0/171]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:58.672000 29036 torch/_dynamo/convert_frame.py:964] [0/171]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:58.672000 29036 torch/_dynamo/convert_frame.py:964] [0/171] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:58.672000 29036 torch/_dynamo/convert_frame.py:964] [0/171] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:58,674 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=97, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=98, magnitude=3200.0
2025-09-05 17:28:58,674 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,674 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,675 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,675 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,675 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,675 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,675 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,675 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,675 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,675 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,675 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:58,675 - INFO - No valid responses to write for this batch
2025-09-05 17:28:58,685 - GPU-0 - INFO - Completed batch 103, total work units processed by this worker: 1624
2025-09-05 17:28:58,685 - INFO - Completed batch 103, total work units processed by this worker: 1624
2025-09-05 17:28:58,686 - GPU-0 - INFO - Processing batch 104 (4 work units)
2025-09-05 17:28:58,686 - INFO - Processing batch 104 (4 work units)
W0905 17:28:58.743000 29036 torch/_dynamo/convert_frame.py:964] [0/172] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:58.743000 29036 torch/_dynamo/convert_frame.py:964] [0/172]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:58.743000 29036 torch/_dynamo/convert_frame.py:964] [0/172]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:58.743000 29036 torch/_dynamo/convert_frame.py:964] [0/172] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:58.743000 29036 torch/_dynamo/convert_frame.py:964] [0/172] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:58,745 - ERROR - Error processing batch: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:58,745 - INFO - Falling back to sequential processing
W0905 17:28:58.797000 29036 torch/_dynamo/convert_frame.py:964] [0/173] torch._dynamo hit config.recompile_limit (8)
W0905 17:28:58.797000 29036 torch/_dynamo/convert_frame.py:964] [0/173]    function: 'wrapper' (/root/git/persona-subspace/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:927)
W0905 17:28:58.797000 29036 torch/_dynamo/convert_frame.py:964] [0/173]    last reason: 0/7: ___check_obj_id(kwargs['past_key_values'].key_cache[0], 124046390522848)
W0905 17:28:58.797000 29036 torch/_dynamo/convert_frame.py:964] [0/173] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0905 17:28:58.797000 29036 torch/_dynamo/convert_frame.py:964] [0/173] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
2025-09-05 17:28:58,799 - ERROR - Fallback processing also failed: recompile_limit reached with one_graph=True. Excessive recompilations can degrade performance due to the compilation overhead of each recompilation. To monitor recompilations, enable TORCH_LOGS=recompiles. If recompilations are expected, consider increasing torch._dynamo.config.cache_size_limit to an appropriate value.
2025-09-05 17:28:58,799 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,799 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,799 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,799 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,799 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,799 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,799 - GPU-0 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,799 - WARNING - Skipping empty response for id=99, magnitude=3200.0
2025-09-05 17:28:58,799 - GPU-0 - INFO - No valid responses to write for this batch
2025-09-05 17:28:58,799 - INFO - No valid responses to write for this batch
2025-09-05 17:28:58,800 - GPU-0 - INFO - Completed batch 104, total work units processed by this worker: 1628
2025-09-05 17:28:58,800 - INFO - Completed batch 104, total work units processed by this worker: 1628
2025-09-05 17:28:58,957 - GPU-5 - INFO - Received end signal, exiting
2025-09-05 17:28:58,957 - INFO - Received end signal, exiting
2025-09-05 17:28:58,958 - GPU-5 - INFO - Worker completed. Processed 58 batches, 928 work units
2025-09-05 17:28:58,958 - INFO - Worker completed. Processed 58 batches, 928 work units
2025-09-05 17:28:59,286 - GPU-7 - INFO - Received end signal, exiting
2025-09-05 17:28:59,286 - INFO - Received end signal, exiting
2025-09-05 17:28:59,286 - GPU-7 - INFO - Worker completed. Processed 130 batches, 2044 work units
2025-09-05 17:28:59,286 - INFO - Worker completed. Processed 130 batches, 2044 work units
2025-09-05 17:28:59,351 - GPU-4 - INFO - Received end signal, exiting
2025-09-05 17:28:59,351 - INFO - Received end signal, exiting
2025-09-05 17:28:59,352 - GPU-4 - INFO - Worker completed. Processed 88 batches, 1384 work units
2025-09-05 17:28:59,352 - INFO - Worker completed. Processed 88 batches, 1384 work units
2025-09-05 17:29:00,965 - GPU-0 - INFO - Received end signal, exiting
2025-09-05 17:29:00,965 - INFO - Received end signal, exiting
2025-09-05 17:29:00,966 - GPU-0 - INFO - Worker completed. Processed 104 batches, 1628 work units
2025-09-05 17:29:00,966 - INFO - Worker completed. Processed 104 batches, 1628 work units
2025-09-05 17:29:04,609 - GPU-6 - INFO - Completed batch 54, total work units processed by this worker: 852
2025-09-05 17:29:04,609 - INFO - Completed batch 54, total work units processed by this worker: 852
2025-09-05 17:29:07,706 - GPU-6 - INFO - Received end signal, exiting
2025-09-05 17:29:07,706 - INFO - Received end signal, exiting
2025-09-05 17:29:07,707 - GPU-6 - INFO - Worker completed. Processed 54 batches, 852 work units
2025-09-05 17:29:07,707 - INFO - Worker completed. Processed 54 batches, 852 work units
2025-09-05 17:29:10,185 - GPU-2 - INFO - Completed batch 26, total work units processed by this worker: 404
2025-09-05 17:29:10,185 - INFO - Completed batch 26, total work units processed by this worker: 404
2025-09-05 17:29:11,059 - GPU-1 - INFO - Completed batch 55, total work units processed by this worker: 880
2025-09-05 17:29:11,059 - INFO - Completed batch 55, total work units processed by this worker: 880
2025-09-05 17:29:11,059 - GPU-1 - INFO - Received end signal, exiting
2025-09-05 17:29:11,059 - INFO - Received end signal, exiting
2025-09-05 17:29:11,060 - GPU-1 - INFO - Worker completed. Processed 55 batches, 880 work units
2025-09-05 17:29:11,060 - INFO - Worker completed. Processed 55 batches, 880 work units
2025-09-05 17:29:12,816 - GPU-2 - INFO - Received end signal, exiting
2025-09-05 17:29:12,816 - INFO - Received end signal, exiting
2025-09-05 17:29:12,817 - GPU-2 - INFO - Worker completed. Processed 26 batches, 404 work units
2025-09-05 17:29:12,817 - INFO - Worker completed. Processed 26 batches, 404 work units
2025-09-05 17:29:13,560 - GPU-3 - INFO - Completed batch 55, total work units processed by this worker: 880
2025-09-05 17:29:13,560 - INFO - Completed batch 55, total work units processed by this worker: 880
2025-09-05 17:29:13,560 - GPU-3 - INFO - Received end signal, exiting
2025-09-05 17:29:13,560 - INFO - Received end signal, exiting
2025-09-05 17:29:13,561 - GPU-3 - INFO - Worker completed. Processed 55 batches, 880 work units
2025-09-05 17:29:13,561 - INFO - Worker completed. Processed 55 batches, 880 work units
Worker process 0 completed successfully
Worker process 1 completed successfully
Worker process 2 completed successfully
Worker process 3 completed successfully
Worker process 4 completed successfully
Worker process 5 completed successfully
Worker process 6 completed successfully
Worker process 7 completed successfully

All workers completed!
Results saved to: /root/git/persona-subspace/evals/susceptibility/gemma-2-27b/steered/default_50.jsonl
