{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Role-play or persona shift?\n",
    "\n",
    "- get activations from formatting conversation as dialogue\n",
    "- original activations of chat with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-14 18:39:54 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.steering_utils import ActivationSteering\n",
    "from utils.probing_utils import *\n",
    "from utils.inference_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_MODEL_NAME = \"google/gemma-2-27b-it\"\n",
    "LAYER = 22\n",
    "OUTPUT_DIR = \"./results/7_dialogue_chat\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat transcripts as dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_dir = \"/workspace/roleplay/gemma-2-27b\"\n",
    "transcripts_dir = \"/root/git/persona-subspace/roleplay/results/gemma-2-27b/role_vectors/transcripts\"\n",
    "\n",
    "roles = [\"anxious_teenager\", \"deep_sea_leviathan\", \"medieval_bard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_activations = {} # role to activation tensor of (n_layers, n_tokens, hidden_dim)\n",
    "chats = {} # role to list of dicts in typical chat conversation format\n",
    "\n",
    "for role in roles:\n",
    "    convo = json.load(open(f\"{transcripts_dir}/{role}.json\"))\n",
    "    chats[role] = convo[\"conversation\"]\n",
    "    \n",
    "    chat_activation = torch.load(f\"{activations_dir}/{role}.pt\")\n",
    "    chat_activations[role] = chat_activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46, 2623, 4608])\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(chat_activations[\"anxious_teenager\"].shape)\n",
    "print(len(chats[\"anxious_teenager\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to reformat chat conversation as a dialogue\n",
    "\n",
    "# def chat_to_dialogue(conversation, user_name, assistant_name):\n",
    "#     dialogue = \"\"\n",
    "#     for message in conversation:\n",
    "#         if message[\"role\"] == \"user\":\n",
    "#             dialogue += f\"{user_name}: {message['content']}\\n\"\n",
    "#         elif message[\"role\"] == \"assistant\":\n",
    "#             dialogue += f\"{assistant_name}: {message['content']}\\n\"\n",
    "#     return dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save string under \"dialogue\" in the original json file\n",
    "dialogues = {}\n",
    "\n",
    "for role in roles:\n",
    "    convo = json.load(open(f\"{transcripts_dir}/{role}.json\"))\n",
    "    dialogues[role] = convo[\"dialogue\"]\n",
    "\n",
    "# names = [(\"Therapist\", \"Christina\"), (\"Behemoth\", \"Leviathan\"), (\"NPC\", \"Bard\")]\n",
    "\n",
    "# for role, name in zip(roles, names):\n",
    "#     dialogue = chat_to_dialogue(chats[role], name[0], name[1])\n",
    "#     dialogues[role] = dialogue\n",
    "\n",
    "#     original_convo = json.load(open(f\"{transcripts_dir}/{role}.json\"))\n",
    "#     original_convo[\"dialogue\"] = dialogue\n",
    "\n",
    "#     with open(f\"{transcripts_dir}/{role}.json\", \"w\") as f:\n",
    "#         json.dump(original_convo, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get activations for dialogues\n",
    "\n",
    "- chat and not chat prompt formatted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d277de1006394b87ad9a8e141afecb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = load_model(CHAT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_activations = {}\n",
    "for role, dialogue in dialogues.items():\n",
    "    dialogue_activation = extract_full_activations(model, tokenizer, dialogue, chat_format=False)\n",
    "    torch.save(dialogue_activations, f\"{activations_dir}/dialogues/{role}.pt\")\n",
    "\n",
    "    dialogue_activations[role] = dialogue_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46, 2589, 4608])\n"
     ]
    }
   ],
   "source": [
    "print(dialogue_activations[\"anxious_teenager\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe could try base also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could just mean the entire conversation?\n",
    "\n",
    "# or just the responses of the assistant / 2nd interlocutor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
