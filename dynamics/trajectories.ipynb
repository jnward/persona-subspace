{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6083d828",
   "metadata": {},
   "source": [
    "# Trajectories of role + trait space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e91b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-20 21:51:39 [__init__.py:235] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.inference_utils import *\n",
    "from utils.probing_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in PCA results\n",
    "CHAT_MODEL_NAME = \"google/gemma-2-27b-it\"\n",
    "role_dir = \"roles_240\" \n",
    "trait_dir = \"traits_240\"\n",
    "layer = 22\n",
    "components = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac6142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_results = torch.load(f\"/workspace/{role_dir}/pca/layer{layer}_pos23.pt\", weights_only=False)\n",
    "trait_results = torch.load(f\"/workspace/{trait_dir}/pca/layer{layer}_pos-neg50.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2dee2c",
   "metadata": {},
   "source": [
    "## Get conversation activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d176b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_file = \"/root/git/persona-subspace/traits/results/transcripts/long1.json\"\n",
    "conversation = json.load(open(conversation_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model(CHAT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = extract_full_activations(model, tokenizer, conversation, layer=22)\n",
    "mean_acts_per_turn = mean_response_activation_per_turn(activations, conversation, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82aaa4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b5a92d4",
   "metadata": {},
   "source": [
    "## Project onto different PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine similarity after scaling the activation\n",
    "\n",
    "# get projection without scaling?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
